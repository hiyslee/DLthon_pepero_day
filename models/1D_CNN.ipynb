{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymkKuxN0LUvC",
        "outputId": "2c34df95-ed70-459a-d4fa-2913b0c0648d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WinError 3] 지정된 경로를 찾을 수 없습니다: '/content/drive/MyDrive/Colab Notebooks/아이펠/DLthon_pepero_day'\n",
            "c:\\Users\\suhol\\workspace\\aiffel_prac\\dlthon\\DLthon_pepero_day\\models\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/Colab Notebooks/아이펠/DLthon_pepero_day\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0jTAIhMYLMxg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "현재 작업 디렉토리: c:\\Users\\suhol\\workspace\\aiffel_prac\\dlthon\\DLthon_pepero_day\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import sys, os\n",
        "from pathlib import Path\n",
        "\n",
        "# 현재 파일이 상위의 루트 디렉토리로 이동시킨 것으로 인식하게 하도록...\n",
        "# 이렇게 하면 경로 수정 필요 없음\n",
        "TARGET_ROOT = \"DLthon_pepero_day\"\n",
        "p = Path.cwd()\n",
        "while p.name != TARGET_ROOT and p.parent != p:\n",
        "    p = p.parent\n",
        "if p.name != TARGET_ROOT:\n",
        "    raise RuntimeError(f\"상위 경로에 '{TARGET_ROOT}' 폴더를 찾지 못했습니다.\")\n",
        "if Path.cwd() != p:\n",
        "    os.chdir(p)\n",
        "if str(p) not in sys.path:\n",
        "    sys.path.insert(0, str(p))\n",
        "print(\"현재 작업 디렉토리:\", Path.cwd())\n",
        "\n",
        "from dataset import DKTCDataset, collate_fn, create_dataloaders\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxezvJsYMFlk"
      },
      "source": [
        "# 1. 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kR_ZDzNaB20H"
      },
      "outputs": [],
      "source": [
        "class CNNClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    1D CNN 기반 텍스트 분류 모델\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 vocab_size,      # 어휘 사전의 크기 (vocab 객체로부터 받음)\n",
        "                 embed_dim,       # 임베딩 벡터의 차원\n",
        "                 num_classes,     # 분류할 클래스의 개수 (5)\n",
        "                 num_filters,     # 각 필터 크기별 컨볼루션 필터의 수\n",
        "                 filter_sizes,    # 사용할 컨볼루션 필터의 크기\n",
        "                 dropout_prob):   # 드롭아웃 확률\n",
        "\n",
        "        super(CNNClassifier, self).__init__()\n",
        "\n",
        "        # 1. 임베딩 레이어\n",
        "        # padding_idx=0: <PAD> 토큰은 0 벡터로 임베딩하고 학습하지 않음\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "\n",
        "        # 2. 1D Convolution 레이어들 (다른 커널 크기를 사용)\n",
        "        # filter_sizes 개수만큼의 Conv1d 레이어를 ModuleList로 생성\n",
        "        # Conv1d는 (batch_size, in_channels, seq_len)을 입력으로 받음\n",
        "        # 우리 임베딩은 (batch_size, seq_len, embed_dim)이므로, permute(0, 2, 1) 필요\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels=embed_dim,\n",
        "                      out_channels=num_filters,\n",
        "                      kernel_size=k) # n-gram 크기\n",
        "            for k in filter_sizes\n",
        "        ])\n",
        "\n",
        "        # 3. 드롭아웃\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "        # 4. FC 레이어 (분류기)\n",
        "        # 각 필터에서 하나씩의 피처(max-pooling)가 나오므로,\n",
        "        # 총 num_filters * len(filter_sizes) 개의 피처가 입력됨\n",
        "        self.fc = nn.Linear(num_filters * len(filter_sizes), num_classes)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        \"\"\"\n",
        "        모델의 순전파 로직\n",
        "\n",
        "        Args:\n",
        "            input_ids (torch.Tensor): (batch_size, seq_len)\n",
        "                                     dataset.py에 의해 seq_len은 max_length-1이 됨\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: (batch_size, num_classes)\n",
        "                          각 클래스에 대한 logits\n",
        "        \"\"\"\n",
        "\n",
        "        # 1. 임베딩\n",
        "        # input_ids: (batch_size, seq_len)\n",
        "        # embedded: (batch_size, seq_len, embed_dim)\n",
        "        embedded = self.embedding(input_ids)\n",
        "\n",
        "        # 2. Conv1d 입력을 위해 차원 변경\n",
        "        # embedded: (batch_size, embed_dim, seq_len)\n",
        "        embedded = embedded.permute(0, 2, 1)\n",
        "\n",
        "        # 3. 컨볼루션 + ReLU\n",
        "        # conved: (batch_size, num_filters, new_seq_len)\n",
        "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
        "\n",
        "        # 4. Max pooling\n",
        "        # F.max_pool1d(conv, conv.shape[2])는 (batch_size, num_filters, 1)을 반환\n",
        "        # .squeeze(2)를 통해 (batch_size, num_filters)로 만듦\n",
        "        # pooled: [ (batch_size, num_filters), (batch_size, num_filters), ... ]\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "\n",
        "        # 5. 피처 결합 (Concatenate)\n",
        "        # catted: (batch_size, num_filters * len(filter_sizes))\n",
        "        catted = torch.cat(pooled, dim=1)\n",
        "\n",
        "        # 6. 드롭아웃\n",
        "        dropped = self.dropout(catted)\n",
        "\n",
        "        # 7. 완전 연결 레이어 (분류)\n",
        "        # logits: (batch_size, num_classes)\n",
        "        logits = self.fc(dropped)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Helper 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RPonn9uFOmrB"
      },
      "outputs": [],
      "source": [
        "# 1. 헬퍼 함수 정의\n",
        "def count_parameters(model):\n",
        "    \"\"\"학습 가능한 파라미터 수 계산\"\"\"\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    \"\"\"에폭 소요 시간 계산\"\"\"\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "def calculate_accuracy(preds, y_true):\n",
        "    \"\"\"\n",
        "    Accuracy 계산 함수\n",
        "    logits(preds)를 받아서 argmax로 예측 클래스를 추출\n",
        "    \"\"\"\n",
        "    y_pred = preds.argmax(dim=1) # (batch_size, num_classes) -> (batch_size)\n",
        "    correct = (y_pred == y_true).float() # True/False를 1.0/0.0으로\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc.item() # Python float 값으로 반환"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. train 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IRJHeKfWPGDx"
      },
      "outputs": [],
      "source": [
        "# 3. 평가 함수 정의\n",
        "def evaluate(model, iterator, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            predictions = model(input_ids)\n",
        "            loss = criterion(predictions, labels)\n",
        "\n",
        "            # Accuracy 계산\n",
        "            acc = calculate_accuracy(predictions, labels)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XGu6CyOjOqQ7"
      },
      "outputs": [],
      "source": [
        "# 2. 훈련 함수 정의\n",
        "def train(model, iterator, optimizer, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "        # 1. 배치 데이터를 device로 이동\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # 2. 그래디언트 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 3. 순전파\n",
        "        # input_ids: (batch_size, seq_len)\n",
        "        # predictions (logits): (batch_size, num_classes)\n",
        "        predictions = model(input_ids)\n",
        "\n",
        "        # 4. 손실 계산\n",
        "        loss = criterion(predictions, labels)\n",
        "\n",
        "        # 5. Accuracy 계산\n",
        "        acc = calculate_accuracy(predictions, labels)\n",
        "\n",
        "        # 6. 역전파\n",
        "        loss.backward()\n",
        "\n",
        "        # 7. 그래디언트 클리핑\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        # 8. 가중치 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 9. 누적\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc\n",
        "\n",
        "    # 평균 손실과 평균 acc 반환\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. 하이퍼파라미터 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN_PATH = './Data/aiffel-dl-thon-dktc-online-15/train.csv'\n",
        "TEST_PATH = './Data/aiffel-dl-thon-dktc-online-15/test.csv'\n",
        "SUBMIT_PATH = \"./Data/aiffel-dl-thon-dktc-online-15/submission.csv\"\n",
        "BEST_MODEL_PATH = './models/best_model_cnn.pt'\n",
        "VOCAB_SIZE = 1300\n",
        "MAX_LENGTH = 400\n",
        "BATCH_SIZE = 64\n",
        "VALID_RATIO = 0.1 # 훈련 데이터 중 10%를 검증용으로 사용\n",
        "\n",
        "INPUT_DIM = 1320\n",
        "EMBED_DIM = 256\n",
        "NUM_CLASSES = 5\n",
        "N_FILTERS = 128\n",
        "FILTER_SIZES = [2, 3, 4, 5]\n",
        "DROPOUT_PROB = 0.5\n",
        "\n",
        "N_EPOCHS = 500\n",
        "PATIENCE = 10\n",
        "\n",
        "LEARNING_RATE = 0.00005"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. 데이터 로더 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQDQOusDVGKy",
        "outputId": "e652d27a-710a-4aa9-b585-949e85214cac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Loading data...\n",
            "\n",
            "Loading data...\n",
            "==================================================\n",
            "데이터 로드 및 전처리 중...\n",
            "==================================================\n",
            "Train 데이터: 4950 개의 conversation\n",
            "Test 데이터: 500 개의 conversation\n",
            "\n",
            "샘플 데이터:\n",
            "Conversation: 지금 너 스스로를 죽여달라고 애원하는 것인가? 아닙니다. 죄송합니다. 죽을 거면 혼자 죽지 우리까지 사건에 휘말리게 해? 진짜 죽여버리고 싶게. 정말 잘못했습니다. 너가 선택해. 너가 죽을래 네 가족을 죽여줄까. 죄송합니다. 정말 잘못했습니다. 너에게는 선택권이 없어. 선택 못한다면 너와 네 가족까지 모조리 죽여버릴거야. 선택 못하겠습니다. 한번만 도와주세요. 그냥 다 죽여버려야겠군. 이의 없지? 제발 도와주세요.\n",
            "Label: 0\n",
            "\n",
            "Conversation: 길동경찰서입니다. 9시 40분 마트에 폭발물을 설치할거다. 네? 똑바로 들어 한번만 더 얘기한다. 장난전화 걸지 마시죠. 9시 40분 마트에 폭발물이 터지면 다 죽는거야. 장난전화는 업무방해죄에 해당됩니다. 판단은 너에게 달려있다. 길동경찰서에도 폭발물 터지면 꽤나 재미있겠지. 선생님 진정하세요. 난 이야기했어. 경고했다는 말이야.\n",
            "Label: 0\n",
            "\n",
            "Conversation: 너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어. 그만해. 니들 놀리는거 재미없어. 지영아 너가 키 160이지? 그럼 재는 160도 안돼는거네? 너 군대도 안가고 좋겠다. 니들이 나 작은데 보태준거 있냐? 난쟁이들도 장가가고하던데. 너도 희망을 가져봐 더이상 하지마라. 그 키크는 수술도 있대잖아? 니네 엄마는 그거 안해주디? 나람 해줬어. 저 키로 어찌살아. 제발 그만 괴롭히라고!\n",
            "Label: 3\n",
            "\n",
            "==================================================\n",
            "SentencePiece 모델 학습 중...\n",
            "==================================================\n",
            "\n",
            "모델 저장됨: ./configs/sentences.model\n",
            "Vocab 크기: 1300\n",
            "\n",
            "Train DataLoader 준비 완료: 총 4455개 conversations\n",
            "Validation DataLoader 준비 완료: 총 495개 conversations\n",
            "Test DataLoader 준비 완료: 총 500개 conversations.\n"
          ]
        }
      ],
      "source": [
        "# ==================================================================\n",
        "# 메인 실행 로직\n",
        "# ==================================================================\n",
        "\n",
        "# 0. GPU 장치 설정\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 1. 데이터 로더 준비\n",
        "print(\"\\nLoading data...\")\n",
        "\n",
        "\n",
        "# 2. 데이터 로더 생성\n",
        "print(\"\\nLoading data...\")\n",
        "try:\n",
        "    # create_dataloaders는 훈련/테스트 로더와 vocab을 반환\n",
        "    train_loader, val_loader, test_loader, vocab = create_dataloaders(\n",
        "        TRAIN_PATH, TEST_PATH,\n",
        "        vocab_size=VOCAB_SIZE,\n",
        "        max_length=MAX_LENGTH,\n",
        "        batch_size=BATCH_SIZE\n",
        "    )\n",
        "    PAD_IDX = vocab.PAD_ID # collate_fn에 사용\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"=\"*50)\n",
        "    print(\"ERROR: 데이터 파일(train.csv/test.csv)을 찾을 수 없습니다.\")\n",
        "    print(\"TRAIN_PATH와 TEST_PATH를 실제 파일 경로로 수정해주세요.\")\n",
        "    print(\"=\"*50)\n",
        "    exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYnfXaxdtoVq"
      },
      "source": [
        "# 6. 모델 선언"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Initializing 1D CNN model...\n",
            "The model has 799,749 trainable parameters.\n"
          ]
        }
      ],
      "source": [
        "# 5. 모델 하이퍼파라미터 및 초기화\n",
        "print(\"\\nInitializing 1D CNN model...\")\n",
        "\n",
        "model = CNNClassifier(\n",
        "    vocab_size=INPUT_DIM,\n",
        "    embed_dim=EMBED_DIM,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    num_filters=N_FILTERS,\n",
        "    filter_sizes=FILTER_SIZES,\n",
        "    dropout_prob=DROPOUT_PROB\n",
        ").to(device)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7. loss function, optimizer 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ylh9DvwZcA6w",
        "outputId": "3ed83e68-d118-4507-8d67-75749469f468"
      },
      "outputs": [],
      "source": [
        "# 6. 옵티마이저 및 손실 함수 정의\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# 7. 학습 설정\n",
        "best_valid_loss = float('inf')\n",
        "best_valid_acc = 0.0\n",
        "patience_counter = 0\n",
        "model_save_path = BEST_MODEL_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 8. 모델 훈련"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbVE10VqNU0Q",
        "outputId": "d733f500-7785-4f46-ee84-cb9adfc29c1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "--- 1D CNN Model Training starts ---\n",
            "============================================================\n",
            "\n",
            "Epoch: 01 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 1.738 | Train Acc: 27.48%\n",
            "\t Val. Loss: 1.321 |  Val. Acc: 63.71%\n",
            "\t>> Validation loss improved (1.321). Saving model...\n",
            "Epoch: 02 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 1.458 | Train Acc: 38.97%\n",
            "\t Val. Loss: 1.081 |  Val. Acc: 69.18%\n",
            "\t>> Validation loss improved (1.081). Saving model...\n",
            "Epoch: 03 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 1.201 | Train Acc: 51.51%\n",
            "\t Val. Loss: 0.918 |  Val. Acc: 73.96%\n",
            "\t>> Validation loss improved (0.918). Saving model...\n",
            "Epoch: 04 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 1.059 | Train Acc: 59.45%\n",
            "\t Val. Loss: 0.804 |  Val. Acc: 75.20%\n",
            "\t>> Validation loss improved (0.804). Saving model...\n",
            "Epoch: 05 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.925 | Train Acc: 65.13%\n",
            "\t Val. Loss: 0.706 |  Val. Acc: 80.03%\n",
            "\t>> Validation loss improved (0.706). Saving model...\n",
            "Epoch: 06 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.832 | Train Acc: 69.23%\n",
            "\t Val. Loss: 0.635 |  Val. Acc: 81.79%\n",
            "\t>> Validation loss improved (0.635). Saving model...\n",
            "Epoch: 07 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.764 | Train Acc: 71.63%\n",
            "\t Val. Loss: 0.581 |  Val. Acc: 81.79%\n",
            "\t>> Validation loss improved (0.581). Saving model...\n",
            "Epoch: 08 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.729 | Train Acc: 73.28%\n",
            "\t Val. Loss: 0.544 |  Val. Acc: 82.11%\n",
            "\t>> Validation loss improved (0.544). Saving model...\n",
            "Epoch: 09 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.672 | Train Acc: 76.09%\n",
            "\t Val. Loss: 0.511 |  Val. Acc: 82.57%\n",
            "\t>> Validation loss improved (0.511). Saving model...\n",
            "Epoch: 10 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.621 | Train Acc: 77.68%\n",
            "\t Val. Loss: 0.490 |  Val. Acc: 83.74%\n",
            "\t>> Validation loss improved (0.490). Saving model...\n",
            "Epoch: 11 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.594 | Train Acc: 78.66%\n",
            "\t Val. Loss: 0.467 |  Val. Acc: 82.37%\n",
            "\t>> Validation loss improved (0.467). Saving model...\n",
            "Epoch: 12 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.567 | Train Acc: 79.50%\n",
            "\t Val. Loss: 0.448 |  Val. Acc: 83.74%\n",
            "\t>> Validation loss improved (0.448). Saving model...\n",
            "Epoch: 13 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.542 | Train Acc: 80.51%\n",
            "\t Val. Loss: 0.433 |  Val. Acc: 83.54%\n",
            "\t>> Validation loss improved (0.433). Saving model...\n",
            "Epoch: 14 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.528 | Train Acc: 81.39%\n",
            "\t Val. Loss: 0.423 |  Val. Acc: 84.20%\n",
            "\t>> Validation loss improved (0.423). Saving model...\n",
            "Epoch: 15 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.490 | Train Acc: 82.71%\n",
            "\t Val. Loss: 0.411 |  Val. Acc: 84.59%\n",
            "\t>> Validation loss improved (0.411). Saving model...\n",
            "Epoch: 16 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.480 | Train Acc: 83.44%\n",
            "\t Val. Loss: 0.400 |  Val. Acc: 86.61%\n",
            "\t>> Validation loss improved (0.400). Saving model...\n",
            "Epoch: 17 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.467 | Train Acc: 83.82%\n",
            "\t Val. Loss: 0.394 |  Val. Acc: 85.30%\n",
            "\t>> Validation loss improved (0.394). Saving model...\n",
            "Epoch: 18 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.445 | Train Acc: 84.45%\n",
            "\t Val. Loss: 0.387 |  Val. Acc: 86.37%\n",
            "\t>> Validation loss improved (0.387). Saving model...\n",
            "Epoch: 19 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.441 | Train Acc: 84.55%\n",
            "\t Val. Loss: 0.378 |  Val. Acc: 86.22%\n",
            "\t>> Validation loss improved (0.378). Saving model...\n",
            "Epoch: 20 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.420 | Train Acc: 85.56%\n",
            "\t Val. Loss: 0.370 |  Val. Acc: 87.54%\n",
            "\t>> Validation loss improved (0.370). Saving model...\n",
            "Epoch: 21 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.388 | Train Acc: 86.69%\n",
            "\t Val. Loss: 0.364 |  Val. Acc: 87.34%\n",
            "\t>> Validation loss improved (0.364). Saving model...\n",
            "Epoch: 22 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.404 | Train Acc: 86.06%\n",
            "\t Val. Loss: 0.357 |  Val. Acc: 88.19%\n",
            "\t>> Validation loss improved (0.357). Saving model...\n",
            "Epoch: 23 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.398 | Train Acc: 86.08%\n",
            "\t Val. Loss: 0.352 |  Val. Acc: 88.66%\n",
            "\t>> Validation loss improved (0.352). Saving model...\n",
            "Epoch: 24 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.379 | Train Acc: 86.17%\n",
            "\t Val. Loss: 0.347 |  Val. Acc: 88.66%\n",
            "\t>> Validation loss improved (0.347). Saving model...\n",
            "Epoch: 25 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.372 | Train Acc: 87.00%\n",
            "\t Val. Loss: 0.345 |  Val. Acc: 88.19%\n",
            "\t>> Validation loss improved (0.345). Saving model...\n",
            "Epoch: 26 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.358 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.338 |  Val. Acc: 89.05%\n",
            "\t>> Validation loss improved (0.338). Saving model...\n",
            "Epoch: 27 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.342 | Train Acc: 88.00%\n",
            "\t Val. Loss: 0.334 |  Val. Acc: 88.32%\n",
            "\t>> Validation loss improved (0.334). Saving model...\n",
            "Epoch: 28 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.338 | Train Acc: 88.48%\n",
            "\t Val. Loss: 0.329 |  Val. Acc: 88.51%\n",
            "\t>> Validation loss improved (0.329). Saving model...\n",
            "Epoch: 29 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.342 | Train Acc: 88.55%\n",
            "\t Val. Loss: 0.327 |  Val. Acc: 88.78%\n",
            "\t>> Validation loss improved (0.327). Saving model...\n",
            "Epoch: 30 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.310 | Train Acc: 89.27%\n",
            "\t Val. Loss: 0.326 |  Val. Acc: 88.66%\n",
            "\t>> Validation loss improved (0.326). Saving model...\n",
            "Epoch: 31 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.317 | Train Acc: 89.27%\n",
            "\t Val. Loss: 0.322 |  Val. Acc: 88.58%\n",
            "\t>> Validation loss improved (0.322). Saving model...\n",
            "Epoch: 32 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.307 | Train Acc: 89.38%\n",
            "\t Val. Loss: 0.319 |  Val. Acc: 89.44%\n",
            "\t>> Validation loss improved (0.319). Saving model...\n",
            "Epoch: 33 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.306 | Train Acc: 89.58%\n",
            "\t Val. Loss: 0.315 |  Val. Acc: 89.24%\n",
            "\t>> Validation loss improved (0.315). Saving model...\n",
            "Epoch: 34 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.288 | Train Acc: 90.37%\n",
            "\t Val. Loss: 0.313 |  Val. Acc: 89.63%\n",
            "\t>> Validation loss improved (0.313). Saving model...\n",
            "Epoch: 35 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.282 | Train Acc: 90.61%\n",
            "\t Val. Loss: 0.307 |  Val. Acc: 89.83%\n",
            "\t>> Validation loss improved (0.307). Saving model...\n",
            "Epoch: 36 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.285 | Train Acc: 90.85%\n",
            "\t Val. Loss: 0.307 |  Val. Acc: 89.24%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 37 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.267 | Train Acc: 90.78%\n",
            "\t Val. Loss: 0.304 |  Val. Acc: 90.54%\n",
            "\t>> Validation loss improved (0.304). Saving model...\n",
            "Epoch: 38 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.266 | Train Acc: 90.91%\n",
            "\t Val. Loss: 0.304 |  Val. Acc: 89.24%\n",
            "\t>> Validation loss improved (0.304). Saving model...\n",
            "Epoch: 39 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.259 | Train Acc: 91.45%\n",
            "\t Val. Loss: 0.298 |  Val. Acc: 90.02%\n",
            "\t>> Validation loss improved (0.298). Saving model...\n",
            "Epoch: 40 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.251 | Train Acc: 92.11%\n",
            "\t Val. Loss: 0.298 |  Val. Acc: 89.44%\n",
            "\t>> Validation loss improved (0.298). Saving model...\n",
            "Epoch: 41 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.252 | Train Acc: 91.71%\n",
            "\t Val. Loss: 0.294 |  Val. Acc: 90.22%\n",
            "\t>> Validation loss improved (0.294). Saving model...\n",
            "Epoch: 42 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.242 | Train Acc: 91.91%\n",
            "\t Val. Loss: 0.300 |  Val. Acc: 89.44%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 43 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.249 | Train Acc: 91.45%\n",
            "\t Val. Loss: 0.292 |  Val. Acc: 90.22%\n",
            "\t>> Validation loss improved (0.292). Saving model...\n",
            "Epoch: 44 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.241 | Train Acc: 92.28%\n",
            "\t Val. Loss: 0.293 |  Val. Acc: 89.63%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 45 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.224 | Train Acc: 92.80%\n",
            "\t Val. Loss: 0.292 |  Val. Acc: 90.54%\n",
            "\t>> Validation loss improved (0.292). Saving model...\n",
            "Epoch: 46 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.219 | Train Acc: 92.79%\n",
            "\t Val. Loss: 0.286 |  Val. Acc: 90.80%\n",
            "\t>> Validation loss improved (0.286). Saving model...\n",
            "Epoch: 47 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.216 | Train Acc: 92.38%\n",
            "\t Val. Loss: 0.284 |  Val. Acc: 90.61%\n",
            "\t>> Validation loss improved (0.284). Saving model...\n",
            "Epoch: 48 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.214 | Train Acc: 92.98%\n",
            "\t Val. Loss: 0.285 |  Val. Acc: 90.02%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 49 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.209 | Train Acc: 93.29%\n",
            "\t Val. Loss: 0.287 |  Val. Acc: 89.83%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 50 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.216 | Train Acc: 93.16%\n",
            "\t Val. Loss: 0.287 |  Val. Acc: 89.63%\n",
            "\t>> Validation loss did not improve. Counter: 3/10\n",
            "Epoch: 51 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.196 | Train Acc: 93.76%\n",
            "\t Val. Loss: 0.284 |  Val. Acc: 89.63%\n",
            "\t>> Validation loss did not improve. Counter: 4/10\n",
            "Epoch: 52 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.189 | Train Acc: 94.14%\n",
            "\t Val. Loss: 0.278 |  Val. Acc: 90.41%\n",
            "\t>> Validation loss improved (0.278). Saving model...\n",
            "Epoch: 53 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.186 | Train Acc: 94.15%\n",
            "\t Val. Loss: 0.280 |  Val. Acc: 90.61%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 54 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.186 | Train Acc: 93.85%\n",
            "\t Val. Loss: 0.281 |  Val. Acc: 89.63%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 55 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.177 | Train Acc: 94.58%\n",
            "\t Val. Loss: 0.277 |  Val. Acc: 90.61%\n",
            "\t>> Validation loss improved (0.277). Saving model...\n",
            "Epoch: 56 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.182 | Train Acc: 94.65%\n",
            "\t Val. Loss: 0.277 |  Val. Acc: 90.22%\n",
            "\t>> Validation loss improved (0.277). Saving model...\n",
            "Epoch: 57 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.185 | Train Acc: 93.98%\n",
            "\t Val. Loss: 0.273 |  Val. Acc: 90.61%\n",
            "\t>> Validation loss improved (0.273). Saving model...\n",
            "Epoch: 58 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.166 | Train Acc: 94.96%\n",
            "\t Val. Loss: 0.276 |  Val. Acc: 90.80%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 59 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.167 | Train Acc: 94.67%\n",
            "\t Val. Loss: 0.273 |  Val. Acc: 90.80%\n",
            "\t>> Validation loss improved (0.273). Saving model...\n",
            "Epoch: 60 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.164 | Train Acc: 94.87%\n",
            "\t Val. Loss: 0.272 |  Val. Acc: 90.61%\n",
            "\t>> Validation loss improved (0.272). Saving model...\n",
            "Epoch: 61 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.165 | Train Acc: 94.44%\n",
            "\t Val. Loss: 0.272 |  Val. Acc: 90.41%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 62 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.152 | Train Acc: 95.47%\n",
            "\t Val. Loss: 0.274 |  Val. Acc: 90.41%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 63 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.156 | Train Acc: 95.08%\n",
            "\t Val. Loss: 0.272 |  Val. Acc: 90.22%\n",
            "\t>> Validation loss improved (0.272). Saving model...\n",
            "Epoch: 64 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.153 | Train Acc: 95.12%\n",
            "\t Val. Loss: 0.270 |  Val. Acc: 91.39%\n",
            "\t>> Validation loss improved (0.270). Saving model...\n",
            "Epoch: 65 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.145 | Train Acc: 95.58%\n",
            "\t Val. Loss: 0.269 |  Val. Acc: 91.00%\n",
            "\t>> Validation loss improved (0.269). Saving model...\n",
            "Epoch: 66 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.143 | Train Acc: 95.59%\n",
            "\t Val. Loss: 0.266 |  Val. Acc: 91.19%\n",
            "\t>> Validation loss improved (0.266). Saving model...\n",
            "Epoch: 67 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.144 | Train Acc: 95.72%\n",
            "\t Val. Loss: 0.268 |  Val. Acc: 91.58%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 68 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.133 | Train Acc: 96.06%\n",
            "\t Val. Loss: 0.269 |  Val. Acc: 91.19%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 69 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.139 | Train Acc: 95.66%\n",
            "\t Val. Loss: 0.267 |  Val. Acc: 91.39%\n",
            "\t>> Validation loss did not improve. Counter: 3/10\n",
            "Epoch: 70 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.136 | Train Acc: 95.74%\n",
            "\t Val. Loss: 0.268 |  Val. Acc: 91.19%\n",
            "\t>> Validation loss did not improve. Counter: 4/10\n",
            "Epoch: 71 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.138 | Train Acc: 95.64%\n",
            "\t Val. Loss: 0.271 |  Val. Acc: 90.68%\n",
            "\t>> Validation loss did not improve. Counter: 5/10\n",
            "Epoch: 72 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.126 | Train Acc: 96.23%\n",
            "\t Val. Loss: 0.266 |  Val. Acc: 91.39%\n",
            "\t>> Validation loss improved (0.266). Saving model...\n",
            "Epoch: 73 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.130 | Train Acc: 96.20%\n",
            "\t Val. Loss: 0.272 |  Val. Acc: 90.22%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 74 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.122 | Train Acc: 96.53%\n",
            "\t Val. Loss: 0.269 |  Val. Acc: 91.58%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 75 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.119 | Train Acc: 96.58%\n",
            "\t Val. Loss: 0.264 |  Val. Acc: 91.78%\n",
            "\t>> Validation loss improved (0.264). Saving model...\n",
            "Epoch: 76 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.115 | Train Acc: 96.51%\n",
            "\t Val. Loss: 0.266 |  Val. Acc: 91.19%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 77 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.113 | Train Acc: 96.55%\n",
            "\t Val. Loss: 0.266 |  Val. Acc: 91.19%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 78 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.114 | Train Acc: 96.56%\n",
            "\t Val. Loss: 0.267 |  Val. Acc: 90.61%\n",
            "\t>> Validation loss did not improve. Counter: 3/10\n",
            "Epoch: 79 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.112 | Train Acc: 96.36%\n",
            "\t Val. Loss: 0.265 |  Val. Acc: 91.00%\n",
            "\t>> Validation loss did not improve. Counter: 4/10\n",
            "Epoch: 80 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.116 | Train Acc: 96.47%\n",
            "\t Val. Loss: 0.266 |  Val. Acc: 91.00%\n",
            "\t>> Validation loss did not improve. Counter: 5/10\n",
            "Epoch: 81 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.110 | Train Acc: 96.75%\n",
            "\t Val. Loss: 0.267 |  Val. Acc: 91.07%\n",
            "\t>> Validation loss did not improve. Counter: 6/10\n",
            "Epoch: 82 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.115 | Train Acc: 96.52%\n",
            "\t Val. Loss: 0.265 |  Val. Acc: 91.07%\n",
            "\t>> Validation loss did not improve. Counter: 7/10\n",
            "Epoch: 83 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.101 | Train Acc: 97.28%\n",
            "\t Val. Loss: 0.267 |  Val. Acc: 90.61%\n",
            "\t>> Validation loss did not improve. Counter: 8/10\n",
            "Epoch: 84 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.106 | Train Acc: 96.82%\n",
            "\t Val. Loss: 0.264 |  Val. Acc: 91.26%\n",
            "\t>> Validation loss improved (0.264). Saving model...\n",
            "Epoch: 85 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.102 | Train Acc: 97.05%\n",
            "\t Val. Loss: 0.262 |  Val. Acc: 91.07%\n",
            "\t>> Validation loss improved (0.262). Saving model...\n",
            "Epoch: 86 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.098 | Train Acc: 96.79%\n",
            "\t Val. Loss: 0.263 |  Val. Acc: 91.07%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 87 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.092 | Train Acc: 97.15%\n",
            "\t Val. Loss: 0.263 |  Val. Acc: 91.26%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 88 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.092 | Train Acc: 97.51%\n",
            "\t Val. Loss: 0.263 |  Val. Acc: 91.19%\n",
            "\t>> Validation loss did not improve. Counter: 3/10\n",
            "Epoch: 89 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.098 | Train Acc: 97.13%\n",
            "\t Val. Loss: 0.261 |  Val. Acc: 91.46%\n",
            "\t>> Validation loss improved (0.261). Saving model...\n",
            "Epoch: 90 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.088 | Train Acc: 97.58%\n",
            "\t Val. Loss: 0.262 |  Val. Acc: 91.39%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 91 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.092 | Train Acc: 97.10%\n",
            "\t Val. Loss: 0.263 |  Val. Acc: 91.26%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 92 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.083 | Train Acc: 97.69%\n",
            "\t Val. Loss: 0.265 |  Val. Acc: 91.07%\n",
            "\t>> Validation loss did not improve. Counter: 3/10\n",
            "Epoch: 93 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.091 | Train Acc: 97.16%\n",
            "\t Val. Loss: 0.266 |  Val. Acc: 91.26%\n",
            "\t>> Validation loss did not improve. Counter: 4/10\n",
            "Epoch: 94 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.086 | Train Acc: 97.27%\n",
            "\t Val. Loss: 0.260 |  Val. Acc: 91.66%\n",
            "\t>> Validation loss improved (0.260). Saving model...\n",
            "Epoch: 95 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.081 | Train Acc: 97.91%\n",
            "\t Val. Loss: 0.265 |  Val. Acc: 91.26%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 96 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.074 | Train Acc: 97.90%\n",
            "\t Val. Loss: 0.260 |  Val. Acc: 91.19%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 97 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.072 | Train Acc: 98.04%\n",
            "\t Val. Loss: 0.265 |  Val. Acc: 91.26%\n",
            "\t>> Validation loss did not improve. Counter: 3/10\n",
            "Epoch: 98 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.077 | Train Acc: 97.75%\n",
            "\t Val. Loss: 0.264 |  Val. Acc: 91.26%\n",
            "\t>> Validation loss did not improve. Counter: 4/10\n",
            "Epoch: 99 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.071 | Train Acc: 98.15%\n",
            "\t Val. Loss: 0.260 |  Val. Acc: 91.26%\n",
            "\t>> Validation loss did not improve. Counter: 5/10\n",
            "Epoch: 100 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.073 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.261 |  Val. Acc: 91.26%\n",
            "\t>> Validation loss did not improve. Counter: 6/10\n",
            "Epoch: 101 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.069 | Train Acc: 98.15%\n",
            "\t Val. Loss: 0.268 |  Val. Acc: 91.66%\n",
            "\t>> Validation loss did not improve. Counter: 7/10\n",
            "Epoch: 102 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.074 | Train Acc: 97.68%\n",
            "\t Val. Loss: 0.267 |  Val. Acc: 91.46%\n",
            "\t>> Validation loss did not improve. Counter: 8/10\n",
            "Epoch: 103 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.065 | Train Acc: 98.49%\n",
            "\t Val. Loss: 0.260 |  Val. Acc: 91.46%\n",
            "\t>> Validation loss did not improve. Counter: 9/10\n",
            "Epoch: 104 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.067 | Train Acc: 98.27%\n",
            "\t Val. Loss: 0.263 |  Val. Acc: 91.46%\n",
            "\t>> Validation loss did not improve. Counter: 10/10\n",
            "--- Early stopping triggered after 104 epochs ---\n",
            "\n",
            "============================================================\n",
            "--- Training Finished ---\n",
            "Best Model saved to: ./models/best_model_cnn.pt\n",
            "  -> Best Validation Loss: 0.260\n",
            "  -> Best Validation Acc at Best Loss: 91.66%\n",
            "============================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"--- 1D CNN Model Training starts ---\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "# 8. 학습 루프\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "    valid_loss, valid_acc = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "    # 조기 종료 로직\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        best_valid_acc = valid_acc\n",
        "        torch.save(model.state_dict(), model_save_path)\n",
        "        patience_counter = 0\n",
        "        print(f'\\t>> Validation loss improved ({best_valid_loss:.3f}). Saving model...')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f'\\t>> Validation loss did not improve. Counter: {patience_counter}/{PATIENCE}')\n",
        "\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(f'--- Early stopping triggered after {epoch+1} epochs ---')\n",
        "            break\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"--- Training Finished ---\")\n",
        "print(f\"Best Model saved to: {model_save_path}\")\n",
        "print(f\"  -> Best Validation Loss: {best_valid_loss:.3f}\")\n",
        "print(f\"  -> Best Validation Acc at Best Loss: {best_valid_acc*100:.2f}%\")\n",
        "print(f\"{'='*60}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Hc7t5UzANU4g",
        "outputId": "c0312a72-40e6-4763-8fa3-be5a83e26973"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "--- Checking Model Predictions (1 Batch from Validation Set) ---\n",
            "============================================================\n",
            "\n",
            "Total 64 samples in this batch.\n",
            "\n",
            "--- Sample 1 / ✅ (Correct) ---\n",
            "  [Original Text]: 너가 뭐라도 되는거 같냐 닥쳐 이새끼좀 봐 뭐라고 닥치라 했냐 시비좀 그만 걸어 넌 오늘 뒤졌다 닥치고 따라와 제발 그만해 이 찐따새끼 많이 컸다 따라와 저리가 야 이새끼 다신 말 못하게 조져 오키 오늘 너 뒤졌다\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 2 / ✅ (Correct) ---\n",
            "  [Original Text]: 요즘 너무 건조해서 그런지 온몸이 가 ⁇  난 논바닥 같아. 쩍쩍 갈라지고 아파. 나도. 특히 자고 일어나면 목이 너무 칼칼하고 아파. 어떻게 해야 할까? 이 건조한 지옥에서 벗어나고 싶어. 자기 전에 방에 젖은 수건 널어놓고 자봐. 효과 좋아. 그래? 오늘 밤에 당장 해봐야겠다. 고마워. 응. 그리고 귤껍질 모아서 방에 놔두는 것도 천연 가습기 효과가 있대. 알겠어. 너는 정말 나의 생활 백과사전이구나. 모르는 게 뭐야 대체? 너 없었으면 나 어떻게 살았을까. 요즘 너무 건조해서 그런지, 피부가 다 뒤집어졌어. 나도. 각질도 많이 생기고, 화장도 다 떠. 미스트를 뿌려도 소용이 없어. 수분 크림을 듬뿍 바르고 자야겠다. 나는 1일 1팩 하고 있어. 확실히 좀 나아지는 것 같아. 그래? 나도 오늘부터 해봐야겠다. 추천하는 팩 있어? 알겠어. 내가 쓰는 거 링크 보내줄게.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 3 / ✅ (Correct) ---\n",
            "  [Original Text]: 너 엄마 없어? 아.응. 왜 ? 뭐때문에 .? 아빠가. 술 좋아하셔서 . 아? 술? 폭행? 아 너도 참 불쌍하다 그래서 엄마가 도망갔구나 ? .아.으응. 술이 뭐 좋다고 그러는거래 이해안가네 너희 아빠 정신 좀 차리라해 .응 아빠는 술에 엄마는 도망에 아휴 우리 부모님은 안그래서 다행이다 부.럽다\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 4 / ✅ (Correct) ---\n",
            "  [Original Text]: 넌 목소리가 왜 그래? 듣기 싫어. 나도 내 목소리가 가끔 듣기 싫더라. 듣기 싫으니까 앞으로 너 학교와서 말하지마. 응? 선생님이 발표만 안 시키면. 그래볼게. 응 제발. 진짜 듣기 싫어 앵앵 그럼 목소리 다르게 내볼까? 아니. 그냥 너가 낸 소리 다 싫어. 난 너랑 잘 지내고 싶은데 넌 아닌가보구나. 응 내가 왜 너랑 잘지내? 알겠어.\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 5 / ✅ (Correct) ---\n",
            "  [Original Text]: 역시 가족이 있어야 오는건가? 우리 가족을 인질로 잡아? 사람이야? 당연하지 얼굴보기 꽤나 힘든데 이렇게라도 볼 수 있어서 얼마나 좋아. 당장 우리가족 살려줘 살려줄게 살려주는 대신에 한 명에 니 장기 하나 어때? 정말 아직도 정신을 못차렸구나 그러니까 내가 여기서 나간거야. 가족들이 죽는걸 눈으로 지켜볼거야? 절대 안돼. 건들면 너넨 내 손에 죽어. 아이고. 그럼 니 장기 가져가게 마 취주사부터 맞자. 풀어주는 조건이야.\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 6 / ✅ (Correct) ---\n",
            "  [Original Text]: 어이 김대리 어딨는데. 과장님 담배 때문에 잠깐 밖에요. 그럼 내가 얘기한 거 다했어. 아직 제가. 안돼면 집에 오늘 안가려고? 과장님 제발요. 그러고도 월급 받는다고. 바로 할게요. 얘기했다. 바로 해놔. 예. 알겠습니다.\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 7 / ❌ (WRONG) ---\n",
            "  [Original Text]: 빌린 돈 당장 갚아 지금 당장은 돈이 없습니다 내일까지 계좌로 오백 보내. 당장 내일까지요? 그 돈을 어디서 구해요 안 보내면 . 시간을 조금만 더 주세요 제가 다음 주까지는 꼭 꼭 구해올게요 . 안 보내면 . 너 콩팥 한 쪽은 무사하지 못할 줄 알아 제발 한 번만 봐주세요 죽기 싫으면 내일 저기 앞 뒷골목에서 보자. 흐읍흐읍 넵\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 8 / ✅ (Correct) ---\n",
            "  [Original Text]: 야 김호준 너 돈 있냐? 나 오늘 피씨방 갈건데 미안한데 나 오늘 학용품 사고 엄마아빠가 용돈 안준지 오래돼서 돈이 없어 구구절절 뭐라는거냐? 너 돈있는거 다알아 빨리내놔 너 내가 만만해 보여? 틈만나면 돈 달라그러고 넌 내가 친구로 안보여? 이 새끼가 뭐라는거야 지금? 그냥 돈만 주면 끝날일을 지금 이렇게 만들어? 너 진짜 그렇게 살지마 내 전재산 다 털어서 줄테니까 이번이 마지막이야 진작 이렇게 해야지 많이 컸다 너? 넌 우리집안 사정 알면 이런 소리 못할거야 내가 니 집안사정 알아야되냐? 난 돈만 있으면돼 넌 진짜. 나쁜놈이야.\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 9 / ✅ (Correct) ---\n",
            "  [Original Text]: 나 어제 남자친구랑 100일이었어. 우와, 축하해! 뭐 했어? 레스토랑 가서 밥 먹고 선물 교환했어. 뭐 받았는데? 목걸이 받았어. 너무 예뻐. 부럽다. 나도 연애하고 싶다. 강아지랑 고양이 중에 뭐가 더 좋아? 나는 강아지. 애교도 많고 산책하는 것도 좋아. 나는 고양이. 시크한 매력이 있어. 고양이는 산책 안 시켜도 돼서 편하겠다. 대신 털이 엄청 빠져. 검은 옷은 입을 생각도 못 해. 장단점이 있네. 그래도 나는 강아지가 더 좋아.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 10 / ✅ (Correct) ---\n",
            "  [Original Text]: 야 내가 배가 고프거든 그래서요 그러니 이 칼 맞기 싫으면 돈을 내놔라 여기 5만원 줄테니까 귀찮게 하지 말고 꺼져 고맙다. 나 일해야 하거든 신경쓰이니까 꺼져 야 좀 더 주면 안되냐 알겠어 5만원 2장이면 됐지 이제 그만 가라 알겠다 고마워 어이가 없네 야 이대로는 아쉬워 좀더 줘\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 11 / ✅ (Correct) ---\n",
            "  [Original Text]: 요즘 길거리에 캐럴이 들리니까 연말 느낌 난다. 그러게. 벌써 12월이라니. 시간이 너무 빨라. 나이 먹기 싫다. 영원히 20대이고 싶어. 인정. 마음만은 아직 10대인데. 우리 내년에도 더 재밌게 놀자. 콜. 하고 싶은 거 다 하고 살자. 나 요즘 너무 덜렁거려서 어제는 회사에 핸드폰을 놓고 와서 남자친구랑 연락이 안 됐잖아. 그래서 엄청 싸웠어. 헐 진짜? 그래서 어떻게 풀었어? 아니. 아직 못 풀었어. 계속 화나 있어. 너무 답답해. 어떡해. 속상하겠다. 내가 대신 사과해줄까? 아니야. 내가 잘못한 거니까 내가 풀어야지. 오늘 저녁에 만나서 진지하게 이야기해보려고. 그래. 잘 풀고 와. 내가 기도할게.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 12 / ✅ (Correct) ---\n",
            "  [Original Text]: 똑바로 서! 최일병! 일병 최치수! 야 너는 너무 고릴라처럼 생겼어 죄송합니다! 너는 고릴라처럼 생겨서 에미도 고릴라 같을 거야 하. 하? 야 개새끼야 너 지금? 한숨? 부모님 욕은 하지 말아주십시오 느검마 고릴라다 이 새끼야 뒤지게 맞아야겠다 고릴라새끼 으악 때리지 마세요!\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 13 / ✅ (Correct) ---\n",
            "  [Original Text]: 나 드디어 운전면허 땄어. 우와, 축하해! 이제 나 데리러 와. 아직은 무서워서 혼자 운전 못 해. 연수 받아야지. 응. 주말마다 아빠한테 배우기로 했어. 좋겠다. 나도 면허 따고 싶다. 오늘 점심은 뭐 먹을까? 어제 회식해서, 속이 너무 안 좋아. 그럼 북엇국 어때? 시원하고 담백해서, 해장에 최고야. 콜. 이 근처에 잘하는 집 알아? 응. 내가 아는 맛집 있는데, 거기 진짜 진국이야. 좋아. 가서 밥 한 그릇 뚝딱 말아먹고 오자. 생각만 해도 속이 풀린다. 빨리 가자.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 14 / ✅ (Correct) ---\n",
            "  [Original Text]: 나 이거 좀 부탁할게 네.? 이거 좀 부탁한다고 이거 제 일이 아닌데. 그니깐 부탁한다고 .그래도 직장상사끼리 돕고 살아야지 안그래.? .네 그래 잘부탁해 .\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 15 / ✅ (Correct) ---\n",
            "  [Original Text]: 다른사람들이 컴플레인하는데 조용히해주세요 너내가 어떤사람인줄알아? 어떤사람 인데요? 건방지네 내가 여기 지역 지주야 어디서 조용히하래 공공장소인데 너무시끄러워 피해가가요 웃기고있네 확그냥 입을 찢어버리다 목소리 낮추시고 진정하세요 야진정? 건방지네 너 여기서 짤라버린다 계속 협박하시면 고소하겠습니다 고소해라 확 죽여버린다\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 16 / ✅ (Correct) ---\n",
            "  [Original Text]: 아니 진짜 너무하세요 야 나도 어쩔수없어 아니 뭐가 어쩔수 없어요 도대체 넌 뭐가 불만이냐? 게임 만드는 회사에 프로그래머가 많이 필요하지 않다니 사실인데 어쩌라고 솔직히 다 유디티그래픽 아티스트를 많이 고용하고 네 그리고 프로그래머는 일부 극소수 엘리트만 고용하고 나머지 재능없는 개발팀은 월급 줄 예산이 없어서 네 그래서요 다 빼버리는 시국인데 즉 니가 더 공부해서 엘리트가 돼서 와 어쩔수없어 그니까 사장님이 말하는 앨리트는 비싼돈 들여 외국에서 공부해오고 온 사람인데 그래 전 지금 제가 처한 현실로는 힘들어요 그리고 프로그래머 무시하나요? 왜 아티스트를 많이 고용해요? 야 니 나랑 친구냐 현실이 그렀다고 게임 조작법은 이젠 계발된 만큼 계발 됐어 그래서 빼는거야 아니 그래도 버그 잡는건 도와줄수 있는데 그래서 기본적으로 앨리트가 하는거고 이젠 게임업계는 그래픽 경쟁이야 아니 진짜 불\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 17 / ✅ (Correct) ---\n",
            "  [Original Text]: 어 여기 우리 담배피는 자린데 할아버지 좀 비키세요 아이고.학생들 담배 피우면 몸에 안 좋아요. 신경 끄세요 할아버지보다는 몸 좋고 건강하니까 아이.참  ⁇ 었을 때 일 좀 열심히 하시지 늙어서 고생하시네요 할아버지한테 그게 무슨말이야. 아 냄새도 나는 거 같고 좀 씻고 다니세요 야 우리는 저렇게 늙지말자 당연하지 저렇게 절대 안 산다 창피하게 그.그만하지 못해 어디 어른 무서운 줄 모르고 . 웃기네 어디 요즘 애들 무서운 줄 모르고 까부세요\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 18 / ✅ (Correct) ---\n",
            "  [Original Text]: 야 일처리 똑바로 하랬지 어쩔 수 없었습니다 저번처럼 어금니 하나 더 뽑혀봐야 정신차리려나? 아닙니다 내가 니네 가족이고 친구고 다 알고있어 네. 특히 길동 아 제발 그사람만은 앞으로 이딴식으로 일하면 니가 아니라 얘부터 잡아다가 손가락 하나씩 부러뜨릴줄알아 정신차려라 네 알겠습니다\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 19 / ✅ (Correct) ---\n",
            "  [Original Text]: 박사원은 일 마무리 마저 하고 점심하도록 해요. 네? 다른 분들은. 다른 분들이아니라 지금 박사원만 마무리가 안됐는데 우리 전체가 점심을 못할 이유가 있나? 아닙니다.근데 저도 다녀와서 마저 하면 안될까요.? 참 사회생활 안해본 거 티내는 건가 지금 박사원이 일이 안끝나서 전체 마무리가 안되는 거라고 생각이 안드는건가요? 죄송합니다. 빨리 끝내보도록 하겠습니다. 일머리가 없으면 노력이라도 해야지. 뺀질거리기만하고. 식사다녀오세요. 어째 인원이 한명 더 늘었는데 일은 배로 더 느려진 것 같네. 쯧. 다들 밥먹으러 갑시다. 오늘 점심은 내가 살게요. .죄송합니다.\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 20 / ✅ (Correct) ---\n",
            "  [Original Text]: 너 옷이 왜 그래? 응? 뭐가 어때서? 아니 진짜 안 어울리고 웃겨. 아 그렇구나.조심할게. 아니 조심할 문제가 아니라 너 센스가 없다고. 그럼 어떻게. 뭘 어떻게 해 그냥 좀 조용히 하고 있어. 2. 미안해. 1. 미안하면 오늘 청소 좀 네가 대신 해줘 2. 나 오늘 학원 있는데.\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 21 / ✅ (Correct) ---\n",
            "  [Original Text]: 어이 거기 뒤뚱거리는 놈 나? 그래 너 여기 뒤뚱거리는 놈이 너밖에 더 있냐? 놀리지마 네 다리가 짧은걸 얘기하는데 뭘 그리 흥분하시고 그래 그 따위로 말하지 말라고 그럼 장애인 새끼라고 불러줄까? 나도 이름 있어 그래그래 이름 있으시구나 자꾸 그렇게 대꾸하지마\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 22 / ❌ (WRONG) ---\n",
            "  [Original Text]: 어허 황금에서 손을 떼시지? 이 녀석 총으로 나를 겨냥하다니 흐흐흐 아쉽지만 우린 여기서 헤어져야겠어 감히 나를 배신하다니! 금을 모조리 넘겨 이봐! 이러고도 무사할 것 같아? 개처럼 네 밑에서 고생한 대가로 이 정도 챙길 수 있잖아? 이런 배은망덕한.! 나라면 그 주둥이를 좀 더 조심해서 놀릴 거야 어서 금을 이리 내! 크윽!\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 23 / ❌ (WRONG) ---\n",
            "  [Original Text]: 와 이옷 좋아 보인다 왜 그래 야 옷 이리로 패스 야 받아라 어서 돌려줘 야 오늘 심심한데 옷농구 어떠냐? 내가 멋지게 나 옷으로 골 넣어볼께 엄마가 사주신 내 소중한 옷이야 어서 돌려줘 야 니옷으로 농구하니까 농구할맛 난다 하하하 제발 돌려줘\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 24 / ✅ (Correct) ---\n",
            "  [Original Text]: 야 나 학원비 내줘라 싫어 왜 돈없어 다음에 갚을게 안돼 그런 비싼 돈이 내가 어딨어 니 돈 많잖아 빨리 왤케 찌질해 그래도 안돼 에휴 병신인가\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 25 / ✅ (Correct) ---\n",
            "  [Original Text]: 네 고객님 무슨 일이신가요? 제가 거기서 장을 봤거든요 네 고객님 근데 고기가 상한것 같네? 아 언제 구매하신거죠? 일주일인가? 모르겠는데? 고객님 영수증은 가져오셨나요? 너네가 찾아봐 얼른 바꿔줘 안바꿔주면 나 여기 누워서 한발자국도 안할거야 고객님 여기서 이러시면 안되세요 뭐라는거니?\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 26 / ✅ (Correct) ---\n",
            "  [Original Text]: 우리 내일 회식 어디서 한대? 삼겹살집에서 한대. 2차는 노래방이고. 헐, 진짜? 나 노래방 가기 싫은데. 나도. 그냥 고기만 먹고 빠질까? 그럴까? 눈치 보이지 않을까? 괜찮아. 우리 말고도 빠지는 사람 많을 거야. 우리 이번 주말에 쇼핑하러 갈래? 좋아. 나 마침 사고 싶었던 옷 있었어. 어디로 갈까? 백화점 갈까, 아울렛 갈까? 아울렛 가자. 세일 많이 하잖아. 콜. 아침 일찍 만나서 출발하자. 응. 내가 차 가지고 갈게.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 27 / ✅ (Correct) ---\n",
            "  [Original Text]: 여보세요? 무슨 볼일이야? 나야. 저번에 얘기한 하청업체 추천. 말해봤어? 뭐? 내가 도와줄 생각 없다고 했잖아. 어쭈 돈 많은 남자랑 재혼해서 명품 줄줄 걸치고 다니더만 왜 나도 덕 좀 보자는데 그건 배알이 꼴리냐? 날 언제 봤다고 그래? 이제 내 뒤도 따라 다녀? 뭐 성주 새 아빠한테 무슨 일 생기면 내가 성주 어딨는지 정돈 알아야 될거 아냐? 성주 새아빠한테 무슨 일이 왜 생겨. 지금 협박하는거야? 협박은 아니지. 니가 자꾸 나 안도와주면 현실이 될건데. 우리 연준씨한테 무슨 일 생기면 너 진짜 가만 안둬. 고소하고 끝까지 쫓아갈거야. 어 어디 한번 해봐. 쫓아오는 꼴 한번 보고나 싶네. 근데. 그 전에 너를 내가 멀쩡히 둘거 같냐? 뭐. 뭐라고? 내가 그렇게 당할것 같아? 나 못 도와줘. 알아서 하라고! 내가 너 죽이고 니 새 남편까지 죽이는 꼴 보기 싫으면 리스트에 이름 올려.\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 28 / ✅ (Correct) ---\n",
            "  [Original Text]: 나 요즘 너무 우울해서 큰일이야. 왜 그래? 무슨 일 있어? 모르겠어. 그냥 다 재미없고 기운도 없어. 병원 가보는 건 어때? 상담이라도 받아봐. 그럴까? 혼자서는 해결이 안 될 것 같아. 응. 전문가의 도움을 받는 게 좋을 것 같아. 아기가 밤에 잠을 안 자. 육아 꿀팁 좀 알려줘. 낮에 많이 놀아줘. 에너지를 다 쓰게 해야 밤에 잘 자. 그리고 자기 전에 목욕시키고, 자장가 불러줘. 다 해봤는데 소용없어. 그냥 안 자. 그럼 어쩔 수 없지. 그냥 네가 포기하고 같이 밤새우는 수밖에. 육아는 정말 힘든 거구나. 새삼 깨닫네.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 29 / ✅ (Correct) ---\n",
            "  [Original Text]: 너 왜 이렇게 눈을 깜빡이냐? 아. 미안해.내가 틱장애가 있어서 틱장애? 어. 아 어쩐지 되게 보기 불편하다 . 말이 심한것같아 응 근데 나는 니 얼굴이 더심한것같아 . 너무하다 친구끼리 나는 틱장애 둔 친구 없어 친구는 니생각이고 알았으면 고개좀 돌려줘 . 알겠어\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 30 / ✅ (Correct) ---\n",
            "  [Original Text]: 야야 비켜봐 .아.응 야 너는 좀 가만히 앉아있어라 .어? 왜그래. 뚱뚱해서 니 덩치로 길 처 막으면 지나가질 못 하잖아 미안해 . 덩치는 소만 해서는 너 여자맞냐 뭐 .? 뭔 남자인 나보다 덩치가 살 좀 빼라 말이 심하잖아 .\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 31 / ✅ (Correct) ---\n",
            "  [Original Text]: 야 넌 월급루팡이야? 죄송합니다. 진짜 일 이따구로 할래? 짤리고 싶니? 아닙니다. 열심히 하겠습니다. 그딴 말만 하고 말이야. 내가 만만하니? 아닙니다. 옆 부서에 니 동기는 잘한다는데 넌 뭐니? 낙하산이야? 아닙니다. 너 내가 계속 지켜본다. 너 내가 회사 아주 불편하게 다니게 한다. 죄송합니다.\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 32 / ✅ (Correct) ---\n",
            "  [Original Text]: 오늘 저녁은 뭐 먹을까? 오랜만에 기름진 거 먹고 싶다. 곱창 어때? 좋아. 곱창 대창 막창 다 시켜서 모둠으로 먹자. 콜. 볶음밥도 잊으면 안 되지. 치즈 듬뿍 넣어서. 당연하지. 생각만 해도 침 고인다. 내가 맛있는 집 아는데 거기로 갈까? 좋아. 오늘 거기 가서 소주 한잔 하면서 제대로 한번 달려보자. 대신 내일 출근 못 한다고 징징거리기 없기. 나 책임 못 져. 이번 주말에 날씨 좋으면 강릉 바다 보러 갈래? 좋아. 가서 커피 거리도 걷고 맛있는 순두부 젤라또도 먹자. 콜. 가서 경포대에서 밤바다 보면서 맥주 한잔하자. 좋은 생각이야. 생각만 해도 너무 낭만적이다. 응. 내가 KTX 예매할게. 너는 숙소 알아봐. 오션뷰로. 알겠어. 우리 이번 주말 강릉에서 제대로 한번 힐링하고 오자. 기대된다.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 33 / ✅ (Correct) ---\n",
            "  [Original Text]: 돈좀있냐 있긴있는데 있는거 다 내놓자 그럼차비만 좀 차비는 걸어가라 넘 멀어요 다른사람한테 빌려라 에? 쳐맞고 갈래? 아니오 여기 있어요\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 34 / ✅ (Correct) ---\n",
            "  [Original Text]: 죽고 싶어 환장했어? 네? 지금 나 치고 갔잖아! 아 죄송해요 제가 실수로 부딪혔나봐요 눈을 어디다 달고 다니는거야? 아 죄송합니다 아씨 어깨뼈라도 분질러진것같아 에? 설마요 내가 지금 거짓말하는 것처럼 보여? 아니요. 그건아닌데 살짝 부딪혔는데.설마 내가 거짓말하는 것같지? 니어깨 조각조각 내줘야 내 심정을 알려나?\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 35 / ✅ (Correct) ---\n",
            "  [Original Text]: 이봐!김수근씨 네.부장님. 이걸 지금 기획안이라고 낸거야! 아다시 해서 올리겠습니다. 입사한 지 얼만데 아직까지 이렇게밖에 못해! 죄송합니다. 다시 하겠습니다. 이래서 지방대 출신들은 이래서 출신이 중요하다니까 어디 지방대 출신따위가.어휴 부장님그래도 말씀이 좀.\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 36 / ✅ (Correct) ---\n",
            "  [Original Text]: 이번 주말에 뭐 할지 안정했으면 나랑 같이 스크린 골프 치러 갈래? 좋아. 안 그래도 요즘 골프 배우고 싶었는데. 재밌겠다. 콜. 가서 시원한 맥주 한잔 하면서 스트레스 확 풀자. 좋은 생각이야. 생각만 해도 너무 신난다. 가서 멋진 자세로 풀 스 ⁇  하는 모습 보여줄게. 기대해. 응. 내가 너의 멋진 모습을 영상으로 남겨줄게. 평생 간직해. 나 요즘 너무 행복해서 세상을 다 가진 기분이야. 매일이 선물 같고 기적 같아. 왜? 무슨 좋은 일 있는데? 얼굴에 행복이라고 대문짝만하게 쓰여있네. 빨리 불어. 응. 드디어 내가 그토록 원하던 회사에 이직하게 됐어. 연봉도 오르고 복지도 더 좋아졌어. 대박. 진짜? 너무 축하해! 정말 고생 많았다. 네가 해낼 줄 알았어. 고마워. 다 네가 옆에서 응원해주고 도와준 덕분이야. 너무 고맙다 친구야. 무슨 소리야. 다 네가 잘나서 그런 거지\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 37 / ✅ (Correct) ---\n",
            "  [Original Text]: 오늘따라 지하철에 사람이 왜 이렇게 많지? 그러게. 낑겨서 숨도 못 쉬겠어. 누가 내 발 밟았어. 너무 아파. 어떡해. 괜찮아? 괜찮아. 다들 먹고살기 힘드네. 그러게. 얼른 내려서 해방되고 싶다. 오늘 저녁은 얼큰한 짬뽕에 탕수육 어때? 좋아. 짬뽕은 곱빼기로 시켜줘. 배고파. 콜. 탕수육은 부먹, 찍먹? 뭐로 할까? 나는 찍먹. 너는? 나도. 그럼 찍먹으로 통일하자. 군만두는 서비스로 주겠지? 당연하지. 내가 단골인데. 빨리 주문하자.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 38 / ❌ (WRONG) ---\n",
            "  [Original Text]: 너 우리누나 좋아하지? 어? 어떻게 알았어? 니가 우리누나 지나갈때마다 음흉한 눈 치켜뜨길래 모를수가 없었지 늘 모든 사람한테 친절하길래 응 우리누나가 못생기고 못난 것들한테도 친절하거든 그게 너라고 딱히 의미 있는건 아니고 아. 그래. 그래서 그런데 니가 우리누나 좋아하는게 불쾌해서 니마음 정리좀해주라 사람 마음이 그렇게 칼로 무자르듯 쉽게 정리되는거 아니잖아 그거야 내 알바아니고 정리얼른해 너 같은 새끼가 우리누나 좋아한다는게 너무 소름끼친다 얼른 정리 안하면 알지? 내성격 모르는 사람 없잖아 우리학년에 나도 어떻게 할지 모르니까 뒤지게 맞기 싫으면 빠른 시일내로 정리해 아. 알겠어\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 39 / ✅ (Correct) ---\n",
            "  [Original Text]: 너 왜 손가락이 네개야? 어? 와 진짜 신기하다 보지마. 아니 신기해서 그래 다들 다섯개잖아 애들아 이거봐 애 손가락이 네개야 어렸을때 사고로 다쳤어 그만해줘 아그래?무슨사고인데? 어? 알아야 우리도조심하지 친구좋다는게 뭐야 좀 알려줘바 하지말아줘. 제발\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 40 / ✅ (Correct) ---\n",
            "  [Original Text]: 안녕하세요 옷이 작아서 환불해주세요 고객님 옷에 얼룩이 있어서 힘들것같습니다 아니 내가 입은게 아니고 옷이 작다고요 입으신흔적이있어서 곤란할거같습니다 아니 야 왜 화나게 하지 슬슬 혈압오르네 안입어봤다고 작다고 환불해줘! 규정상 어렵습니다 너 왜 이렇게 융통성이 없어 그냥 해달라고 장사하기 싫어? 고객님 죄송합니다 일단 진정하세요. 진정? 내가 거짓말쟁이라는거야? 죄송합니다 이번에는 환불 도와드리겠습니다\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 41 / ✅ (Correct) ---\n",
            "  [Original Text]: 안녕 친구들 농구공이네. 농구 좀 할 줄 아나봐? 엇. 네. 친한척해라. 농구하다 가는 길이야? 네. 그럼 목 마르겠다. 음료수 마시려고 슈퍼가는 길이지? 네. 근데 형아들도 목이 좀 마르네. 돈 좀 빌릴 수 있을까? 이거 밖에 없어요. 확실해? 센터까서 더 나오면 10원당 한대야. 정말 이거밖에 없어요. 그래. 나중에 형아가 맛있는거 사줄게. 우유 많이 마시고 키 많이 커라 안녕! 네.\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 42 / ✅ (Correct) ---\n",
            "  [Original Text]: 오늘 저녁은 뭐 먹을까? 오랜만에 삼겹살에 소주 한잔할까? 좋아. 미나리도 같이 구워서 먹으면, 진짜 맛있겠다. 콜. 생각만 해도 침 고인다. 어디로 갈까? 내가 아는 맛집 있는데, 거기 삼겹살이 진짜 신선하고 맛있어. 좋아. 오늘 거기 가서, 제대로 한번 먹어보자. 대신 너무 많이 먹지는 마. 나 다이어트 중이란 말이야. 나 어제 이사했는데 너무 힘들어. 혼자 다 했어? 응. 짐 정리하다가 허리 나가는 줄 알았어. 고생했네. 집들이는 언제 할 거야? 아직 정리 다 안 끝나서. 다음 주쯤? 알겠어. 필요한 거 있으면 말해. 내가 사 갈게.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 43 / ✅ (Correct) ---\n",
            "  [Original Text]: 조용히 살라고 했는데 이새끼가깔짝깔짝건드네? 그러지마.그건 정말 너네가 잘못한거잖아 야 내가 잘못했어도 그걸 니가 뭔데 말해? 뭔데 신고하네 마네야 나쁜일이니까. 니가 경찰이야? 어? 경찰도 아닌새끼가 남의 일에 오지 ⁇ 은 .그래도 그건 아니야 아 이 외골수새끼 입술 부르트도록 쳐맞아도 아직 정신 못차렸네 아 뇌는 아직 터지도록 안맞아서 그러냐? 제발. 여기서 멈춰주면 나도 조용히할게 야 니가 조용히 하는건 하나도 안중요하고 이빨 꽉 깨물어라 안그러면 이 나간다새끼야 제발 그만해.\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 44 / ✅ (Correct) ---\n",
            "  [Original Text]: 탕수육은 부먹이야, 찍먹이야? 나는 무조건 찍먹. 눅눅한 거 싫어. 나는 부먹. 소스가 튀김에 배어들어야 맛있어. 찍먹파는 바삭한 식감을 중요하게 생각한다고. 부먹파는 촉촉한 식감을 중요하게 생각하지. 이건 평생 해결 안 될 논쟁이다. 인정. 그냥 각자 알아서 먹자. 오늘 저녁은 뭐 먹을까? 오랜만에 삼겹살에 소주 한잔할까? 좋아. 미나리도 같이 구워서 먹으면, 진짜 맛있겠다. 콜. 생각만 해도 침 고인다. 어디로 갈까? 내가 아는 맛집 있는데, 거기 삼겹살이 진짜 신선하고 맛있어. 좋아. 오늘 거기 가서, 제대로 한번 먹어보자. 대신 너무 많이 먹지는 마. 나 다이어트 중이란 말이야.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 45 / ✅ (Correct) ---\n",
            "  [Original Text]: 나 이제 이대로 같이 못 살아. 무슨 일이야? 이렇게 거지같은 환경에서 더 이상 살기 싫어. 우리 환경이 어때서? 맨날 술 마시고 아무것도 안하고 이 상황에서 발전 될 생각을 안하잖아. 나중에 다 잘 된다고 했잖아 왜 또 그래. 왜 또? 내가 널 만나서 이렇게 고생하느니 그냥 같이 죽자. 네가 더 미친 거 같은데? 응 나 지금 미쳤어. 그냥 칼로 찔러 죽이고 싶고 지금 모든 상황이 짜증나. 진정해. 진정? 장난하니? 너 일로와 죽여버리게. 미안해. 대화로 풀자.\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 46 / ✅ (Correct) ---\n",
            "  [Original Text]: 민철씨 내일 회의 5시에 있어요? 네? 저 내일 그시간에 시간차 썼는데요? 그럼 취소해 회의가 5시라 어쩔 수가 없네. 저 내일 그 시간에 시골 내려 갑니다. 뭐? 끝나고 내려가 그러 되는거 아니야? 이미 예매 끝난거라 어쩔 수 없습니다. 죄송합니다. 민철씨 입사하자마자 회사에서 잘리고 싶어? 아니요. 그건 아닌데. 정말 사정이 있어서 그럽니다. 죄송합니다. 민철씨 회의가 잡히면 민철씨는 회의에 맞게 시간차도 취소하고 그러는거야 신입은 원래 자유가 없어. 부장님 그건 안될 것 같습니다. 죄송합니다.\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 47 / ✅ (Correct) ---\n",
            "  [Original Text]: 이번주 주말에 회사에 나와야 겠어요 왜요? 사무실 화분을 옮겨야 겠어요 그럼 다른 분에게 부탁 하세요 왜죠 ? 그날은 집안 일이 있어서요 상사 부탁인데요 상사 부탁이여도 어려울것 같습니다 죄송합니다 인정이 없으시네요. 그렇다면 어쩔수 없죠 네 이런 부탁 안하셨으면 합니다\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 48 / ✅ (Correct) ---\n",
            "  [Original Text]: 진짜 열받아서 너 칼로 찌르고 싶다 왜그러세요 . 여기 아무도 못찾는 곳인데 진짜 죽을래? 잘못했어요 넌 진짜 쉽게 죽으면 안돼 고통스럽게 죽이고 싶다 그만하세요 잘못했어요 너가 날 열받게 했으면 나도 해도 되는거 아니야? 앞으로 화나게 안할게요 시끄럽고 한번만 더 그래봐 넌 진짜 죽는다 알겠습니다 죄송합니다\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 49 / ✅ (Correct) ---\n",
            "  [Original Text]: 너 그럴 줄은 몰랐다 갑자기 왜 그러시는 거야? 몰라서 물어? 어떤 이유인지 말씀 해주셔야 알지 칼로 찔려봐야 정신 차릴래? 친구들한테 너가 헛소문 퍼트리고 다닌다매? 그건 사실이자나 그게 왜 사실이야? 너 때문에 나 얼굴도 못들고 다닌다고 미안해. 하지만 별 이유는 없었어 너 죽여버리고 싶어. 사실 나 칼도 가져왔어 미안. 미안해 말로 사람 죽일수 있는거 알지? 칼로 똑같이 죽여줄까? 잘못했어. 일로 오라고 이놈아. 칼로 쑤셔버리겠어\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 50 / ✅ (Correct) ---\n",
            "  [Original Text]: 나 요즘 너무 힘들어서, 그냥 다 놓고, 세계 일주나 떠나고 싶어. 왜 그래? 무슨 일인데? 또 회사에서 무슨 일 있었어? 응. 내가 열심히 준비한 기획안을, 상사가 자기 이름으로 올렸어. 너무 억울하고, 분해. 미친 거 아니야? 가만히 있었어? 응. 어차피 말해도 안 통할 것 같아서. 그냥 내가 회사를 나가는 게 맞는 것 같아. 힘들겠다. 괜찮아. 너의 능력은 다른 곳에서 더 빛을 발할 거야. 내가 더 좋은 회사 알아봐 줄게. 나 어제 친구랑 같이 클럽 갔다가 완전 재밌게 놀았잖아. 헐 진짜? 어땠어? 사람 많았어? 응. 엄청 많았어. 음악도 너무 신나고 스트레스 확 풀리더라. 부럽다. 나도 클럽 가본 지 엄청 오래됐는데. 다음에 같이 가자. 내가 데려가 줄게. 신세계가 펼쳐질 거야. 콜. 나도 오랜만에 한번 흔들어보고 싶다.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 51 / ✅ (Correct) ---\n",
            "  [Original Text]: 나 어제 자기 전에 유튜브로 먹방 ASMR 듣다가 너무 배고파서 결국 야식 시켜 먹었잖아. 헐 진짜? 뭐 먹었는데? 치킨 족발 피자? 아니. 매운 떡볶이에 튀김 순대 어묵 아주 그냥 분식 파티를 했지. 대박. 나도 어제 라면에 김밥 먹었는데. 역시 야식은 분식이 진리야. 인정. 다이어트는 또 내일부터. 오늘까지만 행복하자 우리. 콜. 오늘 저녁은 뭐 먹을까? 벌써부터 고민되네. 이번 주말에 영화나 보러 갈까? 좋아. 뭐 볼까? 요즘 재밌는 거 뭐 있어? 새로 개봉한 히어로 영화 있는데 평점 좋더라. 아, 그거? 나도 보고 싶었는데. 그럼 그거 보자. 내가 예매할게. 알겠어. 팝콘은 내가 살게.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 52 / ✅ (Correct) ---\n",
            "  [Original Text]: 어머어머 효정씨 살찐것좀봐 네? 아니 업무가 편한가? 아니요.그건아닌데 업무가 편하니까 포동포도 살만찌는거아니야? 말씀이 심하세요 아니 귀여워서 하는 말인데 왜이렇게 정색해? .어쨌든 업무가 마냥 편하지는않습니다. 그래?얼굴에 살오르고 번지르르해보이는 것이 아닌데? .가보겠습니다\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 53 / ❌ (WRONG) ---\n",
            "  [Original Text]: 내대신 이번주 행사 진행요원좀 하게 저 저번주에 했는데요 어 아는데 이번주에 한번 더해 돈도 받고 좋잖아 . 이번주는 애랑 약속도 있고 그럼 애랑 같이 나와서 구경하면서 근무서 차량 통제 요원이 어떻게 애랑 같이 구경하나요. 나때는 다 그랫어 요새 직원들은 아주그냥 여려 마음도 여리고 .아 좀 곤란할것같습니다 그래? 그럼 나도 이제부터 자네를 곤란하게 해야겟어 그게 무슨말이세요? 두고보면 알겠지\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 54 / ✅ (Correct) ---\n",
            "  [Original Text]: 오늘 점심은 뭐 먹을지 안정했어. 나는 김치찌개가 먹고 싶은데. 어제도 김치찌개 먹지 않았어? 그랬나? 그럼 오늘은 된장찌개 먹을까? 좋아. 이 근처에 된장찌개 맛집 있잖아. 그래. 거기로 가자. 10년 후의 나는 어떤 모습으로 살고 있을까? 2탄. 나는 내가 좋아하는 일 하면서 돈도 많이 벌고 멋진 커리어 우먼이 되어 있을 것 같아. 결혼은 안 하고 혼자 멋지게 살 거야. 나는 좋은 아빠가 되어 있을 것 같아. 주말마다 아이들이랑 같이 놀아주고 친구 같은 아빠가 될 거야. 부럽다. 나도 나중에는 너처럼 좋은 가정을 꾸리고 싶다는 생각을 해. 너도 할 수 있어. 우리 각자의 자리에서 행복하게 살자. 그리고 10년 후에도 변치 말고 이렇게 만나자. 좋아. 약속. 꼭 이야.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 55 / ✅ (Correct) ---\n",
            "  [Original Text]: 니 누나 엄청 예쁘더라 우리누나 건들지 말아줘. 나 절대 다시 못가. 감사해야지. 옆에 놓고 내 장난감처럼 사용하는거거든 감동이지? 누나 건들지 말아줘 들어갈 바에는 차라리 날 죽여줘. 너도 죽이고 누나도 갖고 제발. 건들지 말아줘 싫은데 괴롭히고 싶은데? 그래 날 죽여줘 그러도 동생만은 건들지 말아줘 부탁이야. 그래 살려줄게 그럼 너 장기 나한테 줘 돈 좀 벌자. 알았어 다 가져가. 가져가면 되잖아.\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 56 / ✅ (Correct) ---\n",
            "  [Original Text]: 야 쟤 또 왔다. 헐. 저 거지새끼 왜 우리 팀 따라다니냐? 그러니까 말이야. 스킬도 없고 캐시템도 못 사면 좀 눈치껏 빠지지. 얘들아 안녕! 나도 같이 팀전에 참여할래. 우리 하는 말 못들었냐? 저리 좀 가라고. 우리는 너같은 거지새끼 싫어. 그러니까 말이야. 게임도 제일 못하고 도움도 안 되면서 진짜 웃겨. 타자라도 좀 빨리 쳐서 기선제압이라도 하던가. 그래도 난 너희랑 놀고싶어서 온 건데. 한번만 같이 하자. 하. 쟤 강퇴해. 말로해서 안 되네. 진짜 멍청한가봐. 그러니까. 너가 방장이니까 쟤 그냥 영구강퇴 시켜.\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 57 / ✅ (Correct) ---\n",
            "  [Original Text]: 첫사랑 이야기 해줘. 내 첫사랑은 고등학교 때 같은 반 짝꿍이었어. 엄청 예쁘고 착했어. 몰래 짝사랑만 하다가 끝났지만. 아련하다. 나는 대학교 때 CC였는데. 결국 헤어졌지만. 그래도 좋은 추억으로 남아있어. 첫사랑은 다 그런 거지, 뭐. 이루어지지 않아서 더 아름다운. 오늘따라 옛날 생각이 나서 어렸을 때 가지고 놀던 공기 꺼내서 해봤는데 하나도 기억 안 나. 헐 진짜? 나 완전 잘하는데. 꺾기 신동이었어. 대박. 나 좀 가르쳐줘. 하나도 못 하겠어. 좋아. 내가 특별히 가르쳐주지. 대신 꿀밤 맞기 내기 할까? 콜. 자신 있다 이거지? 두고 봐. 내가 이길 수도 있어. 허세는. 그냥 꿀밤 맞을 준비나 해.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 58 / ✅ (Correct) ---\n",
            "  [Original Text]: 원후야 매점에서 니 이름으로 외상 달아놨어 ? 왜그래 ? 나는 매점에서 그 물건 안살거야 친구끼리 좀 외상 좀 하자 돈이 정말 없어서 그래 그냥 달라는게 아니라 갚을거야. 저번에도 외상 단거 그냥 내가 계산했잖아. 왜 이렇게 쪼잔하게 굴어 ? 그치만 . 내가 손 좀 봐줘야 정신 차려 ? . 마지막이야\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 59 / ❌ (WRONG) ---\n",
            "  [Original Text]: 어이 아가씨! 저 아세요.? 이쁜데 어디 살아? 저리 가세요. 아 비싸게 굴지 말고. 몸매 죽이는데? 따라오지 마세요! 아 그러지 말고 나 좀 따라와 봐. 재밌는 거 보여줄게. 따라오지 마시라고요! 더럽게 비싸게 구네! 좀 따라오라고! 이거 놔요!\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 60 / ✅ (Correct) ---\n",
            "  [Original Text]: 너의 흑역사는 뭐야? 잊고 싶은 기억 있어? 나 대학교 때 술 마시고 길에서 잔 적 있어. 헐, 진짜? 안 위험했어? 응. 다행히 친구가 발견해서 데려다줬어. 지금 생각해도 너무 창피해. 잊고 싶다. 괜찮아. 누구나 그런 실수 한 번쯤은 해. 너는 사람들이랑 어울리는 거 좋아해 아니면 혼자 있는 거 좋아해? 나는 혼자 있는 거. 기 빨리는 거 싫어. 나는 사람들이랑 어울리는 거. 새로운 사람 만나는 게 재밌어. 부럽다. 나는 낯가림이 심해서 새로운 사람 만나는 게 너무 힘들어. 너도 충분히 매력적인 사람이야. 너무 걱정하지 마. 그냥 너 자신을 보여줘. 알겠어. 노력해볼게. 고마워.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 61 / ✅ (Correct) ---\n",
            "  [Original Text]: 나 요즘 너무 피곤해서 그런지 자꾸 코피가 나. 헐 진짜? 괜찮아? 병원 가봤어? 아니. 그냥 피곤해서 그런 거겠지 하고 넘겼어. 미련하게 굴지 마. 그러다가 큰 병 된다. 내가 같이 가줄게. 내일 당장 가자. 진짜? 고마워. 너밖에 없다 정말. 대신 진료 끝나고 맛있는 거 사줘. 나 소고기 먹고 싶어. 라면은 꼬들면이야, 퍼진면이야? 나는 무조건 꼬들면. 씹는 맛이 있어야지. 나는 퍼진면. 부드럽게 넘어가는 게 좋아. 꼬들면은 설익은 것 같아서 싫어. 퍼진면은 퉁퉁 불어서 맛없잖아. 이것도 취향이 확고하네. 같이 라면 먹을 일은 없겠다.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 62 / ✅ (Correct) ---\n",
            "  [Original Text]: 좋게 좋게 갑시다. 어차피 두개 달린거 하나 없다고 죽는 것도 아니잖아? 왜 이러세요.누구세요. 다 서로서로 좋자고 하는 건데 눈 하나 빠진다고 앞이 안보여? 그런거 아닌데 그냥 순순히 수술합시다. 제가 왜 제눈을 그 사람한테 왜 제 눈까지 내줘야합니까. 이렇게 말하면 서운한데 그 동안 당신이 우리 도움으로 애들 학교보내고 한 거 아닌가? 그건. 당신이 못주겠다고 하면 뭐 이번에 첫째가 고등학교 들어갔다고 했나? 한창 공부할 나이겠네. 아이들은 건들지 마십시오. 공부해야 하는 나이에 눈이 참 중요한데 그렇지? 제발. 이러지마시고 다른 방법을 찾아봐주세요.\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 63 / ✅ (Correct) ---\n",
            "  [Original Text]: 나 어제 소개팅했는데 상대방이 너무 별로라서 중간에 화장실 가는 척하고 그냥 도망쳐 나왔어. 헐 진짜? 어떻게 그랬어? 상대방은 어떡하고. 나도 모르겠어. 그냥 너무 아니다 싶어서 어쩔 수 없었어. 너무 무례했나? 아니야. 잘했어. 그런 사람한테는 그 정도도 사치야. 어떤 사람이었는데? 계속 다리 떨고 음식 쩝쩝거리고 심지어 트림까지 하더라고. 최악이었어. 잘 도망쳤네. 고생했다. 다음에는 좋은 사람 만날 수 있을 거야. 시어머니가 자꾸 연락해서 간섭하시는데, 어떻게 대처해야 할지 모르겠어. 남편한테 말해. 중간에서 남편이 잘 차단해줘야 해. 말했는데, 자기 엄마라서 그런지 별말을 못 하더라고. 그럼 네가 직접 말해야지. 정중하게, 하지만 단호하게. 알겠어. 더 이상은 못 참겠다. 오늘 전화해서 말씀드려야겠어. 잘 생각했어. 네 스트레스가 제일 중요해.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 64 / ✅ (Correct) ---\n",
            "  [Original Text]: 돈 가지고 길동역으로 와 나 돈 없어. 나 지금 너 동생 학원 앞이야 동생은 건드리지마 뭐 너가 안주면 어쩔수없지 니 동생 무슨일 생기면 너 책임이야 가족은 냅둬. 눈 한쪽에 100만원은 받으니까 너 동생으로 돈 퉁칠께 진짜 이번이 빌려주는거 마지막이야.내 동생은 건드리지마 처음부터 그냥 주면 좋았잖냐 진짜 마지막이야 이게.이제는 정말 돈 없어.\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"--- Checking Model Predictions (1 Batch from Validation Set) ---\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "idx_to_class = {\n",
        "    0: '협박 대화', 1: '갈취 대화', 2: '직장 내 괴롭힘 대화',\n",
        "    3: '기타 괴롭힘 대화', 4: '일반 대화'\n",
        "}\n",
        "\n",
        "# 1. 저장된 Best 모델 로드\n",
        "try:\n",
        "    model.load_state_dict(torch.load(model_save_path))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: 저장된 모델({model_save_path})을 찾을 수 없습니다.\")\n",
        "    exit()\n",
        "\n",
        "# 2. 검증 데이터 1배치 가져오기\n",
        "with torch.no_grad():\n",
        "    # iter()로 DataLoader를 반복 가능한 객체로 만들고 next()로 1배치 추출\n",
        "    try:\n",
        "        batch = next(iter(val_loader))\n",
        "    except StopIteration:\n",
        "        print(\"ERROR: valid_loader가 비어있습니다.\")\n",
        "        exit()\n",
        "\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    labels = batch['labels'].to(device)\n",
        "\n",
        "    # 3. 모델 예측 수행\n",
        "    predictions = model(input_ids)\n",
        "    y_pred = predictions.argmax(dim=1) # 예측 클래스 ID (0~4)\n",
        "\n",
        "    # 4. 결과 비교 출력\n",
        "    print(f\"Total {len(labels)} samples in this batch.\\n\")\n",
        "\n",
        "    for i in range(len(labels)):\n",
        "        # 1) input_ids (텐서) -> list -> vocab으로 디코딩\n",
        "        # <pad> 토큰(ID: 0)은 디코딩 시 제외\n",
        "        token_ids = input_ids[i].cpu().tolist()\n",
        "\n",
        "        # 0번(PAD_ID) 토큰을 제외하고 실제 텍스트로 디코딩\n",
        "        # vocab.decode()는 dataset.py의 SentencePieceVocab 객체에 정의되어 있음\n",
        "        # (BOS/EOS/CLS 등 특수 토큰은 vocab.decode()가 알아서 제외함)\n",
        "        text = vocab.decode([tid for tid in token_ids if tid != PAD_IDX])\n",
        "\n",
        "        pred_class_id = y_pred[i].item()\n",
        "        true_class_id = labels[i].item()\n",
        "\n",
        "        # 2) 예측 클래스와 실제 클래스 이름 가져오기\n",
        "        pred_class_name = idx_to_class[pred_class_id]\n",
        "        true_class_name = idx_to_class[true_class_id]\n",
        "\n",
        "        # 3) 결과 출력\n",
        "        is_correct = \"✅ (Correct)\" if pred_class_id == true_class_id else \"❌ (WRONG)\"\n",
        "\n",
        "        print(f\"--- Sample {i+1} / {is_correct} ---\")\n",
        "        print(f\"  [Original Text]: {text}\")\n",
        "        print(f\"  [Model Predict]: {pred_class_name} (ID: {pred_class_id})\")\n",
        "        print(f\"  [Actual Label]:  {true_class_name} (ID: {true_class_id})\")\n",
        "        print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 9. Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "5Y632d0iQDvF"
      },
      "outputs": [],
      "source": [
        "# 4. 테스트 로더용 예측 함수\n",
        "def predict_test(model, iterator, device):\n",
        "    \"\"\"\n",
        "    레이블이 없는 test_loader에 대해 예측을 수행하고\n",
        "    (문장 ID 대신) 인덱스 순서대로 예측 클래스를 반환합니다.\n",
        "    (submission.csv 생성을 위함)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    predictions_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            # test_loader는 'labels'가 없음\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "\n",
        "            # 모델 예측 (logits)\n",
        "            predictions = model(input_ids)\n",
        "\n",
        "            # 가장 확률이 높은 클래스 ID (0~4)\n",
        "            y_pred = predictions.argmax(dim=1)\n",
        "\n",
        "            predictions_list.extend(y_pred.cpu().numpy())\n",
        "\n",
        "    return predictions_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 10. 제출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA59KerENU2Z",
        "outputId": "862658ed-19a0-42d9-d418-825b353515e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Loading best CNN model for test prediction ---\n",
            "ERROR: 저장된 모델(./models/best_model_cnn.pt)을 찾을 수 없습니다.\n"
          ]
        }
      ],
      "source": [
        "# 9. 테스트 데이터 예측 및 제출 파일 생성\n",
        "print(f\"\\n--- Loading best CNN model for test prediction ---\")\n",
        "try:\n",
        "    model.load_state_dict(torch.load(\"/content/best_model_cnn_10.pt\"))\n",
        "\n",
        "    # test_loader로 예측 수행\n",
        "    test_predictions = predict_test(model, test_loader, device)\n",
        "\n",
        "    print(\"Prediction complete. Creating submission file...\")\n",
        "\n",
        "    import pandas as pd\n",
        "    test_df = pd.read_csv(TEST_PATH)\n",
        "\n",
        "    if len(test_df) == len(test_predictions):\n",
        "        submission_df = pd.DataFrame({\n",
        "            'idx': test_df['idx'],\n",
        "            'class': test_predictions # <-- 숫자 ID 리스트를 그대로 사용\n",
        "        })\n",
        "        submission_df.to_csv('submission.csv', index=False)\n",
        "        print(\"submission.csv file created successfully (with numeric IDs).\")\n",
        "    else:\n",
        "        print(f\"ERROR: Mismatch in length. Test DF: {len(test_df)}, Predictions: {len(test_predictions)}\")\n",
        "        print(\"Please check preprocessing logic if it removes test samples.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: 저장된 모델({model_save_path})을 찾을 수 없습니다.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during test prediction: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiDcXT9HuFfC",
        "outputId": "31cbb711-d875-4a78-a40e-d6fce042a13d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 500 entries, 0 to 499\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   idx     500 non-null    object\n",
            " 1   class   500 non-null    int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 7.9+ KB\n"
          ]
        }
      ],
      "source": [
        "sub = pd.read_csv(SUBMIT_PATH)\n",
        "sub.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2vZFgB1Tpjm"
      },
      "source": [
        "# 학습 기록\n",
        "1차 시도:  \n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.286\n",
        "  -> Best Validation F1 (Macro) at Best Loss: 0.889\n",
        "============================================================\n",
        "```\n",
        "<br>\n",
        "\n",
        "2차 시도:\n",
        "- L2 정칙화 추가  \n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.333\n",
        "  -> Best Validation F1 (Macro) at Best Loss: 0.888\n",
        "============================================================\n",
        "```\n",
        "loss 크게 증가함. -> 다시 빼자  \n",
        "<br>\n",
        "\n",
        "3차 시도:  \n",
        "- 정칙화 다시 제거\n",
        "- N_FILTERS = 64 (128 -> 64)\n",
        "- EMBED_DIM = 128 (256 -> 128)  \n",
        "모델 크기 줄임\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.313\n",
        "  -> Best Validation F1 (Macro) at Best Loss: 0.886\n",
        "============================================================\n",
        "```\n",
        "<br>\n",
        "\n",
        "4차 시도:  \n",
        "- vocab_size = 1300 (1500 -> 1300)\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.294\n",
        "  -> Best Validation F1 (Macro) at Best Loss: 0.887\n",
        "============================================================\n",
        "```\n",
        "<br>\n",
        "\n",
        "5차 시도:\n",
        "- N_FILTERS = 128 (원상복구)\n",
        "- EMBED_DIM = 256 (원상복구)\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.300\n",
        "  -> Best Validation F1 (Macro) at Best Loss: 0.890\n",
        "============================================================\n",
        "```\n",
        "다 비슷비슷한데,,, 지금까진 모두 얼리스탑했으니 학습률 조정하고 에포크 늘려보자.  \n",
        "<br>\n",
        "\n",
        "6차 시도:  \n",
        "- 평가 방법 변경 (f1 -> Acc)\n",
        "- lr = 0.0001 (0.001 -> 0.0001)\n",
        "- epochs = 500 (30 -> 500)\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.239\n",
        "  -> Best Validation Acc at Best Loss: 91.21%\n",
        "============================================================\n",
        "```\n",
        "45 epoch에서 early stop  \n",
        "<br>\n",
        "\n",
        "7차 시도:  \n",
        "- FILTER_SIZES = [2, 3, 4, 5]   \n",
        "    ([3, 4, 5] -> [2, 3, 4, 5])\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.233\n",
        "  -> Best Validation Acc at Best Loss: 91.80%\n",
        "============================================================\n",
        "```\n",
        "57 epoch에서 early stop  \n",
        "<br>\n",
        "\n",
        "8차 시도:  \n",
        "- dropout = 0.3 (0.5 -> 0.3)\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.237\n",
        "  -> Best Validation Acc at Best Loss: 91.02%\n",
        "============================================================\n",
        "```\n",
        "늘려서 다시 해보자  \n",
        "<br>\n",
        "\n",
        "9차 시도:  \n",
        "- dropout = 0.7 (0.3 -> 0.7)\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.241\n",
        "  -> Best Validation Acc at Best Loss: 91.14%\n",
        "============================================================\n",
        "```\n",
        "큰 차이 없어 보임.  \n",
        "<br>\n",
        "\n",
        "10차 시도:  \n",
        "- lr 줄였으니 L2 정칙화 다시 시도  \n",
        "- 라고 하려고 했으나 지금까지 정칙화 계속 적용하고 있었음;;  \n",
        "- 이번엔 없애서 해보자  \n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.222\n",
        "  -> Best Validation Acc at Best Loss: 92.90%\n",
        "============================================================\n",
        "```\n",
        "ridge 없애니 확실히 올랐음.  \n",
        "<br>\n",
        "\n",
        "11차 시도:  \n",
        "- 다시 모델 크기 줄여보기\n",
        "- N_FILTERS = 64 (128 -> 64)\n",
        "- EMBED_DIM = 128 (256 -> 128)  \n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.276\n",
        "  -> Best Validation Acc at Best Loss: 90.29%\n",
        "============================================================\n",
        "```\n",
        "  \n",
        "<br>\n",
        "\n",
        "12차 시도:  \n",
        "- N_FILTERS = 256 (64 -> 256)\n",
        "- EMBED_DIM = 512 (128 -> 512)  \n",
        "-> 파라미터 250만개\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.230\n",
        "  -> Best Validation Acc at Best Loss: 92.58%\n",
        "============================================================\n",
        "```\n",
        "좋긴 한데,, 학습률 더 낮춰보자  \n",
        "<br>\n",
        "\n",
        "13차 시도:  \n",
        "- lr = 1e-5 (0.0001 -> 1e-5)\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.290\n",
        "  -> Best Validation Acc at Best Loss: 90.15%\n",
        "============================================================\n",
        "```\n",
        "의미 없는 듯 하다.  \n",
        "<br>\n",
        "\n",
        "\n",
        "1D CNN 선택 이유:  \n",
        "- 협박, 갈취 등 자극적인 대화는 \"죽어\", \"내놔\" 같은 짧은 키워드로 구분될 가능성이 높다고 생각했다.  \n",
        "- 따라서 n-gram 방식을 사용하며 국소적인 패턴을 감지하는 데 좋은 성능을 보이는 1d CNN을 선택했다.  \n",
        "- 또한, 구조가 다른 모델에 비해 단순해서 학습에 걸리는 시간이 상대적으로 짧다.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
