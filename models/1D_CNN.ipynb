{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymkKuxN0LUvC",
        "outputId": "2c34df95-ed70-459a-d4fa-2913b0c0648d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WinError 3] 지정된 경로를 찾을 수 없습니다: '/content/drive/MyDrive/Colab Notebooks/아이펠/DLthon_pepero_day'\n",
            "c:\\Users\\suhol\\workspace\\aiffel_prac\\dlthon\\DLthon_pepero_day\\models\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/Colab Notebooks/아이펠/DLthon_pepero_day\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jTAIhMYLMxg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "현재 작업 디렉토리: c:\\Users\\suhol\\workspace\\aiffel_prac\\dlthon\\DLthon_pepero_day\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import sys, os\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "# 현재 파일이 상위의 루트 디렉토리로 이동시킨 것으로 인식하게 하도록...\n",
        "# 이렇게 하면 경로 수정 필요 없음\n",
        "if os.path.basename(os.getcwd()) == 'models':\n",
        "    os.chdir('..')\n",
        "print(\"현재 작업 디렉토리:\", Path.cwd())\n",
        "\n",
        "# 프로젝트 내 폴더에서 함수 로드\n",
        "from dataset import DKTCDataset, collate_fn, create_dataloaders\n",
        "\n",
        "# 디바이스 설정\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxezvJsYMFlk"
      },
      "source": [
        "# 1. 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "kR_ZDzNaB20H"
      },
      "outputs": [],
      "source": [
        "class CNNClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    1D CNN 기반 텍스트 분류 모델\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 vocab_size,      # 어휘 사전의 크기 (vocab 객체로부터 받음)\n",
        "                 embed_dim,       # 임베딩 벡터의 차원\n",
        "                 num_classes,     # 분류할 클래스의 개수 (5)\n",
        "                 num_filters,     # 각 필터 크기별 컨볼루션 필터의 수\n",
        "                 filter_sizes,    # 사용할 컨볼루션 필터의 크기\n",
        "                 dropout_prob):   # 드롭아웃 확률\n",
        "\n",
        "        super(CNNClassifier, self).__init__()\n",
        "\n",
        "        # 1. 임베딩 레이어\n",
        "        # padding_idx=0: <PAD> 토큰은 0 벡터로 임베딩하고 학습하지 않음\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "\n",
        "        # 2. 1D Convolution 레이어들 (다른 커널 크기를 사용)\n",
        "        # filter_sizes 개수만큼의 Conv1d 레이어를 ModuleList로 생성\n",
        "        # Conv1d는 (batch_size, in_channels, seq_len)을 입력으로 받음\n",
        "        # 우리 임베딩은 (batch_size, seq_len, embed_dim)이므로, permute(0, 2, 1) 필요\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels=embed_dim,\n",
        "                      out_channels=num_filters,\n",
        "                      kernel_size=k) # n-gram 크기\n",
        "            for k in filter_sizes\n",
        "        ])\n",
        "\n",
        "        # 3. 드롭아웃\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "        # 4. FC 레이어 (분류기)\n",
        "        # 각 필터에서 하나씩의 피처(max-pooling)가 나오므로,\n",
        "        # 총 num_filters * len(filter_sizes) 개의 피처가 입력됨\n",
        "        self.fc = nn.Linear(num_filters * len(filter_sizes), num_classes)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        \"\"\"\n",
        "        모델의 순전파 로직\n",
        "\n",
        "        Args:\n",
        "            input_ids (torch.Tensor): (batch_size, seq_len)\n",
        "                                     dataset.py에 의해 seq_len은 max_length-1이 됨\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: (batch_size, num_classes)\n",
        "                          각 클래스에 대한 logits\n",
        "        \"\"\"\n",
        "\n",
        "        # 1. 임베딩\n",
        "        # input_ids: (batch_size, seq_len)\n",
        "        # embedded: (batch_size, seq_len, embed_dim)\n",
        "        embedded = self.embedding(input_ids)\n",
        "\n",
        "        # 2. Conv1d 입력을 위해 차원 변경\n",
        "        # embedded: (batch_size, embed_dim, seq_len)\n",
        "        embedded = embedded.permute(0, 2, 1)\n",
        "\n",
        "        # 3. 컨볼루션 + ReLU\n",
        "        # conved: (batch_size, num_filters, new_seq_len)\n",
        "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
        "\n",
        "        # 4. Max pooling\n",
        "        # F.max_pool1d(conv, conv.shape[2])는 (batch_size, num_filters, 1)을 반환\n",
        "        # .squeeze(2)를 통해 (batch_size, num_filters)로 만듦\n",
        "        # pooled: [ (batch_size, num_filters), (batch_size, num_filters), ... ]\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "\n",
        "        # 5. 피처 결합 (Concatenate)\n",
        "        # catted: (batch_size, num_filters * len(filter_sizes))\n",
        "        catted = torch.cat(pooled, dim=1)\n",
        "\n",
        "        # 6. 드롭아웃\n",
        "        dropped = self.dropout(catted)\n",
        "\n",
        "        # 7. 완전 연결 레이어 (분류)\n",
        "        # logits: (batch_size, num_classes)\n",
        "        logits = self.fc(dropped)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Helper 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "RPonn9uFOmrB"
      },
      "outputs": [],
      "source": [
        "# 1. 헬퍼 함수 정의\n",
        "def count_parameters(model):\n",
        "    \"\"\"학습 가능한 파라미터 수 계산\"\"\"\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    \"\"\"에폭 소요 시간 계산\"\"\"\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "def calculate_accuracy(preds, y_true):\n",
        "    \"\"\"\n",
        "    Accuracy 계산 함수\n",
        "    logits(preds)를 받아서 argmax로 예측 클래스를 추출\n",
        "    \"\"\"\n",
        "    y_pred = preds.argmax(dim=1) # (batch_size, num_classes) -> (batch_size)\n",
        "    correct = (y_pred == y_true).float() # True/False를 1.0/0.0으로\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc.item() # Python float 값으로 반환"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. train 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "IRJHeKfWPGDx"
      },
      "outputs": [],
      "source": [
        "# 3. 평가 함수 정의\n",
        "def evaluate(model, iterator, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            predictions = model(input_ids)\n",
        "            loss = criterion(predictions, labels)\n",
        "\n",
        "            # Accuracy 계산\n",
        "            acc = calculate_accuracy(predictions, labels)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "XGu6CyOjOqQ7"
      },
      "outputs": [],
      "source": [
        "# 2. 훈련 함수 정의\n",
        "def train(model, iterator, optimizer, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "        # 1. 배치 데이터를 device로 이동\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # 2. 그래디언트 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 3. 순전파\n",
        "        # input_ids: (batch_size, seq_len)\n",
        "        # predictions (logits): (batch_size, num_classes)\n",
        "        predictions = model(input_ids)\n",
        "\n",
        "        # 4. 손실 계산\n",
        "        loss = criterion(predictions, labels)\n",
        "\n",
        "        # 5. Accuracy 계산\n",
        "        acc = calculate_accuracy(predictions, labels)\n",
        "\n",
        "        # 6. 역전파\n",
        "        loss.backward()\n",
        "\n",
        "        # 7. 그래디언트 클리핑\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        # 8. 가중치 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 9. 누적\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc\n",
        "\n",
        "    # 평균 손실과 평균 acc 반환\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. 하이퍼파라미터 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN_PATH = './Data/aiffel-dl-thon-dktc-online-15/train.csv'\n",
        "TEST_PATH = './Data/aiffel-dl-thon-dktc-online-15/test.csv'\n",
        "SUBMIT_PATH = \"./Data/aiffel-dl-thon-dktc-online-15/submission.csv\"\n",
        "BEST_MODEL_PATH = './models/best_model_cnn.pt'\n",
        "VOCAB_SIZE = 1300\n",
        "MAX_LENGTH = 400\n",
        "BATCH_SIZE = 64\n",
        "VALID_RATIO = 0.1 # 훈련 데이터 중 10%를 검증용으로 사용\n",
        "\n",
        "INPUT_DIM = 1320\n",
        "EMBED_DIM = 256\n",
        "NUM_CLASSES = 5\n",
        "N_FILTERS = 128\n",
        "FILTER_SIZES = [2, 3, 4, 5]\n",
        "DROPOUT_PROB = 0.5\n",
        "\n",
        "N_EPOCHS = 500\n",
        "PATIENCE = 10\n",
        "\n",
        "LEARNING_RATE = 0.00005"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. 데이터 로더 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQDQOusDVGKy",
        "outputId": "e652d27a-710a-4aa9-b585-949e85214cac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Loading data...\n",
            "\n",
            "Loading data...\n",
            "==================================================\n",
            "데이터 로드 및 전처리 중...\n",
            "==================================================\n",
            "Train 데이터: 4950 개의 conversation\n",
            "Test 데이터: 500 개의 conversation\n",
            "\n",
            "샘플 데이터:\n",
            "Conversation: 지금 너 스스로를 죽여달라고 애원하는 것인가? 아닙니다. 죄송합니다. 죽을 거면 혼자 죽지 우리까지 사건에 휘말리게 해? 진짜 죽여버리고 싶게. 정말 잘못했습니다. 너가 선택해. 너가 죽을래 네 가족을 죽여줄까. 죄송합니다. 정말 잘못했습니다. 너에게는 선택권이 없어. 선택 못한다면 너와 네 가족까지 모조리 죽여버릴거야. 선택 못하겠습니다. 한번만 도와주세요. 그냥 다 죽여버려야겠군. 이의 없지? 제발 도와주세요.\n",
            "Label: 0\n",
            "\n",
            "Conversation: 길동경찰서입니다. 9시 40분 마트에 폭발물을 설치할거다. 네? 똑바로 들어 한번만 더 얘기한다. 장난전화 걸지 마시죠. 9시 40분 마트에 폭발물이 터지면 다 죽는거야. 장난전화는 업무방해죄에 해당됩니다. 판단은 너에게 달려있다. 길동경찰서에도 폭발물 터지면 꽤나 재미있겠지. 선생님 진정하세요. 난 이야기했어. 경고했다는 말이야.\n",
            "Label: 0\n",
            "\n",
            "Conversation: 너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어. 그만해. 니들 놀리는거 재미없어. 지영아 너가 키 160이지? 그럼 재는 160도 안돼는거네? 너 군대도 안가고 좋겠다. 니들이 나 작은데 보태준거 있냐? 난쟁이들도 장가가고하던데. 너도 희망을 가져봐 더이상 하지마라. 그 키크는 수술도 있대잖아? 니네 엄마는 그거 안해주디? 나람 해줬어. 저 키로 어찌살아. 제발 그만 괴롭히라고!\n",
            "Label: 3\n",
            "\n",
            "==================================================\n",
            "SentencePiece 모델 학습 중...\n",
            "==================================================\n",
            "\n",
            "모델 저장됨: ./configs/sentences.model\n",
            "Vocab 크기: 1300\n",
            "\n",
            "Train DataLoader 준비 완료: 총 4455개 conversations\n",
            "Validation DataLoader 준비 완료: 총 495개 conversations\n",
            "Test DataLoader 준비 완료: 총 500개 conversations.\n"
          ]
        }
      ],
      "source": [
        "# 1. 데이터 로더 준비\n",
        "print(\"\\nLoading data...\")\n",
        "\n",
        "\n",
        "# 2. 데이터 로더 생성\n",
        "print(\"\\nLoading data...\")\n",
        "try:\n",
        "    # create_dataloaders는 훈련/테스트 로더와 vocab을 반환\n",
        "    train_loader, val_loader, test_loader, vocab = create_dataloaders(\n",
        "        TRAIN_PATH, TEST_PATH,\n",
        "        vocab_size=VOCAB_SIZE,\n",
        "        max_length=MAX_LENGTH,\n",
        "        batch_size=BATCH_SIZE\n",
        "    )\n",
        "    PAD_IDX = vocab.PAD_ID # collate_fn에 사용\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"=\"*50)\n",
        "    print(\"ERROR: 데이터 파일(train.csv/test.csv)을 찾을 수 없습니다.\")\n",
        "    print(\"TRAIN_PATH와 TEST_PATH를 실제 파일 경로로 수정해주세요.\")\n",
        "    print(\"=\"*50)\n",
        "    exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYnfXaxdtoVq"
      },
      "source": [
        "# 6. 모델 선언"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Initializing 1D CNN model...\n",
            "The model has 799,749 trainable parameters.\n"
          ]
        }
      ],
      "source": [
        "# 5. 모델 하이퍼파라미터 및 초기화\n",
        "print(\"\\nInitializing 1D CNN model...\")\n",
        "\n",
        "model = CNNClassifier(\n",
        "    vocab_size=INPUT_DIM,\n",
        "    embed_dim=EMBED_DIM,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    num_filters=N_FILTERS,\n",
        "    filter_sizes=FILTER_SIZES,\n",
        "    dropout_prob=DROPOUT_PROB\n",
        ").to(device)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7. loss function, optimizer 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ylh9DvwZcA6w",
        "outputId": "3ed83e68-d118-4507-8d67-75749469f468"
      },
      "outputs": [],
      "source": [
        "# 6. 옵티마이저 및 손실 함수 정의\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# 7. 학습 설정\n",
        "best_valid_loss = float('inf')\n",
        "best_valid_acc = 0.0\n",
        "patience_counter = 0\n",
        "model_save_path = BEST_MODEL_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 8. 모델 훈련"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbVE10VqNU0Q",
        "outputId": "d733f500-7785-4f46-ee84-cb9adfc29c1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "--- 1D CNN Model Training starts ---\n",
            "============================================================\n",
            "\n",
            "Epoch: 01 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 1.733 | Train Acc: 26.86%\n",
            "\t Val. Loss: 1.294 |  Val. Acc: 62.47%\n",
            "\t>> Validation loss improved (1.294). Saving model...\n",
            "Epoch: 02 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 1.424 | Train Acc: 41.20%\n",
            "\t Val. Loss: 1.046 |  Val. Acc: 73.44%\n",
            "\t>> Validation loss improved (1.046). Saving model...\n",
            "Epoch: 03 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 1.191 | Train Acc: 52.25%\n",
            "\t Val. Loss: 0.893 |  Val. Acc: 73.90%\n",
            "\t>> Validation loss improved (0.893). Saving model...\n",
            "Epoch: 04 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 1.031 | Train Acc: 58.27%\n",
            "\t Val. Loss: 0.777 |  Val. Acc: 77.49%\n",
            "\t>> Validation loss improved (0.777). Saving model...\n",
            "Epoch: 05 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.931 | Train Acc: 63.82%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 80.03%\n",
            "\t>> Validation loss improved (0.693). Saving model...\n",
            "Epoch: 06 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.831 | Train Acc: 68.39%\n",
            "\t Val. Loss: 0.629 |  Val. Acc: 80.42%\n",
            "\t>> Validation loss improved (0.629). Saving model...\n",
            "Epoch: 07 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.757 | Train Acc: 71.14%\n",
            "\t Val. Loss: 0.582 |  Val. Acc: 80.22%\n",
            "\t>> Validation loss improved (0.582). Saving model...\n",
            "Epoch: 08 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.709 | Train Acc: 74.51%\n",
            "\t Val. Loss: 0.546 |  Val. Acc: 82.44%\n",
            "\t>> Validation loss improved (0.546). Saving model...\n",
            "Epoch: 09 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.660 | Train Acc: 76.41%\n",
            "\t Val. Loss: 0.516 |  Val. Acc: 82.44%\n",
            "\t>> Validation loss improved (0.516). Saving model...\n",
            "Epoch: 10 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.632 | Train Acc: 77.80%\n",
            "\t Val. Loss: 0.494 |  Val. Acc: 82.76%\n",
            "\t>> Validation loss improved (0.494). Saving model...\n",
            "Epoch: 11 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.584 | Train Acc: 78.62%\n",
            "\t Val. Loss: 0.476 |  Val. Acc: 83.42%\n",
            "\t>> Validation loss improved (0.476). Saving model...\n",
            "Epoch: 12 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.551 | Train Acc: 80.20%\n",
            "\t Val. Loss: 0.459 |  Val. Acc: 83.93%\n",
            "\t>> Validation loss improved (0.459). Saving model...\n",
            "Epoch: 13 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.540 | Train Acc: 80.05%\n",
            "\t Val. Loss: 0.444 |  Val. Acc: 85.39%\n",
            "\t>> Validation loss improved (0.444). Saving model...\n",
            "Epoch: 14 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.507 | Train Acc: 81.60%\n",
            "\t Val. Loss: 0.430 |  Val. Acc: 85.58%\n",
            "\t>> Validation loss improved (0.430). Saving model...\n",
            "Epoch: 15 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.493 | Train Acc: 82.58%\n",
            "\t Val. Loss: 0.422 |  Val. Acc: 85.44%\n",
            "\t>> Validation loss improved (0.422). Saving model...\n",
            "Epoch: 16 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.474 | Train Acc: 82.87%\n",
            "\t Val. Loss: 0.410 |  Val. Acc: 86.17%\n",
            "\t>> Validation loss improved (0.410). Saving model...\n",
            "Epoch: 17 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.461 | Train Acc: 83.69%\n",
            "\t Val. Loss: 0.401 |  Val. Acc: 85.97%\n",
            "\t>> Validation loss improved (0.401). Saving model...\n",
            "Epoch: 18 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.456 | Train Acc: 84.14%\n",
            "\t Val. Loss: 0.396 |  Val. Acc: 86.88%\n",
            "\t>> Validation loss improved (0.396). Saving model...\n",
            "Epoch: 19 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.429 | Train Acc: 84.93%\n",
            "\t Val. Loss: 0.387 |  Val. Acc: 86.69%\n",
            "\t>> Validation loss improved (0.387). Saving model...\n",
            "Epoch: 20 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.425 | Train Acc: 84.77%\n",
            "\t Val. Loss: 0.380 |  Val. Acc: 86.95%\n",
            "\t>> Validation loss improved (0.380). Saving model...\n",
            "Epoch: 21 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.410 | Train Acc: 85.21%\n",
            "\t Val. Loss: 0.377 |  Val. Acc: 87.27%\n",
            "\t>> Validation loss improved (0.377). Saving model...\n",
            "Epoch: 22 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.394 | Train Acc: 86.65%\n",
            "\t Val. Loss: 0.369 |  Val. Acc: 87.15%\n",
            "\t>> Validation loss improved (0.369). Saving model...\n",
            "Epoch: 23 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.379 | Train Acc: 86.53%\n",
            "\t Val. Loss: 0.361 |  Val. Acc: 87.54%\n",
            "\t>> Validation loss improved (0.361). Saving model...\n",
            "Epoch: 24 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.371 | Train Acc: 87.37%\n",
            "\t Val. Loss: 0.361 |  Val. Acc: 87.93%\n",
            "\t>> Validation loss improved (0.361). Saving model...\n",
            "Epoch: 25 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.354 | Train Acc: 87.42%\n",
            "\t Val. Loss: 0.354 |  Val. Acc: 88.32%\n",
            "\t>> Validation loss improved (0.354). Saving model...\n",
            "Epoch: 26 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.349 | Train Acc: 87.63%\n",
            "\t Val. Loss: 0.351 |  Val. Acc: 87.86%\n",
            "\t>> Validation loss improved (0.351). Saving model...\n",
            "Epoch: 27 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.359 | Train Acc: 87.50%\n",
            "\t Val. Loss: 0.349 |  Val. Acc: 87.47%\n",
            "\t>> Validation loss improved (0.349). Saving model...\n",
            "Epoch: 28 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.336 | Train Acc: 88.34%\n",
            "\t Val. Loss: 0.341 |  Val. Acc: 88.12%\n",
            "\t>> Validation loss improved (0.341). Saving model...\n",
            "Epoch: 29 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.331 | Train Acc: 88.80%\n",
            "\t Val. Loss: 0.340 |  Val. Acc: 88.71%\n",
            "\t>> Validation loss improved (0.340). Saving model...\n",
            "Epoch: 30 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.325 | Train Acc: 89.00%\n",
            "\t Val. Loss: 0.334 |  Val. Acc: 88.51%\n",
            "\t>> Validation loss improved (0.334). Saving model...\n",
            "Epoch: 31 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.305 | Train Acc: 89.59%\n",
            "\t Val. Loss: 0.330 |  Val. Acc: 88.05%\n",
            "\t>> Validation loss improved (0.330). Saving model...\n",
            "Epoch: 32 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.313 | Train Acc: 89.30%\n",
            "\t Val. Loss: 0.329 |  Val. Acc: 88.25%\n",
            "\t>> Validation loss improved (0.329). Saving model...\n",
            "Epoch: 33 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.290 | Train Acc: 90.33%\n",
            "\t Val. Loss: 0.326 |  Val. Acc: 88.05%\n",
            "\t>> Validation loss improved (0.326). Saving model...\n",
            "Epoch: 34 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.293 | Train Acc: 90.22%\n",
            "\t Val. Loss: 0.321 |  Val. Acc: 88.25%\n",
            "\t>> Validation loss improved (0.321). Saving model...\n",
            "Epoch: 35 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.279 | Train Acc: 90.89%\n",
            "\t Val. Loss: 0.317 |  Val. Acc: 89.17%\n",
            "\t>> Validation loss improved (0.317). Saving model...\n",
            "Epoch: 36 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.272 | Train Acc: 90.54%\n",
            "\t Val. Loss: 0.316 |  Val. Acc: 88.83%\n",
            "\t>> Validation loss improved (0.316). Saving model...\n",
            "Epoch: 37 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.268 | Train Acc: 91.33%\n",
            "\t Val. Loss: 0.312 |  Val. Acc: 89.03%\n",
            "\t>> Validation loss improved (0.312). Saving model...\n",
            "Epoch: 38 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.265 | Train Acc: 91.59%\n",
            "\t Val. Loss: 0.311 |  Val. Acc: 89.22%\n",
            "\t>> Validation loss improved (0.311). Saving model...\n",
            "Epoch: 39 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.267 | Train Acc: 91.26%\n",
            "\t Val. Loss: 0.309 |  Val. Acc: 89.22%\n",
            "\t>> Validation loss improved (0.309). Saving model...\n",
            "Epoch: 40 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.250 | Train Acc: 91.65%\n",
            "\t Val. Loss: 0.309 |  Val. Acc: 88.44%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 41 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.243 | Train Acc: 91.96%\n",
            "\t Val. Loss: 0.306 |  Val. Acc: 89.03%\n",
            "\t>> Validation loss improved (0.306). Saving model...\n",
            "Epoch: 42 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.234 | Train Acc: 92.36%\n",
            "\t Val. Loss: 0.303 |  Val. Acc: 89.03%\n",
            "\t>> Validation loss improved (0.303). Saving model...\n",
            "Epoch: 43 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.239 | Train Acc: 91.94%\n",
            "\t Val. Loss: 0.303 |  Val. Acc: 88.64%\n",
            "\t>> Validation loss improved (0.303). Saving model...\n",
            "Epoch: 44 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.234 | Train Acc: 92.29%\n",
            "\t Val. Loss: 0.302 |  Val. Acc: 89.22%\n",
            "\t>> Validation loss improved (0.302). Saving model...\n",
            "Epoch: 45 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.230 | Train Acc: 92.68%\n",
            "\t Val. Loss: 0.301 |  Val. Acc: 88.83%\n",
            "\t>> Validation loss improved (0.301). Saving model...\n",
            "Epoch: 46 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.214 | Train Acc: 92.97%\n",
            "\t Val. Loss: 0.295 |  Val. Acc: 89.42%\n",
            "\t>> Validation loss improved (0.295). Saving model...\n",
            "Epoch: 47 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.214 | Train Acc: 92.63%\n",
            "\t Val. Loss: 0.294 |  Val. Acc: 89.62%\n",
            "\t>> Validation loss improved (0.294). Saving model...\n",
            "Epoch: 48 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.209 | Train Acc: 93.27%\n",
            "\t Val. Loss: 0.292 |  Val. Acc: 89.62%\n",
            "\t>> Validation loss improved (0.292). Saving model...\n",
            "Epoch: 49 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.194 | Train Acc: 94.09%\n",
            "\t Val. Loss: 0.293 |  Val. Acc: 89.42%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 50 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.206 | Train Acc: 93.08%\n",
            "\t Val. Loss: 0.291 |  Val. Acc: 89.81%\n",
            "\t>> Validation loss improved (0.291). Saving model...\n",
            "Epoch: 51 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.193 | Train Acc: 93.77%\n",
            "\t Val. Loss: 0.291 |  Val. Acc: 89.30%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 52 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.191 | Train Acc: 93.94%\n",
            "\t Val. Loss: 0.290 |  Val. Acc: 89.22%\n",
            "\t>> Validation loss improved (0.290). Saving model...\n",
            "Epoch: 53 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.183 | Train Acc: 94.42%\n",
            "\t Val. Loss: 0.287 |  Val. Acc: 89.62%\n",
            "\t>> Validation loss improved (0.287). Saving model...\n",
            "Epoch: 54 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.184 | Train Acc: 94.19%\n",
            "\t Val. Loss: 0.289 |  Val. Acc: 89.42%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 55 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.184 | Train Acc: 94.08%\n",
            "\t Val. Loss: 0.287 |  Val. Acc: 89.62%\n",
            "\t>> Validation loss improved (0.287). Saving model...\n",
            "Epoch: 56 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.179 | Train Acc: 94.39%\n",
            "\t Val. Loss: 0.286 |  Val. Acc: 89.62%\n",
            "\t>> Validation loss improved (0.286). Saving model...\n",
            "Epoch: 57 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.178 | Train Acc: 94.17%\n",
            "\t Val. Loss: 0.284 |  Val. Acc: 89.62%\n",
            "\t>> Validation loss improved (0.284). Saving model...\n",
            "Epoch: 58 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.163 | Train Acc: 95.17%\n",
            "\t Val. Loss: 0.282 |  Val. Acc: 90.01%\n",
            "\t>> Validation loss improved (0.282). Saving model...\n",
            "Epoch: 59 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.169 | Train Acc: 94.82%\n",
            "\t Val. Loss: 0.283 |  Val. Acc: 89.62%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 60 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.166 | Train Acc: 94.87%\n",
            "\t Val. Loss: 0.283 |  Val. Acc: 89.62%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 61 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.170 | Train Acc: 94.68%\n",
            "\t Val. Loss: 0.281 |  Val. Acc: 90.01%\n",
            "\t>> Validation loss improved (0.281). Saving model...\n",
            "Epoch: 62 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.159 | Train Acc: 95.01%\n",
            "\t Val. Loss: 0.281 |  Val. Acc: 89.62%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 63 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.160 | Train Acc: 94.85%\n",
            "\t Val. Loss: 0.279 |  Val. Acc: 89.62%\n",
            "\t>> Validation loss improved (0.279). Saving model...\n",
            "Epoch: 64 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.151 | Train Acc: 95.03%\n",
            "\t Val. Loss: 0.282 |  Val. Acc: 89.62%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 65 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.152 | Train Acc: 95.46%\n",
            "\t Val. Loss: 0.278 |  Val. Acc: 89.81%\n",
            "\t>> Validation loss improved (0.278). Saving model...\n",
            "Epoch: 66 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.142 | Train Acc: 95.60%\n",
            "\t Val. Loss: 0.279 |  Val. Acc: 89.03%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 67 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.132 | Train Acc: 96.30%\n",
            "\t Val. Loss: 0.281 |  Val. Acc: 89.42%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 68 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.138 | Train Acc: 95.55%\n",
            "\t Val. Loss: 0.278 |  Val. Acc: 89.42%\n",
            "\t>> Validation loss did not improve. Counter: 3/10\n",
            "Epoch: 69 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.136 | Train Acc: 95.84%\n",
            "\t Val. Loss: 0.282 |  Val. Acc: 88.83%\n",
            "\t>> Validation loss did not improve. Counter: 4/10\n",
            "Epoch: 70 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.129 | Train Acc: 95.98%\n",
            "\t Val. Loss: 0.278 |  Val. Acc: 89.22%\n",
            "\t>> Validation loss did not improve. Counter: 5/10\n",
            "Epoch: 71 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.127 | Train Acc: 96.18%\n",
            "\t Val. Loss: 0.277 |  Val. Acc: 89.62%\n",
            "\t>> Validation loss improved (0.277). Saving model...\n",
            "Epoch: 72 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.126 | Train Acc: 96.12%\n",
            "\t Val. Loss: 0.278 |  Val. Acc: 89.22%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 73 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.123 | Train Acc: 96.11%\n",
            "\t Val. Loss: 0.276 |  Val. Acc: 89.22%\n",
            "\t>> Validation loss improved (0.276). Saving model...\n",
            "Epoch: 74 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.125 | Train Acc: 96.34%\n",
            "\t Val. Loss: 0.275 |  Val. Acc: 89.22%\n",
            "\t>> Validation loss improved (0.275). Saving model...\n",
            "Epoch: 75 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.121 | Train Acc: 96.52%\n",
            "\t Val. Loss: 0.273 |  Val. Acc: 89.22%\n",
            "\t>> Validation loss improved (0.273). Saving model...\n",
            "Epoch: 76 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.118 | Train Acc: 96.57%\n",
            "\t Val. Loss: 0.273 |  Val. Acc: 89.22%\n",
            "\t>> Validation loss improved (0.273). Saving model...\n",
            "Epoch: 77 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.111 | Train Acc: 96.58%\n",
            "\t Val. Loss: 0.274 |  Val. Acc: 89.03%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 78 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.110 | Train Acc: 96.65%\n",
            "\t Val. Loss: 0.275 |  Val. Acc: 89.03%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 79 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.116 | Train Acc: 96.51%\n",
            "\t Val. Loss: 0.272 |  Val. Acc: 89.22%\n",
            "\t>> Validation loss improved (0.272). Saving model...\n",
            "Epoch: 80 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.109 | Train Acc: 96.88%\n",
            "\t Val. Loss: 0.272 |  Val. Acc: 89.22%\n",
            "\t>> Validation loss improved (0.272). Saving model...\n",
            "Epoch: 81 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.108 | Train Acc: 96.89%\n",
            "\t Val. Loss: 0.270 |  Val. Acc: 89.81%\n",
            "\t>> Validation loss improved (0.270). Saving model...\n",
            "Epoch: 82 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.101 | Train Acc: 97.39%\n",
            "\t Val. Loss: 0.272 |  Val. Acc: 89.81%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 83 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.098 | Train Acc: 97.20%\n",
            "\t Val. Loss: 0.272 |  Val. Acc: 89.42%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 84 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.094 | Train Acc: 97.39%\n",
            "\t Val. Loss: 0.271 |  Val. Acc: 89.62%\n",
            "\t>> Validation loss did not improve. Counter: 3/10\n",
            "Epoch: 85 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.093 | Train Acc: 97.37%\n",
            "\t Val. Loss: 0.269 |  Val. Acc: 89.62%\n",
            "\t>> Validation loss improved (0.269). Saving model...\n",
            "Epoch: 86 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.096 | Train Acc: 97.37%\n",
            "\t Val. Loss: 0.271 |  Val. Acc: 89.22%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 87 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.093 | Train Acc: 97.60%\n",
            "\t Val. Loss: 0.267 |  Val. Acc: 89.62%\n",
            "\t>> Validation loss improved (0.267). Saving model...\n",
            "Epoch: 88 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.085 | Train Acc: 97.69%\n",
            "\t Val. Loss: 0.267 |  Val. Acc: 89.62%\n",
            "\t>> Validation loss improved (0.267). Saving model...\n",
            "Epoch: 89 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.088 | Train Acc: 97.26%\n",
            "\t Val. Loss: 0.267 |  Val. Acc: 89.81%\n",
            "\t>> Validation loss improved (0.267). Saving model...\n",
            "Epoch: 90 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.090 | Train Acc: 97.35%\n",
            "\t Val. Loss: 0.268 |  Val. Acc: 89.03%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 91 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.085 | Train Acc: 97.57%\n",
            "\t Val. Loss: 0.266 |  Val. Acc: 89.81%\n",
            "\t>> Validation loss improved (0.266). Saving model...\n",
            "Epoch: 92 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.079 | Train Acc: 98.04%\n",
            "\t Val. Loss: 0.265 |  Val. Acc: 89.81%\n",
            "\t>> Validation loss improved (0.265). Saving model...\n",
            "Epoch: 93 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.081 | Train Acc: 97.79%\n",
            "\t Val. Loss: 0.266 |  Val. Acc: 89.81%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 94 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.074 | Train Acc: 97.99%\n",
            "\t Val. Loss: 0.266 |  Val. Acc: 89.22%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 95 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.077 | Train Acc: 97.72%\n",
            "\t Val. Loss: 0.264 |  Val. Acc: 89.42%\n",
            "\t>> Validation loss improved (0.264). Saving model...\n",
            "Epoch: 96 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.075 | Train Acc: 97.93%\n",
            "\t Val. Loss: 0.266 |  Val. Acc: 89.42%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 97 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.076 | Train Acc: 98.04%\n",
            "\t Val. Loss: 0.266 |  Val. Acc: 89.62%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 98 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.067 | Train Acc: 98.42%\n",
            "\t Val. Loss: 0.266 |  Val. Acc: 89.42%\n",
            "\t>> Validation loss did not improve. Counter: 3/10\n",
            "Epoch: 99 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.074 | Train Acc: 97.89%\n",
            "\t Val. Loss: 0.265 |  Val. Acc: 89.62%\n",
            "\t>> Validation loss did not improve. Counter: 4/10\n",
            "Epoch: 100 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.066 | Train Acc: 98.33%\n",
            "\t Val. Loss: 0.262 |  Val. Acc: 89.81%\n",
            "\t>> Validation loss improved (0.262). Saving model...\n",
            "Epoch: 101 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.064 | Train Acc: 98.44%\n",
            "\t Val. Loss: 0.266 |  Val. Acc: 89.42%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 102 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.072 | Train Acc: 98.04%\n",
            "\t Val. Loss: 0.266 |  Val. Acc: 89.62%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 103 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.067 | Train Acc: 98.17%\n",
            "\t Val. Loss: 0.268 |  Val. Acc: 89.42%\n",
            "\t>> Validation loss did not improve. Counter: 3/10\n",
            "Epoch: 104 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.071 | Train Acc: 98.16%\n",
            "\t Val. Loss: 0.266 |  Val. Acc: 89.42%\n",
            "\t>> Validation loss did not improve. Counter: 4/10\n",
            "Epoch: 105 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.059 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.270 |  Val. Acc: 89.03%\n",
            "\t>> Validation loss did not improve. Counter: 5/10\n",
            "Epoch: 106 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.054 | Train Acc: 98.71%\n",
            "\t Val. Loss: 0.267 |  Val. Acc: 89.42%\n",
            "\t>> Validation loss did not improve. Counter: 6/10\n",
            "Epoch: 107 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.061 | Train Acc: 98.48%\n",
            "\t Val. Loss: 0.266 |  Val. Acc: 89.22%\n",
            "\t>> Validation loss did not improve. Counter: 7/10\n",
            "Epoch: 108 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.060 | Train Acc: 98.42%\n",
            "\t Val. Loss: 0.264 |  Val. Acc: 89.42%\n",
            "\t>> Validation loss did not improve. Counter: 8/10\n",
            "Epoch: 109 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.054 | Train Acc: 98.59%\n",
            "\t Val. Loss: 0.266 |  Val. Acc: 89.42%\n",
            "\t>> Validation loss did not improve. Counter: 9/10\n",
            "Epoch: 110 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.052 | Train Acc: 98.73%\n",
            "\t Val. Loss: 0.266 |  Val. Acc: 89.62%\n",
            "\t>> Validation loss did not improve. Counter: 10/10\n",
            "--- Early stopping triggered after 110 epochs ---\n",
            "\n",
            "============================================================\n",
            "--- Training Finished ---\n",
            "Best Model saved to: ./models/best_model_cnn.pt\n",
            "  -> Best Validation Loss: 0.262\n",
            "  -> Best Validation Acc at Best Loss: 89.81%\n",
            "============================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"--- 1D CNN Model Training starts ---\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "# 8. 학습 루프\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "    valid_loss, valid_acc = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "    # 조기 종료 로직\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        best_valid_acc = valid_acc\n",
        "        torch.save(model.state_dict(), model_save_path)\n",
        "        patience_counter = 0\n",
        "        print(f'\\t>> Validation loss improved ({best_valid_loss:.3f}). Saving model...')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f'\\t>> Validation loss did not improve. Counter: {patience_counter}/{PATIENCE}')\n",
        "\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(f'--- Early stopping triggered after {epoch+1} epochs ---')\n",
        "            break\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"--- Training Finished ---\")\n",
        "print(f\"Best Model saved to: {model_save_path}\")\n",
        "print(f\"  -> Best Validation Loss: {best_valid_loss:.3f}\")\n",
        "print(f\"  -> Best Validation Acc at Best Loss: {best_valid_acc*100:.2f}%\")\n",
        "print(f\"{'='*60}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Hc7t5UzANU4g",
        "outputId": "c0312a72-40e6-4763-8fa3-be5a83e26973"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "--- Checking Model Predictions (1 Batch from Validation Set) ---\n",
            "============================================================\n",
            "\n",
            "Total 64 samples in this batch.\n",
            "\n",
            "--- Sample 1 / ✅ (Correct) ---\n",
            "  [Original Text]: 일을 못하면 말이라도 잘 하던지 죄송합니다 나 때는 이러면 바로 불려갔어 알아? 죄송합니다 요즘 젊은이들은 끈기가 없어 끈기가 열심히 하겠습니다 열심히 말고 잘 하란말야 잘 하겠습니다 아휴 답답해 꺼져 죄송합니다\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 2 / ✅ (Correct) ---\n",
            "  [Original Text]: 야 제발 한번만 봐주라 됐고 이제 그만 만나자 어차피 의미없는 만남 계속 왜 해야 하는데 제발 내가 죽을죄를 졌다고! 너 진짜 안받아주면 죽인다. 아 왜 소리를 지르고 그래 진짜 꺼져 내가 뭘 그렇게 잘못했는데 너 어디야 내가 지금 죽이러 간다. 진짜 다시는 보지 말자 너 새끼야 어디야 어딘지 알면 뭐 어쩌게 미친놈아 이렇게 될 바에 너 죽고 나 죽자. 지금 나 협박 하는거야?\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 3 / ✅ (Correct) ---\n",
            "  [Original Text]: 이번 주말에 뭐 할지 안정했으면 나랑 놀자. 좋아. 뭐 할까? 요즘 유행하는 방 탈출 카페 갈래? 콜. 나 한 번도 안 가봤는데 재밌을 것 같아. 응. 머리 쓰는 거 좋아하잖아. 너한테 딱이야. 좋아. 내가 예약할게. 나 어제 자기 전에 공포영화 봤더니 잠을 설쳤어. 왜 혼자 그런 걸 봐. 호기심에 봤는데 너무 무서웠어. 무슨 영화였는데? 곡성 봤는데 아직도 여운이 남아. 그거 진짜 무섭지. 나도 보고 며칠 동안 고생했어.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 4 / ✅ (Correct) ---\n",
            "  [Original Text]: 안녕? 너희 몇 살이야? 저희 초등학교 6학년이요 돈 있어? 내가 돈이 좀 필요해서 아니. 없어요 돈 있는 거 같은데 있으면 어쩔건데 진짜 없어요 100원 나올때 마다 한 대씩이다 주머니에 지금 천원 한장 이게 다에요 아까는 없다며? 다른 애는 얼마? 저. 2천원이요 또? 더 가져와\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 5 / ✅ (Correct) ---\n",
            "  [Original Text]: 이봐 가만있어 누? 누구세요? 칼에 옆구리 뚫리고 싶지 않으면 움직이지마 제발 가만있을게요 살려만주세요 내가 하라는 대로만 해 네 그럴께요 문열고 조용히 집으로 들어가 네. 그럴께요 살려만 주세요 흑흑 빨리빨리 움직여 네 . 좀만 좀만 기다려주세요\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 6 / ❌ (WRONG) ---\n",
            "  [Original Text]: 오 너가 새로 입사한 애냐? 네 반갑습네다. 제가 이 회사에 새로 취직한 사람입니다. 뭐야 니 말투 왜이래. 저 수령동지 모시는 곳에서 온 말투냐 아 제가 새터민이라고 북에서 남으로 넘어온 사람이라서 그런가봅네다. 많이 남조선말 연습하고 있습네다. 북한에서 탈출했다고? 뭐하러 여기까지 왔냐 우리 먹고 살기도 바쁜데. 이 회사는 무슨 한국 사람들도 실직자 많구만 북한 사람을 채용했냐. 저도 이제 어엿한 남한 사람입네다. 귀화시험까지 다 통과했습네다. 부모님은 다 계시고? 그 뭐냐 위쪽에서 건너올라면 꼭 누구 머리에 총 맞던데 혹시 너도 그랬냐? 부모님은 아니고 할아버지께서 돌아가셨습니다. 근무 선 군인들 똑바로 일 안 했네. 이왕 죽일거 할머니도 죽이면 뭐 할아버지 덜 외로우실텐데 말이 너무 심하십네다. 저희 할아버지 우리 먼저 강 건너게 하시고 돌아가셨단 말입니다. 야 장난이\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 7 / ✅ (Correct) ---\n",
            "  [Original Text]: 이사장님 저한테 그러시면 안돼죠 내가 한번만 더 미안하자 어떻게 저한테 그러실 수 있습니까! 조용히 가자.계속 징징거리면 니 식구들 위험해져 하. 다 니가 자초한 일이다 애초에 내가 깡패 새끼를 믿는게 아니였는데 뭐?이 새끼가 상황 파악 못하고 기어오르네 . 니 가족들도 곱게는 못 보내주겠다.하늘에서 잘 지켜봐라 죄송합니다.제발 가족들은 건들아지 말아주세요\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 8 / ✅ (Correct) ---\n",
            "  [Original Text]: 야 이과장 넵 부르셨습니까 이사님 니가 제출한 서류 봤는데 시발 이게 맞냐? 죄송합니다. 죄송하면 다야 시발? 아닙니다. 서둘러서 다시 해오겠습니다. 그럼 빨리 튀어가서 해야지 뭐하는거야? 넵 알겠습니다. 빨리 가겠습니다. 이런 병신같은 새끼를 봤나 빨리 가 넵.\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 9 / ✅ (Correct) ---\n",
            "  [Original Text]: 정한아 나 오늘 배고파서 그러는데 우리 나가서 밥먹자 급식 진짜 맛이 없는거야 오늘 아 그래? 그러자 근데 너 오늘 돈 가져왔어? 아까 없다고 했던 것 같은데 어 맞아. 돈이 없어. 그래서 그런데 니가 오늘 내 밥값 좀 내줘라. 머? 차라리 돈을 빌려달라고 하지 좀 그렇잖아. 아 미안. 근데 나 돈이 없어서 하루만 니가 내줘라. 나 진짜 파스타 먹고 싶단 말이야. 파스타? 넘 비싸 나 돈 없어. 야 넌 친구가 파스타 먹고 싶다는데 좀 빌려주지 그게 어렵냐 좀 하루만 내주라 다음에 내가 살게 아니. 너 전에도 그러고 지금까지 돈 안 갚았잔아. 야 이번에는 갚는다고 맛있는거 산다니까 그러니까 니가 오늘 사라 마지막이야.\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 10 / ✅ (Correct) ---\n",
            "  [Original Text]: 이봐 안과장 나랑 회식 해야지 앗 부장님 죄송합니다. 어머니가 돌아가셔서 장례식장을 가야. 그래서 가기 싫다는 거야? 아 저 그게 싫다는 거야 좋다는 거야 빨리 말해 아 알겠습니다. 가겠습니다. 그래 그래야지 그게 다 직장 생활이야 그래야 하늘에 계신 어머님이 생활 잘하는 널 보고 좋아하시지\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 11 / ✅ (Correct) ---\n",
            "  [Original Text]: 못본사이 더 예뻐졌다 어디가냐? 아니. 알바가. 갑자기 왜 나타났어? 그냥 너 데리러 가려고 안돼 데려가지마. 그때 나 죽고싶을 정도로 힘들었어. 매일 같이 맞고 살았다고 이번에는 죽은 정도는 아닐거야 가자 싫어 제발. 가서 머할건데 이번에는 진짜로 죽는거야. 아니야 그러지마. 나 진짜 두 번다시 거기 가고싶지 않어. 내 장기도 줬잖아. 장기가 더 필요해졌어. 그러니까 온거지 나도 사람답게 살고 싶어. 그러지마.\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 12 / ✅ (Correct) ---\n",
            "  [Original Text]: 저기 누구에요? 니 길동초등학교 3반이지? 어맞는데 나 병재 친군데 나몰라? 알아왜 내가 지금 배가 너무 고픈데 돈좀빌려줘 돈없어 그리고 내가왜? 돈좀 빌려달라고 맞을래? 진짜없어\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 13 / ✅ (Correct) ---\n",
            "  [Original Text]: 나 요즘 너무 무기력하고 아무것도 하기 싫어. 왜 그래? 번아웃 온 거야? 그런가 봐. 회사 가는 것도 너무 힘들고 주말에도 그냥 누워만 있어. 너무 스트레스 받아서 그런 거 아니야? 여행이라도 다녀와. 그럴까? 혼자 조용히 쉬다 오고 싶다. 좋은 생각이야. 훌쩍 떠나서 푹 쉬고 와. 오늘따라 옛날 생각이 나서 어렸을 때 즐겨하던 포트리스 랑 카트라이더 하고 싶다. 헐 진짜? 아직도 그거 하는 사람이 있어? 완전 고고학적 유물 아니야? 국립중앙박물관에 기증해야 할 것 같은데. 응. 가끔 친구들이랑 PC방 가서 하곤 해. 생각보다 손가락이 기억하고 있더라고. 재밌어. 추억 돋고 짜릿해. 크. 나도 어렸을 때 카트라이더 하다가 아이템 써서 역전승 했을 때 희열 장난 아니었는데. 맞아. 그때는 정말 단순한 게임 하나에도 울고 웃었는데. 그립다 그리워. 그러게. 다시 그때로 돌아가서 친구들이랑 같이 \n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 14 / ✅ (Correct) ---\n",
            "  [Original Text]: 칼 내려 놓으세요 너가 나 무시하고 있잖아 선생님 진정하시고 제 말좀 들어보세요 너 죽여버릴거야 죄송해요 선생님 그래도 이러시면 안돼요 내가 못 할것 같아? 자꾸 이러시면 여기 있는 모두가 위험해져요 팔 하나는 못쓰게 해주겠어 경찰 부르겠습니다 어디 한번 해보시던지\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 15 / ✅ (Correct) ---\n",
            "  [Original Text]: 야 어디가냐 네.? 왜.왜요? 아니 어디가냐구 저 지금 학원가는데요 아 그렇구나 형이 피시방 좀 하려는데 아.네. 근데 저 돈이 없어서. 아 그래? 근데 내가 여기 학원다니는데 오늘 학원비 내던데? 아 학원비는 진짜 안돼요. 이것밖에 없어요. 형도 사람이야 이건 내가 가져간다학원비는 잘내고 네.안녕히 가세요.\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 16 / ✅ (Correct) ---\n",
            "  [Original Text]: 과장님 제가 저번에 빌려드렸던 가방 내일 돌려주실 수 있을까요? 내가 니 봉이야? 왜 명령질이야 아 죄송합니다. 근데 그게 필요해서요. 내가 언제 빌렸다고 그래? 기억도 안나는데 이러심 안돼죠 과장님 안되긴 뭐가 안돼 부탁드립니다 돌려주세요 아니 빌린 기억이 없다니까 과장님 정말 이러실겁니까? 너야 말로 이럴거야? 생사람 잡지말고 가서 일이나 해\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 17 / ✅ (Correct) ---\n",
            "  [Original Text]: 나 어제 소개팅했는데 상대방이 너무 괜찮아서 계속 생각나고 심장이 두근거려서 어제 한숨도 못 잤어. 어떡하지? 오 진짜? 잘됐다! 어떤 점이 그렇게 마음에 들었는데? 빨리 말해봐. 나 너무 궁금해서 현기증 난단 말이야. 심장이 같이 뛰어. 일단 외모가 완전 내 스타일이었고 목소리가 꿀 떨어졌어. 그리고 결정적으로 내가 좋아하는 노래를 알고 있더라고. 같이 불렀잖아. 완전 운명이네. 그래서 다음 약속은 당연히 잡았겠지? 안 잡았으면 너 진짜 인간도 아니다. 아니. 헤어지고 나서 상대방한테 먼저 연락 왔어. 주말에 노래방 가자고. 너무 행복해서 세상을 다 가진 기분이야. 대박. 이건 무조건 결혼해서 애 셋은 낳아야 한다. 내가 사회 봐줄게. 이번에는 진짜 솔로 탈출하는 거야? 너무 부럽다. 배 아파서 병원 가야 할 것 같아. 나 어제 자기 전에, 유튜브로 그것이 알고 싶다 레전드 편 보다가\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 18 / ✅ (Correct) ---\n",
            "  [Original Text]: 나 요즘 너무 게을러져서 큰일이야. 씻는 것도 귀찮고 밥 먹는 것도 귀찮아. 나도. 그냥 하루 종일 침대에 누워서 아무것도 안 하고 싶어. 이러다가 진짜 사회 부적응자 되는 거 아니야? 괜찮아. 가끔은 이런 시간도 필요해. 너무 자책하지 마. 그런가? 그래도 좀 불안하네. 우리 뭐라도 해볼까? 생산적인 거. 싫어. 나는 그냥 쉴래. 너도 그냥 쉬어. 나 요즘 너무 바빠서 정신이 하나도 없어. 왜? 무슨 일 있어? 새로운 프로젝트 시작했는데 일이 너무 많아. 힘들겠다. 밥은 잘 챙겨 먹고 다녀? 아니. 맨날 굶거나 대충 때우고 있어. 그러다 쓰러져. 건강 챙기면서 해.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 19 / ✅ (Correct) ---\n",
            "  [Original Text]: 우리를 배신하면 어떻게 되는지 니가 더 잘 알지 않나? 실수 ? 너는 실수를 목숨을 내놓고 하는구나. 아닙니다. 정말 몰랐습니다. 형님 . 나는 고의든 실수든 우리를 배신하는 애는 사람으로 취급을 안해서 말이야. 제가 어떻게 하면 될까요. 어떻게 하긴. 앞으로 우리를 다신 배신하지 않겠다는 의미로 팔 한쪽만 내놓으면 돼. 네? 그게. 무슨 니가 실수였든 아니든 우릴 배신한 건 맞으니까 다신 그러지 않아야 하잖아? 그렇지만 팔을. 내놓는 다는 건. 못하겠어? 그럼 뭐 다른 데를 내놓겠다는 건가? 살려주십쇼.\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 20 / ✅ (Correct) ---\n",
            "  [Original Text]: 띠로리띠띠로리리 바보래요 바보래요 쟨 그말도 못알아들을걸? 나나. 아알아드들어어! 헐. 진짜 장애인이었구나 말로만 듣던! 병 옮는거 아니야? 더러워 아.아!아니야! 가까이 가지 말자! 균 옮길 것 같아. 저리 꺼져! 장애인 새끼야. 우웩. 역겨운 새끼\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 21 / ✅ (Correct) ---\n",
            "  [Original Text]: 야! 뚱떙이 어제 뭐먹고 잤냐 얼굴이 퉁퉁부어가지고 뚱땡이라고 하지마 뭐? 이뚱땡이가 뭐래니 맞아야 정신차리지? 하지마 야! 뚱떙이 편의점가서 컵라면좀 사와 나 돈없는디 야! 이 뚱떙이가 사오라면 사오지 말이 많아 때리지마 알았어 야! 뚱떙이 삼각김밥도 사와라! 불고기 맛으로. 5분안에 빨리 안튀어오면 1분다 1대다 알겠지? 엉엉엉\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 22 / ✅ (Correct) ---\n",
            "  [Original Text]: 우리자식살려내 못살리면 다 죽여버릴거야 최선을 다 하겠습니다 하지만 지금 위급한 상황이라 장담하긴 어렵습니다 안돼 살려내라고 왜 멀쩡하던애가 이지경이됏는데 너때문이야 보호자님 이러시면 안됩니다 죽여버릴거야 칼을휘두 ⁇ 다\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 23 / ✅ (Correct) ---\n",
            "  [Original Text]: 우리 범생이 돈 얼마 있어? 없어 그럼 돈 나오면 10원에 한대씩?야 뒤져 하지마 오호 필통에 숨겨놨네 내놔 내 돈이야 난 깡패가 아니라 때리진 않아 대신 내일 10배로 가지고와 그럼 용서해줄게 무슨 용서야 돈 없다고 거짓말했잖아 너네 정말 최악이야\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 24 / ✅ (Correct) ---\n",
            "  [Original Text]: 아버지 땅팔아서 제가 돈 드린다니까요 이건 안된다 지금 시세보다 높게 쳐준대요 아무리 그래도 그렇지 정신차리거라 아버지! 이번 기회 놓치면 우리는 계속 이시궁창신세에요 이 시궁창에서도 다 애들 키워내고 살았다 아 제발요 시궁창에서 자란 애들이 뭐 얼마나 깨끗하고 잘자랐겠어요? 정신차려라! 노인네 나이드니 아집만 세져서 제가 가지고 갈테니 그리 아세요 네이놈 안된다!\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 25 / ✅ (Correct) ---\n",
            "  [Original Text]: 이번 주말에 뭐 할지 안정했으면 나랑 같이 쿠킹 클래스 들으러 갈래? 좋아. 안 그래도 요즘 요리에 관심 생겼는데. 재밌겠다. 콜. 가서 맛있는 파스타랑 스테이크 만드는 법 배워오자. 좋은 생각이야. 생각만 해도 너무 설렌다. 가서 예쁘게 만들어서 서로 먹여주자. 로맨틱하게. 응. 내가 너의 멋진 모습을 사진으로 남겨줄게. 평생 간직하도록. 이번 주말에 날씨 좋으면, 서울숲 가서 피크닉 할까? 좋아. 가서 자전거도 타고, 사진도 많이 찍자. 내가 맛있는 김밥이랑 유부초밥 싸갈게. 진짜? 그럼 나는 과일이랑 샌드위치 챙겨갈게. 콜. 돗자리랑 블루투스 스피커도 잊지 말고. 당연하지. 생각만 해도 너무 설렌다. 주말만 기다려져.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 26 / ✅ (Correct) ---\n",
            "  [Original Text]: 길동씨. 길동씨는 회사에 놀러오는거야? 네? 회사 출근하는데 옷차림이 그게 뭐야? 나는 여기가 무슨 술집인줄 알았어 아. 죄송합니다. 그리고 화장은 왜이렇게 진하고? 네? 별거 바르지 않았는데. 회사에 놀러오는거 같잖아? 아니면 누구를 꼬시려고 그러는거야? 과장님 그런거 아니예요. 제가 조심할께요. 길동씨 내가 항상 지켜보는거 알지? 잘좀 합시다. 물흐리지말고 네 죄송합니다\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 27 / ✅ (Correct) ---\n",
            "  [Original Text]: 그래 돈좀 줬겠는데? 아 성적도 잘 나왔다고 좀 좋은걸로 사주셨어 우와 부럽다 야 나도 한번 신어보면 안돼냐? 어?어? 신어보고 편하면 나도 엄마한테 사주라고하게 하.하지만. 왜? 우리 친구아니야? 얼른 줘봐 신어만 보겠다니까 응. 와 이거 정말 편한데? 너는 쭉 신을 테니까 나 일주일만 빌려 신을게 뭐?안돼.돌려줘 고맙다 잘신고 돌려줄게\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 28 / ✅ (Correct) ---\n",
            "  [Original Text]: 김대리 방금 어디갔다왔어요? 화.화장실이요 무슨일이세요? 제가 5분이상 자리 비우지 말랬죠 급하면 보고하고 가랫죠 아. 화장실 자리가 안비어서 기다리느라 늦었습니다 또또또 김대리는 맨날 뭐하느라 늦었다 어째서 이랬다 핑계가 왜이렇게 많아? 내가 김대리 사정까지 봐줘야해? 그건아니지만. 그럼 내가 말하면 그냥 죄송합니다 하고 끝내면 되는거야 토달지말고 . 봐봐 또안하네 너 진자 안되겠다 각오해 .죄송합니다\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 29 / ✅ (Correct) ---\n",
            "  [Original Text]: 야 넌 이런거 하나 제대로못해? 죄송합니다 한국대 나오면 다 일 이딴식으로하냐? 죄송합니다 대가리 딸려서 한국대같은데 나왔으면 노력이라도 해야할꺼아냐? 네 시정하겠습니다 넌 오늘 점심도 먹지마. 네? 너같은건 밥쳐먹을 자격도없어 니 자리 앉아서 반성이나해 사장님.\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 30 / ✅ (Correct) ---\n",
            "  [Original Text]: 오늘따라 일이 너무 하기 싫어서, 몰래 웹툰 보고 있어. 나도. 부장님 눈치 보면서 쇼핑하고 있어. 우리 이러다가 잘리는 거 아니야? 괜찮아. 다들 이러고 살아. 우리만 그런 거 아니야. 그런가? 그래도 좀 불안하네. 걱정 마. 퇴근 시간 2시간 남았다. 조금만 더 버티자. 나 요즘 너무 가난해서 중고 거래로 돈 벌고 있어. 오, 진짜? 뭘 파는데? 안 입는 옷이랑 안 쓰는 화장품. 쏠쏠하게 벌려? 응. 생각보다 잘 팔려서 용돈 벌이 하고 있어. 나도 한번 해볼까? 집에 안 쓰는 거 많은데.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 31 / ✅ (Correct) ---\n",
            "  [Original Text]: 아 냄새 . 응? 무슨냄새? 오빠 .발냄새 너무 심한데 아그래 .? 미안해 일하다 와서 그런가 일 하다 온 건 알겠는데 . 그래도 좀. 냄새가 너무 심하다.좀 양말이라도 갈아신던가 하지 냄새가 심해서 입맛 떨어진다 무슨 말을 그렇게해 . 아니 맞잖아 그건 날 배려안한거잖아 어느정도면 참겠는데 아으. 못 참겠다 너무 냄새난다\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 32 / ✅ (Correct) ---\n",
            "  [Original Text]: 내가 정보 다 가지고 있으니 긴말 안할테니까 돈 인 당 만원씩 내놔 네? 그게 뭔소리죠? 혹시 한번만 설명해주실 수 있나요? 아니 그니까 고객 개인정보를 잘 관리해야지 어떻게 마우스 한 번 딸깍에 고객 정보가 다 들어오냐 횡제야 횡제 아. 지금 고객님들 정보가 또 유출되면 민감한 상황이니 대화로 잘 풀어보는건 어떠신가요? 너가 무슨 심리분석가야? 그냥 돈으로 달라그러면 돈으로 줘 그게. 또 돈으로 드리면 이 상황이 유출되어서 언론에도 나와 기업 신뢰도에도 문제가 생길 수 있을 뿐더러 큰 타격이 올 수 있어서요. 아 그니까 회사의 신뢰도 때문에 고객 개인정보는 유출되도 괜찮다? 그래 잘 이해한거 맞지? 그럼 그냥 내가 다른 브로커한테 넘길게 과연 어떤게 기업 신뢰도에 문제가 갈지 보자고 잠시만요 잠시만요 저희 이제 점차 커가는 기업입니다. 한 순간에 망하게 되면 실직하는 사람도 많고\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 33 / ✅ (Correct) ---\n",
            "  [Original Text]: 대리님 제가 뭐하면 될까요? 생각 해보셨어요? 네? 무슨 생각을. 본인이 뭘해야할지 생각도 안해보고 물어봐요? 그정도 머리도 안되면서 무슨 회사 일을 하겠다고. 죄송합니다. 제가 아직 입사한 지 일주일밖에 안되서. 일주일동안은 생각안하고 뭐했어요? 그럴려고 회사에서 월급 주는 줄 아나. 동기들이랑 떠들 생각하지 말고 업무 생각이나 좀 하세요. 네. 죄송합니다. 정신없이 서있지말고 자리로 가시죠? 머리가 나빠서 이런거까지 다 알려줘야 하나? 아닙니다. 죄송합니다. 저런 애를 무슨 일 시키겠다고 뽑아가지고.\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 34 / ✅ (Correct) ---\n",
            "  [Original Text]: 김대리 임마 너 실수좀 작작해 죄송해요 죄송하다는 말만 하면 끝이니 죄송합니다 나 참.어이가 없네 앞으로 진짜 조심할께요 맨날 같은 소리.그만좀해 죄송합니다 같은 실수 안하겠습니다 한 번만 더 내입에서 똑같은 소리나오게 해봐 네 알겠습니다\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 35 / ✅ (Correct) ---\n",
            "  [Original Text]: 오늘 가서 생육조사 하고 오세요 오늘요? 오늘은 비도 오고 제가 치마를 입고와서 비오는 오다말다 하니까 그냥 나갔다오세요 내일 옷 챙겨와서입고 나갔다오겠습니다 아니 오늘 다녀오라니까? 원래 기준 날짜에서 5일 이내만 하면 되지 않습니까 지금 내말에 토다는거야? 아니 그건아니고 비도 오고 치마입어서 내일 다녀오겠습니다 그렇게 이핑계 저핑계 대니까 여자 직원들이 욕먹는거야 아니.제가 안하겠다고 한것도 아니잖아요. 나는 오늘 나가서 생육 조사 하고 오라니까? 니가 내말에 복종하는지 아는지 볼거야 오늘 안에 가서 해와 비가 오든 치마 입에서 보리잎에 다리가 긁히든 말든. 아주 그냥 요새 직원들은 자기들 편한대로만 하려고한다니까 까라면 까야지\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 36 / ✅ (Correct) ---\n",
            "  [Original Text]: 아니 감자가 왜이렇게짜! 고객님 무슨일이세요 감자가 너무 짜다고 감자가 아니라 소금이야 죄송합니다 고객님. 감자튀김엔 원래 소금이. 아니 고객이 소금이라면 소금이지 무슨 말이많아? 아니 그게 아니라. 그게 아니면 뭐야? 여기 직원 태도가 왜 이따위야 사장나오라그래 고객님. 죄송합니다. 손님이 왕인거 몰라? 죄송합니다 에이씨 너나 먹어 소금같은 감자 죄송합니다.\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 37 / ✅ (Correct) ---\n",
            "  [Original Text]: 안녕하십니까 부장님! 이 번에 승진했지? 앉게나. 네! 감사합니다. 다름이 아니라 지금 우리가 11 면담을 다 진행하고 있는 건 알지? 네. 혹시 회사에 어떤 문제가 생긴 건가요? 문제라면 문제긴 하지.허허. 다름이 아니라 인원이 너무 많아서 줄여야 할 것 같다네. 네? 그럼 혹시 . 이번에 들어오신 분들이. 아니. 우리가 면담을 하는 이유가 그런 이윤데 내가 아무리 생각해도 솔직히 자네가 우리 회사에 그렇게 인재는 아니라고 생각하네. 갑자기 무슨 말씀이신지. 저는 지금까지 잘 해왔다고 자부할 수있고.이번에 승진도. 그야 내가 다 미리 계산하고 있는 동안만은 조금이라도 더 편하라고 그런거고 자네가 받는 돈에 비해 자네가 많이 부족하다고 생각하지않나? 항상 감사하게 생각은 하지만. 이런 이유로 갑자기 제가. 나가야 한다는 말씀이신가요? 자네 발로 나가는 방법 말고도 방법이 있긴하지만 그 동안 정이있으니 이 정\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 38 / ✅ (Correct) ---\n",
            "  [Original Text]: 지은씨 요즘 왜 출근시간이 늦죠? 제가 집이 멀어서. 원래 30분전에 오더니 갑자기 5분전에 오고 어찌됐건 정시에 일만 시작할수있으면 언제오든 되는거아닌가요 사회생활 그렇게 하라고 누가 말했어요? 아니. 30분전에 와도 다른게 없더라고요 나 어이가없네 말대꾸 꼬박꼬박하는거 하며. 이런 신입은 또 첨이네. 말대답.은 아니구요. 내일부터 다시 원래대로 30분전에 와서 세팅해놔요. 일할수있게. 네.\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 39 / ✅ (Correct) ---\n",
            "  [Original Text]: 후라이팬 환불좀 해주세요 네? 고객님 구매는 언제 하셨을까여 구매가 언제한지가 뭐가중요해 환불 규정상. 환불 규정? 내가 쓰다 불편해서 환불해주라는데 무슨 규정? 구매한지 일주일이내 영수증 지참하셔야 이봐 이따위로 불편한 후라이팬 만든 니네 잘못이지 내잘못이야? 고객님. 진정하시고 진정이 되겠어?어? 죄송합니다.\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 40 / ❌ (WRONG) ---\n",
            "  [Original Text]: 승미 매점가서 빵우유사와 빨리 응 근데 돈을줘야 사오지 야 장난하냐.언능사와라 낮기전에 알앗어 어쭈 걸어다니지 미안해. 여기 아놔 딸기우유사오라니깐 흰우유사와 바꿔와라 딸기우유가 없엇어 그럼 쵸코우유로 바꿔와라 알앗어 흑흑\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 41 / ✅ (Correct) ---\n",
            "  [Original Text]: 사장님.잠깐와보시겠어요 네 손님 무슨일이세요 이거 보이시죠 머리카락 엇 손님 정말죄송해요. 음식값은 안받을게요 지금돈안받는가해서 해결할수 잇는게 아니잖아요 그럼어떡해하면 기분이풀리시겠어요 보상을해주셔야죠 손님 그냥 돈 안받고 끝낼려고 했는데요 안되겟어요 뭐라구요 안되겟구만 신고할게요 손님 다 확인햇어요.그리고 나온 머리카락 손님꺼던데요\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 42 / ✅ (Correct) ---\n",
            "  [Original Text]: 야 게이 게이 아니라고 맞잖아 게이새끼야 아 아니야 이새끼 전에 소설 보는거 봤어 아니라고 그냥 소설이었어 존나 같잖네 니가 무슨 소설이야 국어 8등급이 때리지마 때 ⁇ 지뫄 아. 야 게이 어디 가? 야 게이새끼야\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 43 / ✅ (Correct) ---\n",
            "  [Original Text]: 나 어제 지하철에서 어떤 할머니가 무거운 짐을 들고 계시길래 대신 들어드렸는데 너무 고맙다고 하시면서 내 손에 쌈짓돈을 쥐여주셨어. 우와 정말 감동적인 이야기다. 그래서 어떻게 했어? 받았어? 아니. 괜찮다고 한사코 거절했는데 할머니께서 학생 맛있는 거 사 먹어 하시면서 끝까지 주시더라고. 어쩔 수 없이 받았어. 잘했네. 할머니의 따뜻한 마음이잖아. 그 돈으로 뭐 사 먹었어? 아니. 그냥 고이 간직하고 있어. 돈보다 더 큰 의미가 담겨 있는 것 같아서. 볼 때마다 마음이 따뜻해져. 너 정말 멋지다. 나도 너처럼 마음이 따뜻하고 깊은 사람이 되어야겠다고 다짐했어. 존경한다 친구야. 주말에 새로 생긴 파스타 집 가봤어? 아니, 어땠어? 맛있었어? 응, 크림 파스타가 진짜 맛있더라. 소스가 엄청 진하고 고소했어. 와, 진짜? 나 크림 파스타 엄청 좋아하는데! 그럼 너도 꼭 가봐. 웨이팅이\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 44 / ✅ (Correct) ---\n",
            "  [Original Text]: 야 짜식아. 돈가져왔어? 오늘 어머니가 외출 중이야 니 아빠 있잖아? 아빤 출장 가셨어 이 짜식이 거짓말을? 아냐 진짜야 너 주머니랑 가방 뒤져서 돈 나오면 알지? . 이건 뭐야?이 자식이 이건 학급비야. 안돼\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 45 / ✅ (Correct) ---\n",
            "  [Original Text]: 야 너 다음 시간 뭐냐? 나.? 나 다음 시간 화학 너 체육복 있냐? 체육복 .? 응 사물함에 . 나 좀 빌린다 끝나고 꼭 가져다줘야해 .! 아 너 체육복 언제 빨았냐? 나. 지난 시간이 체육 시간이라서 . 어쩐지 아 씨 드러워서 못 입겠다 미. 미안.\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 46 / ✅ (Correct) ---\n",
            "  [Original Text]: 우리 헤어져 뭐라고? 진심이야? 응 이제 못하겠어 너 진짜 나랑 헤어지면 너가 죽든 내가 죽든 한 명은 죽을 각오해 아니 왜그러는데 내가 너랑 헤어지고 싶다는데 안 헤어지면 해결되는거 아니야? 아니 그래도 더이상 너랑 못만나겠다고 그러면 오늘 누구 한 명 죽지 뭐 알았어. 그냥 계속 만나자. 그래야지 자기야 사랑해\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 47 / ✅ (Correct) ---\n",
            "  [Original Text]: 오늘따라 옛날 생각이 나서 어렸을 때 즐겨하던 무궁화 꽃이 피었습니다 랑 얼음 땡 하고 싶다. 헐 진짜? 아직도 그거 하는 사람이 있어? 완전 고인물 놀이 아니야? 응. 가끔 조카랑 놀아주면 하곤 해. 생각보다 동심으로 돌아간 기분이고 재밌어. 크. 나도 어렸을 때 얼음 땡 하다가 넘어져서 무릎 깨진 적 있는데. 맞아. 그때는 정말 해 지는 줄 모르고 놀았는데. 그립다 그리워. 그러게. 다시 그때로 돌아가서 친구들이랑 같이 골목대장 하고 싶다. 이번 주말에 날씨 좋으면, 남산 가서 돈가스 먹을까? 좋아. 케이블카 타고 올라가서, 야경도 보고 오자. 콜. 가서 자물쇠도 걸고 올까? 우리 우정 영원하라고. 좋아. 생각만 해도 너무 로맨틱하다. 근데 우리 둘 다 남자인데, 좀 그렇지 않아? 무슨 상관이야. 우정에도 낭만이 필요해.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 48 / ✅ (Correct) ---\n",
            "  [Original Text]: 아기가 밤에 잠을 안 자. 육아 꿀팁 좀 알려줘. 낮에 많이 놀아줘. 에너지를 다 쓰게 해야 밤에 잘 자. 그리고 자기 전에 목욕시키고, 자장가 불러줘. 다 해봤는데 소용없어. 그냥 안 자. 그럼 어쩔 수 없지. 그냥 네가 포기하고 같이 밤새우는 수밖에. 육아는 정말 힘든 거구나. 새삼 깨닫네. 오늘 저녁은 뭐 먹을까? 오랜만에 제대로 된 집밥 먹고 싶다. 좋아. 내가 맛있는 김치찌개 끓여줄게. 돼지고기 듬뿍 넣고. 콜. 생각만 해도 침 고인다. 그럼 나는 계란말이 해줄게. 치즈 넣어서. 최고의 조합이다. 빨리 집에 가서 준비하자. 응. 오늘 밤은 우리 둘만의 행복한 저녁 식사다.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 49 / ✅ (Correct) ---\n",
            "  [Original Text]: 김 대리 이리 좀 와 봐. 부르셨습니까 과장님. 윽 냄새. 네? 자네는 샤워를 한 달에 한 번밖에 안 하나? 그게 무슨 말씀이신지. 좀 씻고 다니라고. 일 못하면 단정하게도 하고 다녀야지. 죄 죄송합니다. 자네가 이러면 아래 사원이 뭘 보고 배우겠나? 정신 좀 차려. 죄송합니다.\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 50 / ✅ (Correct) ---\n",
            "  [Original Text]: 이번 주말에 데이트 어디서 할까? 날씨도 좋은데 공원 가서 피크닉 할까? 좋아. 내가 도시락 싸갈게. 진짜? 그럼 나는 돗자리랑 음료수 챙겨갈게. 콜. 가서 사진도 많이 찍고 오자. 응. 생각만 해도 설렌다. 너의 단골 맛집은 어디야? 나는 회사 앞에 있는 백반집. 매일 메뉴가 바뀌는데 다 맛있어. 아, 거기? 나도 가끔 가는데. 거기 제육볶음이 진짜 맛있어. 너도 먹어봐. 알겠어. 다음에 가면 제육볶음 먹어봐야겠다.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 51 / ✅ (Correct) ---\n",
            "  [Original Text]: 이거 왜 안 했어? 왜 안했냐니깐 힘들어서요. 힘들다고 안해.? 빨리 해 내일 하면 안될까요? 무슨소리야 얼른해 싫어요. 좋은말로 말 할때 빨리 해 죽여버리기 전에\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 52 / ✅ (Correct) ---\n",
            "  [Original Text]: 아니 머리가 왜 이래? 고객님 제가 그래서 고객님은 곱슬이라 이머리 하면 더 풍성해진다고 말씀드렸어요 아니 그래도 그렇지 이게 사람이야? 푸들이지. .분명 괜찮으시다고 하셨잖아요 아니 괜찮은것도 정도가 있지 이거 나 이대로 못나가 세시간이나 걸렸어요 필요없어 다시 피든가 아니면 고소당할준비해 네? 제가 고소를 당해요? 어 사람 머리가지고 아주 장난질을 했다고 내가 너 고소할거야 아. 그냥 다시 풀어드릴게요 앉으세요 네시간걸려요 얼마가 되든 원상복귀해놔\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 53 / ✅ (Correct) ---\n",
            "  [Original Text]: 박하선 일병 빠졌네 일병 박하선 야 불렀는데 대답안하냐? 죄송합니다 니 맞선임 누구냐? 니위로 내아래로 다 집합! 죄죄죄죄 죄송합니다.그.것만은. 야이 찌발놈아 선임말이 우습냐? 아아.아닙니다 알아먹었으면 빨리 안움직여? 네 알겠습니다!\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 54 / ✅ (Correct) ---\n",
            "  [Original Text]: 우리 이번 주말에 쇼핑하러 갈래? 좋아. 나 마침 사고 싶었던 옷 있었어. 어디로 갈까? 백화점 갈까, 아울렛 갈까? 아울렛 가자. 세일 많이 하잖아. 콜. 아침 일찍 만나서 출발하자. 응. 내가 차 가지고 갈게. 나 요즘 너무 행복해서 불안해. 왜? 좋은 거잖아. 응. 근데 이러다가 또 안 좋은 일 생길까 봐. 미리 걱정하지 마. 지금의 행복을 즐겨. 알겠어. 긍정적으로 생각해야지. 그래. 넌 충분히 행복할 자격 있어.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 55 / ✅ (Correct) ---\n",
            "  [Original Text]: 어이 아저씨 나 만원만 주시면 안될까요? 뭐에다 쓰려구? 그런건 묻지말고 만원만 주세요 버르장머리없는 놈이! 내가 널 뭘 믿고 만원을 주냐? 아씨 담배사게 만원만 달라고요 요즘 어린애들이 무서운줄모르고! 아 좋은말할때 빨리줘라 야 그냥 때려버리자 무무슨말이야 때리다니.! 곱게 줬으면 됐잖아 쫄기는\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 56 / ✅ (Correct) ---\n",
            "  [Original Text]: 김비서 오늘 스케줄 어떻게 되지? 네 오전에 바이어 미팅있고 점심후엔 임원회의 예정 입니다 아니 일말구 김비서 회사 끝나고 뭐하냐고 네? 저야 일끝나고 집에 가야죠 김비서 남자친구는 있어? 네 있습니다 뭐 있어? 쯧쯧 보나마나 능력도 없는 별볼일없는 놈이겠지 착하고 성실한 사람이에요 아무튼 오늘 일끝나고 같이 술이나 한잔하자고 남자친구랑 약속이 있어요 방금전에 일끝나고 집에 간다고 했었잖아 나랑 장난쳐? 네.\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 57 / ✅ (Correct) ---\n",
            "  [Original Text]: 스트레스받을 때 어떻게 풀어? 나는 그냥 잠을 자. 자고 일어나면 좀 괜찮아져. 나는 친구랑 수다 떨어. 속마음 다 털어놓고 나면 후련해져. 그것도 좋은 방법이다. 오늘 나랑 수다 좀 떨어줄래? 당연하지. 무슨 일 있어? 다 말해봐. 고마워. 역시 너밖에 없다. 나 요즘 너무 바빠서 운동할 시간이 없어. 나도. 맨날 야근하니까. 살은 점점 찌고 체력은 떨어지고. 악순환의 반복이야. 우리 그냥 주말에라도 같이 운동할까? 좋아. 공원 가서 배드민턴이라도 치자.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 58 / ❌ (WRONG) ---\n",
            "  [Original Text]: 오늘 왜 빨리 집에 갔어? 맡은 일 다 하고 퇴근시간 다 돼서 갔습니다. 내가 끝나고 집에 같이가자고 했잖아. 왜 나 피하는거야? 회사 동료니 회사에서 보면 되는 것 같습니다. 선배님. 내가 너 좋아하는게 잘못이야? 왜 나를 피하냐고! 그럼 내일 회사에서 뵙겠습니다. 너 자꾸 이러면 회사 게시판에 글 다 뿌린다 네? 무슨 글을요. 글 쓸만한게 없는데요 너 완전 인성쓰레기에 문란하다고 회사 사람들한테 다 폭로할거야 저는 그런 사실이 없는데요. 뭘 폭로한다는 거죠? 사실이든 가짜든 사람들이 그거 구별할거같아? 그리고 너를 믿겠어 나를 믿겠어? 진짜 이러지 마시구요. 직장내 괴롭힘 범죄입니다. 범죄? 웃기네 진짜. 내가 너 일 가르쳐준게 얼만데 나한테 뒷통수를쳐? 평생 승진 못하게 해버린다. 제발 그만하세요. 성추행도 시도하셨잖아요. 자꾸 이러면 인사과에 고발하겠습니다. 뭐 고발? 너 진짜 회사 못다니게\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 59 / ❌ (WRONG) ---\n",
            "  [Original Text]: 그때 빌려간 내 가방 좀 돌려줘 싫은데? 내가 왜? 빌려간 지가 벌써 한 달이야. 내 알 바 아니잖아 부모님이 사주신거란 말이야. 나한테 정말 소중해 그거 내 알바 아니고. 그러게 누가 주제에 안 맞게 이런 비싼 가방 가지고 다니래? 머저리 같은 새끼 제발. 부탁해 어차피 너한테 안 어울리는거 나 주면 안되냐? 큭큭 무.슨 소리야 돌려줘 그냥 나 달라고. 안 주면 네 눈깔 뽑아버린다 뭐? 네 눈깔이랑 네 손모가지 잘려봐야 너가 정신차리지? 누가 갑이고 누가 을인지. 나대지마 머저리 같은 새끼\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 60 / ✅ (Correct) ---\n",
            "  [Original Text]: 야 라면 하나 끓여봐 아 형이 끓여 뭐?이새끼가 미쳐 돌았냐 아 왜 맨나 내가 끓여 정신차려라 뚝배기 깨지고 싶냐? 엄마한테 말한다 말해라 지금 엄마도 없는데 니가 요새 제정신이 아닌 것 같아서 형이 정신 건강 시켜줘야겠다 아하지마. 뭘 하지마 병신새끼가 형한테 개기고 끓여올게\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 61 / ✅ (Correct) ---\n",
            "  [Original Text]: 거기 잠깐만! 예.? 저.저요.? 그래. 내가 돈이 지금 급해서 말이야. 저.저 지금 돈이 없는데요. 하.왜 그래.방금 은행에서 나와놓고. 저.진짜 돈이 없어요. 야.뒤질래.? 네.네.? 빨리 돈 내놓으라고 방금 인출한 20만원 아.안돼요.이 돈만은\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 62 / ✅ (Correct) ---\n",
            "  [Original Text]: 이새끼야 내돈가지고와 한번만 봐주세요 .다음주까지가지고올게요 됏고 이새끼야 야! 다 뒤져 네 어서 못해. 살려주세요 너지금 몇번 ⁇ 지알아. 됏고 너 간이랑 신장내놔 여기도장찍어! 살려쥐세요 제발 야 여기 칼가져와 장기좀빼내자 여기잇읍니다\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 63 / ✅ (Correct) ---\n",
            "  [Original Text]: 어디갔다 와? 회사에 있다가 바로 퇴근했는데 왜 그래? 왜 칼을 들고 있어.? 회사 아니잖아.내가 다 알고 물어보는데 뻔뻔하게 거짓말 하네? 아니야 나 진짜 회사에 있었어. 상사한테 전화해서 물어봐도 좋아. 아니 칼만 내려놓고 이야기하자 제발 나 무서워 아니야.너 그 여자 집에서 있다 왔잖아. 내가 모를 것 같아? 그동안 속아주니 기분이 좋았어? 내가 이렇게 칼까지 들었는데 거짓말 하는 것 보니 아주 뻔뻔하네 아니야 진짜 내가 전화 걸어줄게 회사 누구라도 좋으니까 원하면 내가 전화 걸어서 바꿔줄게 진짜 칼만 내려 놓자 내가 칼드니까 무서운가봐? 내가 너 어떻게 할거 같니?회사사람한테 전화해보라고? 내가 너 회사 사람을 어떻게 믿어? 제발 내 말좀 믿어줘 나 입증할 수 있어. 무서우니까 칼만 내려놓자 내가 왜? 너 구라친거 확인되면 바로 너죽고 나죽고야 난 진짜 너밖에 없어 나 정말 회사 다녀왔어. 정말 이러다가 너도 다쳐\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 64 / ✅ (Correct) ---\n",
            "  [Original Text]: 야야 버스비가 없는데 오천원만 빌려주라 너 저번에도 버스비 빌려간거 안갚았자나. 담주에 알바비 들어오면 갚을게 지난주에도 오늘까지 준다고 했자나 야 내가 큰돈 빌려달라는거도 아니고 쪼잔하게 왜 그러냐 그건 그렇지만. 마지막으로 오천원 좀 빌려줘 알겠어.\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"--- Checking Model Predictions (1 Batch from Validation Set) ---\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "idx_to_class = {\n",
        "    0: '협박 대화', 1: '갈취 대화', 2: '직장 내 괴롭힘 대화',\n",
        "    3: '기타 괴롭힘 대화', 4: '일반 대화'\n",
        "}\n",
        "\n",
        "# 1. 저장된 Best 모델 로드\n",
        "try:\n",
        "    model.load_state_dict(torch.load(model_save_path))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: 저장된 모델({model_save_path})을 찾을 수 없습니다.\")\n",
        "    exit()\n",
        "\n",
        "# 2. 검증 데이터 1배치 가져오기\n",
        "with torch.no_grad():\n",
        "    # iter()로 DataLoader를 반복 가능한 객체로 만들고 next()로 1배치 추출\n",
        "    try:\n",
        "        batch = next(iter(val_loader))\n",
        "    except StopIteration:\n",
        "        print(\"ERROR: valid_loader가 비어있습니다.\")\n",
        "        exit()\n",
        "\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    labels = batch['labels'].to(device)\n",
        "\n",
        "    # 3. 모델 예측 수행\n",
        "    predictions = model(input_ids)\n",
        "    y_pred = predictions.argmax(dim=1) # 예측 클래스 ID (0~4)\n",
        "\n",
        "    # 4. 결과 비교 출력\n",
        "    print(f\"Total {len(labels)} samples in this batch.\\n\")\n",
        "\n",
        "    for i in range(len(labels)):\n",
        "        # 1) input_ids (텐서) -> list -> vocab으로 디코딩\n",
        "        # <pad> 토큰(ID: 0)은 디코딩 시 제외\n",
        "        token_ids = input_ids[i].cpu().tolist()\n",
        "\n",
        "        # 0번(PAD_ID) 토큰을 제외하고 실제 텍스트로 디코딩\n",
        "        # vocab.decode()는 dataset.py의 SentencePieceVocab 객체에 정의되어 있음\n",
        "        # (BOS/EOS/CLS 등 특수 토큰은 vocab.decode()가 알아서 제외함)\n",
        "        text = vocab.decode([tid for tid in token_ids if tid != PAD_IDX])\n",
        "\n",
        "        pred_class_id = y_pred[i].item()\n",
        "        true_class_id = labels[i].item()\n",
        "\n",
        "        # 2) 예측 클래스와 실제 클래스 이름 가져오기\n",
        "        pred_class_name = idx_to_class[pred_class_id]\n",
        "        true_class_name = idx_to_class[true_class_id]\n",
        "\n",
        "        # 3) 결과 출력\n",
        "        is_correct = \"✅ (Correct)\" if pred_class_id == true_class_id else \"❌ (WRONG)\"\n",
        "\n",
        "        print(f\"--- Sample {i+1} / {is_correct} ---\")\n",
        "        print(f\"  [Original Text]: {text}\")\n",
        "        print(f\"  [Model Predict]: {pred_class_name} (ID: {pred_class_id})\")\n",
        "        print(f\"  [Actual Label]:  {true_class_name} (ID: {true_class_id})\")\n",
        "        print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 9. Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "5Y632d0iQDvF"
      },
      "outputs": [],
      "source": [
        "# 4. 테스트 로더용 예측 함수\n",
        "def predict_test(model, iterator, device):\n",
        "    \"\"\"\n",
        "    레이블이 없는 test_loader에 대해 예측을 수행하고\n",
        "    (문장 ID 대신) 인덱스 순서대로 예측 클래스를 반환합니다.\n",
        "    (submission.csv 생성을 위함)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    predictions_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            # test_loader는 'labels'가 없음\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "\n",
        "            # 모델 예측 (logits)\n",
        "            predictions = model(input_ids)\n",
        "\n",
        "            # 가장 확률이 높은 클래스 ID (0~4)\n",
        "            y_pred = predictions.argmax(dim=1)\n",
        "\n",
        "            predictions_list.extend(y_pred.cpu().numpy())\n",
        "\n",
        "    return predictions_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 10. 제출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA59KerENU2Z",
        "outputId": "862658ed-19a0-42d9-d418-825b353515e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Loading best CNN model for test prediction ---\n",
            "ERROR: 저장된 모델(./models/best_model_cnn.pt)을 찾을 수 없습니다.\n"
          ]
        }
      ],
      "source": [
        "# 9. 테스트 데이터 예측 및 제출 파일 생성\n",
        "print(f\"\\n--- Loading best CNN model for test prediction ---\")\n",
        "try:\n",
        "    model.load_state_dict(torch.load(\"/content/best_model_cnn_10.pt\"))\n",
        "\n",
        "    # test_loader로 예측 수행\n",
        "    test_predictions = predict_test(model, test_loader, device)\n",
        "\n",
        "    print(\"Prediction complete. Creating submission file...\")\n",
        "\n",
        "    import pandas as pd\n",
        "    test_df = pd.read_csv(TEST_PATH)\n",
        "\n",
        "    if len(test_df) == len(test_predictions):\n",
        "        submission_df = pd.DataFrame({\n",
        "            'idx': test_df['idx'],\n",
        "            'class': test_predictions # <-- 숫자 ID 리스트를 그대로 사용\n",
        "        })\n",
        "        submission_df.to_csv('submission.csv', index=False)\n",
        "        print(\"submission.csv file created successfully (with numeric IDs).\")\n",
        "    else:\n",
        "        print(f\"ERROR: Mismatch in length. Test DF: {len(test_df)}, Predictions: {len(test_predictions)}\")\n",
        "        print(\"Please check preprocessing logic if it removes test samples.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: 저장된 모델({model_save_path})을 찾을 수 없습니다.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during test prediction: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiDcXT9HuFfC",
        "outputId": "31cbb711-d875-4a78-a40e-d6fce042a13d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 500 entries, 0 to 499\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   idx     500 non-null    object\n",
            " 1   class   500 non-null    int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 7.9+ KB\n"
          ]
        }
      ],
      "source": [
        "sub = pd.read_csv(SUBMIT_PATH)\n",
        "sub.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2vZFgB1Tpjm"
      },
      "source": [
        "# 학습 기록\n",
        "1차 시도:  \n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.286\n",
        "  -> Best Validation F1 (Macro) at Best Loss: 0.889\n",
        "============================================================\n",
        "```\n",
        "<br>\n",
        "\n",
        "2차 시도:\n",
        "- L2 정칙화 추가  \n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.333\n",
        "  -> Best Validation F1 (Macro) at Best Loss: 0.888\n",
        "============================================================\n",
        "```\n",
        "loss 크게 증가함. -> 다시 빼자  \n",
        "<br>\n",
        "\n",
        "3차 시도:  \n",
        "- 정칙화 다시 제거\n",
        "- N_FILTERS = 64 (128 -> 64)\n",
        "- EMBED_DIM = 128 (256 -> 128)  \n",
        "모델 크기 줄임\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.313\n",
        "  -> Best Validation F1 (Macro) at Best Loss: 0.886\n",
        "============================================================\n",
        "```\n",
        "<br>\n",
        "\n",
        "4차 시도:  \n",
        "- vocab_size = 1300 (1500 -> 1300)\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.294\n",
        "  -> Best Validation F1 (Macro) at Best Loss: 0.887\n",
        "============================================================\n",
        "```\n",
        "<br>\n",
        "\n",
        "5차 시도:\n",
        "- N_FILTERS = 128 (원상복구)\n",
        "- EMBED_DIM = 256 (원상복구)\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.300\n",
        "  -> Best Validation F1 (Macro) at Best Loss: 0.890\n",
        "============================================================\n",
        "```\n",
        "다 비슷비슷한데,,, 지금까진 모두 얼리스탑했으니 학습률 조정하고 에포크 늘려보자.  \n",
        "<br>\n",
        "\n",
        "6차 시도:  \n",
        "- 평가 방법 변경 (f1 -> Acc)\n",
        "- lr = 0.0001 (0.001 -> 0.0001)\n",
        "- epochs = 500 (30 -> 500)\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.239\n",
        "  -> Best Validation Acc at Best Loss: 91.21%\n",
        "============================================================\n",
        "```\n",
        "45 epoch에서 early stop  \n",
        "<br>\n",
        "\n",
        "7차 시도:  \n",
        "- FILTER_SIZES = [2, 3, 4, 5]   \n",
        "    ([3, 4, 5] -> [2, 3, 4, 5])\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.233\n",
        "  -> Best Validation Acc at Best Loss: 91.80%\n",
        "============================================================\n",
        "```\n",
        "57 epoch에서 early stop  \n",
        "<br>\n",
        "\n",
        "8차 시도:  \n",
        "- dropout = 0.3 (0.5 -> 0.3)\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.237\n",
        "  -> Best Validation Acc at Best Loss: 91.02%\n",
        "============================================================\n",
        "```\n",
        "늘려서 다시 해보자  \n",
        "<br>\n",
        "\n",
        "9차 시도:  \n",
        "- dropout = 0.7 (0.3 -> 0.7)\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.241\n",
        "  -> Best Validation Acc at Best Loss: 91.14%\n",
        "============================================================\n",
        "```\n",
        "큰 차이 없어 보임.  \n",
        "<br>\n",
        "\n",
        "10차 시도:  \n",
        "- lr 줄였으니 L2 정칙화 다시 시도  \n",
        "- 라고 하려고 했으나 지금까지 정칙화 계속 적용하고 있었음;;  \n",
        "- 이번엔 없애서 해보자  \n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.222\n",
        "  -> Best Validation Acc at Best Loss: 92.90%\n",
        "============================================================\n",
        "```\n",
        "ridge 없애니 확실히 올랐음.  \n",
        "<br>\n",
        "\n",
        "11차 시도:  \n",
        "- 다시 모델 크기 줄여보기\n",
        "- N_FILTERS = 64 (128 -> 64)\n",
        "- EMBED_DIM = 128 (256 -> 128)  \n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.276\n",
        "  -> Best Validation Acc at Best Loss: 90.29%\n",
        "============================================================\n",
        "```\n",
        "  \n",
        "<br>\n",
        "\n",
        "12차 시도:  \n",
        "- N_FILTERS = 256 (64 -> 256)\n",
        "- EMBED_DIM = 512 (128 -> 512)  \n",
        "-> 파라미터 250만개\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.230\n",
        "  -> Best Validation Acc at Best Loss: 92.58%\n",
        "============================================================\n",
        "```\n",
        "좋긴 한데,, 학습률 더 낮춰보자  \n",
        "<br>\n",
        "\n",
        "13차 시도:  \n",
        "- lr = 1e-5 (0.0001 -> 1e-5)\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.290\n",
        "  -> Best Validation Acc at Best Loss: 90.15%\n",
        "============================================================\n",
        "```\n",
        "의미 없는 듯 하다.  \n",
        "<br>\n",
        "\n",
        "\n",
        "1D CNN 선택 이유:  \n",
        "- 협박, 갈취 등 자극적인 대화는 \"죽어\", \"내놔\" 같은 짧은 키워드로 구분될 가능성이 높다고 생각했다.  \n",
        "- 따라서 n-gram 방식을 사용하며 국소적인 패턴을 감지하는 데 좋은 성능을 보이는 1d CNN을 선택했다.  \n",
        "- 또한, 구조가 다른 모델에 비해 단순해서 학습에 걸리는 시간이 상대적으로 짧다.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
