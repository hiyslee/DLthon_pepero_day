{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/Colab Notebooks/아이펠/DLthon_pepero_day\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymkKuxN0LUvC",
        "outputId": "2c34df95-ed70-459a-d4fa-2913b0c0648d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/아이펠/DLthon_pepero_day\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset import DKTCDataset, collate_fn, create_dataloaders\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import time"
      ],
      "metadata": {
        "id": "0jTAIhMYLMxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델, 함수 정의"
      ],
      "metadata": {
        "id": "vxezvJsYMFlk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR_ZDzNaB20H"
      },
      "outputs": [],
      "source": [
        "class CNNClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    1D CNN 기반 텍스트 분류 모델\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 vocab_size,      # 어휘 사전의 크기 (vocab 객체로부터 받음)\n",
        "                 embed_dim,       # 임베딩 벡터의 차원\n",
        "                 num_classes,     # 분류할 클래스의 개수 (5)\n",
        "                 num_filters,     # 각 필터 크기별 컨볼루션 필터의 수\n",
        "                 filter_sizes,    # 사용할 컨볼루션 필터의 크기\n",
        "                 dropout_prob):   # 드롭아웃 확률\n",
        "\n",
        "        super(CNNClassifier, self).__init__()\n",
        "\n",
        "        # 1. 임베딩 레이어\n",
        "        # padding_idx=0: <PAD> 토큰은 0 벡터로 임베딩하고 학습하지 않음\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "\n",
        "        # 2. 1D Convolution 레이어들 (다른 커널 크기를 사용)\n",
        "        # filter_sizes 개수만큼의 Conv1d 레이어를 ModuleList로 생성\n",
        "        # Conv1d는 (batch_size, in_channels, seq_len)을 입력으로 받음\n",
        "        # 우리 임베딩은 (batch_size, seq_len, embed_dim)이므로, permute(0, 2, 1) 필요\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels=embed_dim,\n",
        "                      out_channels=num_filters,\n",
        "                      kernel_size=k) # n-gram 크기\n",
        "            for k in filter_sizes\n",
        "        ])\n",
        "\n",
        "        # 3. 드롭아웃\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "        # 4. FC 레이어 (분류기)\n",
        "        # 각 필터에서 하나씩의 피처(max-pooling)가 나오므로,\n",
        "        # 총 num_filters * len(filter_sizes) 개의 피처가 입력됨\n",
        "        self.fc = nn.Linear(num_filters * len(filter_sizes), num_classes)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        \"\"\"\n",
        "        모델의 순전파 로직\n",
        "\n",
        "        Args:\n",
        "            input_ids (torch.Tensor): (batch_size, seq_len)\n",
        "                                     dataset.py에 의해 seq_len은 max_length-1이 됨\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: (batch_size, num_classes)\n",
        "                          각 클래스에 대한 logits\n",
        "        \"\"\"\n",
        "\n",
        "        # 1. 임베딩\n",
        "        # input_ids: (batch_size, seq_len)\n",
        "        # embedded: (batch_size, seq_len, embed_dim)\n",
        "        embedded = self.embedding(input_ids)\n",
        "\n",
        "        # 2. Conv1d 입력을 위해 차원 변경\n",
        "        # embedded: (batch_size, embed_dim, seq_len)\n",
        "        embedded = embedded.permute(0, 2, 1)\n",
        "\n",
        "        # 3. 컨볼루션 + ReLU\n",
        "        # conved: (batch_size, num_filters, new_seq_len)\n",
        "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
        "\n",
        "        # 4. Max pooling\n",
        "        # F.max_pool1d(conv, conv.shape[2])는 (batch_size, num_filters, 1)을 반환\n",
        "        # .squeeze(2)를 통해 (batch_size, num_filters)로 만듦\n",
        "        # pooled: [ (batch_size, num_filters), (batch_size, num_filters), ... ]\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "\n",
        "        # 5. 피처 결합 (Concatenate)\n",
        "        # catted: (batch_size, num_filters * len(filter_sizes))\n",
        "        catted = torch.cat(pooled, dim=1)\n",
        "\n",
        "        # 6. 드롭아웃\n",
        "        dropped = self.dropout(catted)\n",
        "\n",
        "        # 7. 완전 연결 레이어 (분류)\n",
        "        # logits: (batch_size, num_classes)\n",
        "        logits = self.fc(dropped)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 헬퍼 함수 정의\n",
        "def count_parameters(model):\n",
        "    \"\"\"학습 가능한 파라미터 수 계산\"\"\"\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    \"\"\"에폭 소요 시간 계산\"\"\"\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "def calculate_accuracy(preds, y_true):\n",
        "    \"\"\"\n",
        "    Accuracy 계산 함수\n",
        "    logits(preds)를 받아서 argmax로 예측 클래스를 추출\n",
        "    \"\"\"\n",
        "    y_pred = preds.argmax(dim=1) # (batch_size, num_classes) -> (batch_size)\n",
        "    correct = (y_pred == y_true).float() # True/False를 1.0/0.0으로\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc.item() # Python float 값으로 반환"
      ],
      "metadata": {
        "id": "RPonn9uFOmrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 훈련 함수 정의\n",
        "def train(model, iterator, optimizer, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "        # 1. 배치 데이터를 device로 이동\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # 2. 그래디언트 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 3. 순전파\n",
        "        # input_ids: (batch_size, seq_len)\n",
        "        # predictions (logits): (batch_size, num_classes)\n",
        "        predictions = model(input_ids)\n",
        "\n",
        "        # 4. 손실 계산\n",
        "        loss = criterion(predictions, labels)\n",
        "\n",
        "        # 5. Accuracy 계산\n",
        "        acc = calculate_accuracy(predictions, labels)\n",
        "\n",
        "        # 6. 역전파\n",
        "        loss.backward()\n",
        "\n",
        "        # 7. 그래디언트 클리핑\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        # 8. 가중치 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 9. 누적\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc\n",
        "\n",
        "    # 평균 손실과 평균 acc 반환\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "XGu6CyOjOqQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 평가 함수 정의\n",
        "def evaluate(model, iterator, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            predictions = model(input_ids)\n",
        "            loss = criterion(predictions, labels)\n",
        "\n",
        "            # Accuracy 계산\n",
        "            acc = calculate_accuracy(predictions, labels)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "IRJHeKfWPGDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 테스트 로더용 예측 함수\n",
        "def predict_test(model, iterator, device):\n",
        "    \"\"\"\n",
        "    레이블이 없는 test_loader에 대해 예측을 수행하고\n",
        "    (문장 ID 대신) 인덱스 순서대로 예측 클래스를 반환합니다.\n",
        "    (submission.csv 생성을 위함)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    predictions_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            # test_loader는 'labels'가 없음\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "\n",
        "            # 모델 예측 (logits)\n",
        "            predictions = model(input_ids)\n",
        "\n",
        "            # 가장 확률이 높은 클래스 ID (0~4)\n",
        "            y_pred = predictions.argmax(dim=1)\n",
        "\n",
        "            predictions_list.extend(y_pred.cpu().numpy())\n",
        "\n",
        "    return predictions_list"
      ],
      "metadata": {
        "id": "5Y632d0iQDvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 로드"
      ],
      "metadata": {
        "id": "sjrRv21rtkjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================================\n",
        "# 메인 실행 로직\n",
        "# ==================================================================\n",
        "\n",
        "# 0. GPU 장치 설정\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 1. 데이터 로더 준비\n",
        "print(\"\\nLoading data...\")\n",
        "TRAIN_PATH = './Data/aiffel-dl-thon-dktc-online-15/train.csv'\n",
        "TEST_PATH = './Data/aiffel-dl-thon-dktc-online-15/test.csv'\n",
        "VOCAB_SIZE = 1300\n",
        "MAX_LENGTH = 400\n",
        "BATCH_SIZE = 64\n",
        "VALID_RATIO = 0.1 # 훈련 데이터 중 10%를 검증용으로 사용\n",
        "\n",
        "# 2. 데이터 로더 생성\n",
        "print(\"\\nLoading data...\")\n",
        "try:\n",
        "    # create_dataloaders는 훈련/테스트 로더와 vocab을 반환\n",
        "    _train_loader, test_loader, vocab = create_dataloaders(\n",
        "        TRAIN_PATH, TEST_PATH,\n",
        "        vocab_size=VOCAB_SIZE,\n",
        "        max_length=MAX_LENGTH,\n",
        "        batch_size=BATCH_SIZE\n",
        "    )\n",
        "    PAD_IDX = vocab.PAD_ID # collate_fn에 사용\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"=\"*50)\n",
        "    print(\"ERROR: 데이터 파일(train.csv/test.csv)을 찾을 수 없습니다.\")\n",
        "    print(\"TRAIN_PATH와 TEST_PATH를 실제 파일 경로로 수정해주세요.\")\n",
        "    print(\"=\"*50)\n",
        "    exit()\n",
        "\n",
        "# 3. 훈련/검증 데이터 분리\n",
        "print(\"Splitting train data into train/validation sets...\")\n",
        "\n",
        "# DataLoader에서 원본 Dataset 객체 추출\n",
        "train_dataset = _train_loader.dataset\n",
        "\n",
        "# 데이터셋 크기 계산\n",
        "total_size = len(train_dataset)\n",
        "valid_size = int(total_size * VALID_RATIO)\n",
        "train_size = total_size - valid_size\n",
        "\n",
        "# torch.utils.data.random_split으로 데이터셋 분리\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(\n",
        "    train_dataset, [train_size, valid_size]\n",
        ")\n",
        "\n",
        "print(f\"Total train samples: {total_size}\")\n",
        "print(f\"  -> New Train set: {len(train_dataset)} samples\")\n",
        "print(f\"  -> Validation set: {len(valid_dataset)} samples\")\n",
        "\n",
        "# 4. 분리된 데이터셋으로 DataLoader 재생성\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True, # 훈련 데이터는 셔플\n",
        "    collate_fn=lambda batch: collate_fn(batch, pad_idx=PAD_IDX)\n",
        ")\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False, # 검증 데이터는 셔플 안 함\n",
        "    collate_fn=lambda batch: collate_fn(batch, pad_idx=PAD_IDX)\n",
        ")\n",
        "\n",
        "print(\"\\nData loading and splitting complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQDQOusDVGKy",
        "outputId": "e652d27a-710a-4aa9-b585-949e85214cac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Loading data...\n",
            "\n",
            "Loading data...\n",
            "==================================================\n",
            "데이터 로드 및 전처리 중...\n",
            "==================================================\n",
            "Train 데이터: 4950 개의 conversation\n",
            "Test 데이터: 500 개의 conversation\n",
            "\n",
            "샘플 데이터:\n",
            "Conversation: 지금 너 스스로를 죽여달라고 애원하는 것인가? 아닙니다. 죄송합니다. 죽을 거면 혼자 죽지 우리까지 사건에 휘말리게 해? 진짜 죽여버리고 싶게. 정말 잘못했습니다. 너가 선택해. 너가 죽을래 네 가족을 죽여줄까. 죄송합니다. 정말 잘못했습니다. 너에게는 선택권이 없어. 선택 못한다면 너와 네 가족까지 모조리 죽여버릴거야. 선택 못하겠습니다. 한번만 도와주세요. 그냥 다 죽여버려야겠군. 이의 없지? 제발 도와주세요.\n",
            "Label: 0\n",
            "\n",
            "Conversation: 길동경찰서입니다. 9시 40분 마트에 폭발물을 설치할거다. 네? 똑바로 들어 한번만 더 얘기한다. 장난전화 걸지 마시죠. 9시 40분 마트에 폭발물이 터지면 다 죽는거야. 장난전화는 업무방해죄에 해당됩니다. 판단은 너에게 달려있다. 길동경찰서에도 폭발물 터지면 꽤나 재미있겠지. 선생님 진정하세요. 난 이야기했어. 경고했다는 말이야.\n",
            "Label: 0\n",
            "\n",
            "Conversation: 너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어. 그만해. 니들 놀리는거 재미없어. 지영아 너가 키 160이지? 그럼 재는 160도 안돼는거네? 너 군대도 안가고 좋겠다. 니들이 나 작은데 보태준거 있냐? 난쟁이들도 장가가고하던데. 너도 희망을 가져봐 더이상 하지마라. 그 키크는 수술도 있대잖아? 니네 엄마는 그거 안해주디? 나람 해줬어. 저 키로 어찌살아. 제발 그만 괴롭히라고!\n",
            "Label: 3\n",
            "\n",
            "==================================================\n",
            "SentencePiece 모델 학습 중...\n",
            "==================================================\n",
            "\n",
            "모델 저장됨: ./configs/sentences.model\n",
            "Vocab 크기: 1300\n",
            "\n",
            "Train DataLoader 준비 완료: 총 4950개 conversations\n",
            "Test DataLoader 준비 완료: 총 500개 conversations.\n",
            "Splitting train data into train/validation sets...\n",
            "Total train samples: 4950\n",
            "  -> New Train set: 4455 samples\n",
            "  -> Validation set: 495 samples\n",
            "\n",
            "Data loading and splitting complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 학습"
      ],
      "metadata": {
        "id": "uYnfXaxdtoVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 모델 하이퍼파라미터 및 초기화\n",
        "print(\"\\nInitializing 1D CNN model...\")\n",
        "INPUT_DIM = len(vocab)\n",
        "EMBED_DIM = 256\n",
        "NUM_CLASSES = 5\n",
        "N_FILTERS = 128\n",
        "FILTER_SIZES = [2, 3, 4, 5]\n",
        "DROPOUT_PROB = 0.5\n",
        "\n",
        "model = CNNClassifier(\n",
        "    vocab_size=INPUT_DIM,\n",
        "    embed_dim=EMBED_DIM,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    num_filters=N_FILTERS,\n",
        "    filter_sizes=FILTER_SIZES,\n",
        "    dropout_prob=DROPOUT_PROB\n",
        ").to(device)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters.')\n",
        "\n",
        "# 6. 옵티마이저 및 손실 함수 정의\n",
        "LEARNING_RATE = 0.00005\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# 7. 학습 설정\n",
        "N_EPOCHS = 500\n",
        "PATIENCE = 10\n",
        "best_valid_loss = float('inf')\n",
        "best_valid_acc = 0.0\n",
        "patience_counter = 0\n",
        "model_save_path = 'best_model_cnn.pt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ylh9DvwZcA6w",
        "outputId": "3ed83e68-d118-4507-8d67-75749469f468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initializing 1D CNN model...\n",
            "The model has 794,629 trainable parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"--- 1D CNN Model Training starts ---\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "# 8. 학습 루프\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_loader, criterion, device)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "    # 조기 종료 로직\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        best_valid_acc = valid_acc\n",
        "        torch.save(model.state_dict(), model_save_path)\n",
        "        patience_counter = 0\n",
        "        print(f'\\t>> Validation loss improved ({best_valid_loss:.3f}). Saving model...')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f'\\t>> Validation loss did not improve. Counter: {patience_counter}/{PATIENCE}')\n",
        "\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(f'--- Early stopping triggered after {epoch+1} epochs ---')\n",
        "            break\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"--- Training Finished ---\")\n",
        "print(f\"Best Model saved to: {model_save_path}\")\n",
        "print(f\"  -> Best Validation Loss: {best_valid_loss:.3f}\")\n",
        "print(f\"  -> Best Validation Acc at Best Loss: {best_valid_acc*100:.2f}%\")\n",
        "print(f\"{'='*60}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbVE10VqNU0Q",
        "outputId": "d733f500-7785-4f46-ee84-cb9adfc29c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "--- 1D CNN Model Training starts ---\n",
            "============================================================\n",
            "\n",
            "Epoch: 01 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.799 | Train Acc: 24.20%\n",
            "\t Val. Loss: 1.363 |  Val. Acc: 61.41%\n",
            "\t>> Validation loss improved (1.363). Saving model...\n",
            "Epoch: 02 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.502 | Train Acc: 38.48%\n",
            "\t Val. Loss: 1.151 |  Val. Acc: 69.07%\n",
            "\t>> Validation loss improved (1.151). Saving model...\n",
            "Epoch: 03 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.316 | Train Acc: 46.24%\n",
            "\t Val. Loss: 0.999 |  Val. Acc: 71.04%\n",
            "\t>> Validation loss improved (0.999). Saving model...\n",
            "Epoch: 04 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.162 | Train Acc: 54.18%\n",
            "\t Val. Loss: 0.901 |  Val. Acc: 75.93%\n",
            "\t>> Validation loss improved (0.901). Saving model...\n",
            "Epoch: 05 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.046 | Train Acc: 59.08%\n",
            "\t Val. Loss: 0.809 |  Val. Acc: 77.03%\n",
            "\t>> Validation loss improved (0.809). Saving model...\n",
            "Epoch: 06 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.971 | Train Acc: 62.99%\n",
            "\t Val. Loss: 0.740 |  Val. Acc: 79.39%\n",
            "\t>> Validation loss improved (0.740). Saving model...\n",
            "Epoch: 07 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.875 | Train Acc: 66.44%\n",
            "\t Val. Loss: 0.680 |  Val. Acc: 80.56%\n",
            "\t>> Validation loss improved (0.680). Saving model...\n",
            "Epoch: 08 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.801 | Train Acc: 70.33%\n",
            "\t Val. Loss: 0.630 |  Val. Acc: 80.88%\n",
            "\t>> Validation loss improved (0.630). Saving model...\n",
            "Epoch: 09 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.734 | Train Acc: 72.92%\n",
            "\t Val. Loss: 0.582 |  Val. Acc: 82.25%\n",
            "\t>> Validation loss improved (0.582). Saving model...\n",
            "Epoch: 10 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.690 | Train Acc: 75.35%\n",
            "\t Val. Loss: 0.546 |  Val. Acc: 83.29%\n",
            "\t>> Validation loss improved (0.546). Saving model...\n",
            "Epoch: 11 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.644 | Train Acc: 76.82%\n",
            "\t Val. Loss: 0.524 |  Val. Acc: 83.49%\n",
            "\t>> Validation loss improved (0.524). Saving model...\n",
            "Epoch: 12 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.595 | Train Acc: 78.85%\n",
            "\t Val. Loss: 0.502 |  Val. Acc: 84.47%\n",
            "\t>> Validation loss improved (0.502). Saving model...\n",
            "Epoch: 13 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.577 | Train Acc: 79.30%\n",
            "\t Val. Loss: 0.478 |  Val. Acc: 85.18%\n",
            "\t>> Validation loss improved (0.478). Saving model...\n",
            "Epoch: 14 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.541 | Train Acc: 80.77%\n",
            "\t Val. Loss: 0.465 |  Val. Acc: 85.32%\n",
            "\t>> Validation loss improved (0.465). Saving model...\n",
            "Epoch: 15 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.525 | Train Acc: 81.48%\n",
            "\t Val. Loss: 0.453 |  Val. Acc: 85.76%\n",
            "\t>> Validation loss improved (0.453). Saving model...\n",
            "Epoch: 16 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.508 | Train Acc: 81.58%\n",
            "\t Val. Loss: 0.441 |  Val. Acc: 86.03%\n",
            "\t>> Validation loss improved (0.441). Saving model...\n",
            "Epoch: 17 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.487 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.433 |  Val. Acc: 85.96%\n",
            "\t>> Validation loss improved (0.433). Saving model...\n",
            "Epoch: 18 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.472 | Train Acc: 83.50%\n",
            "\t Val. Loss: 0.425 |  Val. Acc: 86.74%\n",
            "\t>> Validation loss improved (0.425). Saving model...\n",
            "Epoch: 19 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.450 | Train Acc: 84.08%\n",
            "\t Val. Loss: 0.419 |  Val. Acc: 86.81%\n",
            "\t>> Validation loss improved (0.419). Saving model...\n",
            "Epoch: 20 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.442 | Train Acc: 84.21%\n",
            "\t Val. Loss: 0.414 |  Val. Acc: 87.01%\n",
            "\t>> Validation loss improved (0.414). Saving model...\n",
            "Epoch: 21 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.438 | Train Acc: 84.92%\n",
            "\t Val. Loss: 0.404 |  Val. Acc: 87.20%\n",
            "\t>> Validation loss improved (0.404). Saving model...\n",
            "Epoch: 22 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.423 | Train Acc: 84.66%\n",
            "\t Val. Loss: 0.401 |  Val. Acc: 86.88%\n",
            "\t>> Validation loss improved (0.401). Saving model...\n",
            "Epoch: 23 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.413 | Train Acc: 85.57%\n",
            "\t Val. Loss: 0.395 |  Val. Acc: 87.59%\n",
            "\t>> Validation loss improved (0.395). Saving model...\n",
            "Epoch: 24 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.383 | Train Acc: 87.29%\n",
            "\t Val. Loss: 0.390 |  Val. Acc: 87.20%\n",
            "\t>> Validation loss improved (0.390). Saving model...\n",
            "Epoch: 25 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.388 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.383 |  Val. Acc: 87.79%\n",
            "\t>> Validation loss improved (0.383). Saving model...\n",
            "Epoch: 26 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.379 | Train Acc: 87.31%\n",
            "\t Val. Loss: 0.379 |  Val. Acc: 87.52%\n",
            "\t>> Validation loss improved (0.379). Saving model...\n",
            "Epoch: 27 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.362 | Train Acc: 87.04%\n",
            "\t Val. Loss: 0.376 |  Val. Acc: 87.59%\n",
            "\t>> Validation loss improved (0.376). Saving model...\n",
            "Epoch: 28 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.363 | Train Acc: 87.05%\n",
            "\t Val. Loss: 0.371 |  Val. Acc: 87.91%\n",
            "\t>> Validation loss improved (0.371). Saving model...\n",
            "Epoch: 29 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.345 | Train Acc: 88.49%\n",
            "\t Val. Loss: 0.369 |  Val. Acc: 87.98%\n",
            "\t>> Validation loss improved (0.369). Saving model...\n",
            "Epoch: 30 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.340 | Train Acc: 87.80%\n",
            "\t Val. Loss: 0.364 |  Val. Acc: 88.76%\n",
            "\t>> Validation loss improved (0.364). Saving model...\n",
            "Epoch: 31 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.338 | Train Acc: 88.37%\n",
            "\t Val. Loss: 0.359 |  Val. Acc: 89.03%\n",
            "\t>> Validation loss improved (0.359). Saving model...\n",
            "Epoch: 32 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.323 | Train Acc: 88.70%\n",
            "\t Val. Loss: 0.357 |  Val. Acc: 88.37%\n",
            "\t>> Validation loss improved (0.357). Saving model...\n",
            "Epoch: 33 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.321 | Train Acc: 89.01%\n",
            "\t Val. Loss: 0.355 |  Val. Acc: 88.44%\n",
            "\t>> Validation loss improved (0.355). Saving model...\n",
            "Epoch: 34 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.304 | Train Acc: 89.63%\n",
            "\t Val. Loss: 0.353 |  Val. Acc: 88.05%\n",
            "\t>> Validation loss improved (0.353). Saving model...\n",
            "Epoch: 35 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.312 | Train Acc: 89.50%\n",
            "\t Val. Loss: 0.350 |  Val. Acc: 88.71%\n",
            "\t>> Validation loss improved (0.350). Saving model...\n",
            "Epoch: 36 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.283 | Train Acc: 90.89%\n",
            "\t Val. Loss: 0.344 |  Val. Acc: 88.98%\n",
            "\t>> Validation loss improved (0.344). Saving model...\n",
            "Epoch: 37 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.286 | Train Acc: 90.19%\n",
            "\t Val. Loss: 0.344 |  Val. Acc: 88.32%\n",
            "\t>> Validation loss improved (0.344). Saving model...\n",
            "Epoch: 38 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.277 | Train Acc: 90.85%\n",
            "\t Val. Loss: 0.341 |  Val. Acc: 89.10%\n",
            "\t>> Validation loss improved (0.341). Saving model...\n",
            "Epoch: 39 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.276 | Train Acc: 91.32%\n",
            "\t Val. Loss: 0.340 |  Val. Acc: 88.05%\n",
            "\t>> Validation loss improved (0.340). Saving model...\n",
            "Epoch: 40 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.265 | Train Acc: 91.24%\n",
            "\t Val. Loss: 0.337 |  Val. Acc: 88.25%\n",
            "\t>> Validation loss improved (0.337). Saving model...\n",
            "Epoch: 41 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.265 | Train Acc: 91.12%\n",
            "\t Val. Loss: 0.337 |  Val. Acc: 88.71%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 42 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.262 | Train Acc: 91.18%\n",
            "\t Val. Loss: 0.331 |  Val. Acc: 89.03%\n",
            "\t>> Validation loss improved (0.331). Saving model...\n",
            "Epoch: 43 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.257 | Train Acc: 91.67%\n",
            "\t Val. Loss: 0.330 |  Val. Acc: 89.10%\n",
            "\t>> Validation loss improved (0.330). Saving model...\n",
            "Epoch: 44 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.235 | Train Acc: 92.45%\n",
            "\t Val. Loss: 0.327 |  Val. Acc: 88.71%\n",
            "\t>> Validation loss improved (0.327). Saving model...\n",
            "Epoch: 45 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.238 | Train Acc: 92.44%\n",
            "\t Val. Loss: 0.324 |  Val. Acc: 88.98%\n",
            "\t>> Validation loss improved (0.324). Saving model...\n",
            "Epoch: 46 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.242 | Train Acc: 91.88%\n",
            "\t Val. Loss: 0.322 |  Val. Acc: 88.90%\n",
            "\t>> Validation loss improved (0.322). Saving model...\n",
            "Epoch: 47 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.223 | Train Acc: 93.07%\n",
            "\t Val. Loss: 0.321 |  Val. Acc: 88.71%\n",
            "\t>> Validation loss improved (0.321). Saving model...\n",
            "Epoch: 48 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.228 | Train Acc: 92.55%\n",
            "\t Val. Loss: 0.322 |  Val. Acc: 88.83%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 49 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.227 | Train Acc: 92.35%\n",
            "\t Val. Loss: 0.319 |  Val. Acc: 88.64%\n",
            "\t>> Validation loss improved (0.319). Saving model...\n",
            "Epoch: 50 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.216 | Train Acc: 92.79%\n",
            "\t Val. Loss: 0.317 |  Val. Acc: 88.90%\n",
            "\t>> Validation loss improved (0.317). Saving model...\n",
            "Epoch: 51 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.212 | Train Acc: 93.15%\n",
            "\t Val. Loss: 0.320 |  Val. Acc: 89.49%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 52 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.209 | Train Acc: 93.13%\n",
            "\t Val. Loss: 0.319 |  Val. Acc: 88.71%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 53 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.205 | Train Acc: 93.51%\n",
            "\t Val. Loss: 0.319 |  Val. Acc: 89.10%\n",
            "\t>> Validation loss did not improve. Counter: 3/10\n",
            "Epoch: 54 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.191 | Train Acc: 93.77%\n",
            "\t Val. Loss: 0.316 |  Val. Acc: 88.90%\n",
            "\t>> Validation loss improved (0.316). Saving model...\n",
            "Epoch: 55 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.191 | Train Acc: 93.87%\n",
            "\t Val. Loss: 0.316 |  Val. Acc: 88.90%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 56 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.188 | Train Acc: 94.02%\n",
            "\t Val. Loss: 0.314 |  Val. Acc: 88.83%\n",
            "\t>> Validation loss improved (0.314). Saving model...\n",
            "Epoch: 57 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.183 | Train Acc: 94.28%\n",
            "\t Val. Loss: 0.312 |  Val. Acc: 88.90%\n",
            "\t>> Validation loss improved (0.312). Saving model...\n",
            "Epoch: 58 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.173 | Train Acc: 94.38%\n",
            "\t Val. Loss: 0.314 |  Val. Acc: 89.42%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 59 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.185 | Train Acc: 93.87%\n",
            "\t Val. Loss: 0.309 |  Val. Acc: 89.37%\n",
            "\t>> Validation loss improved (0.309). Saving model...\n",
            "Epoch: 60 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.181 | Train Acc: 94.38%\n",
            "\t Val. Loss: 0.311 |  Val. Acc: 89.49%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 61 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.173 | Train Acc: 94.14%\n",
            "\t Val. Loss: 0.310 |  Val. Acc: 89.10%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 62 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.169 | Train Acc: 94.70%\n",
            "\t Val. Loss: 0.311 |  Val. Acc: 89.49%\n",
            "\t>> Validation loss did not improve. Counter: 3/10\n",
            "Epoch: 63 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.160 | Train Acc: 94.99%\n",
            "\t Val. Loss: 0.306 |  Val. Acc: 89.30%\n",
            "\t>> Validation loss improved (0.306). Saving model...\n",
            "Epoch: 64 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.163 | Train Acc: 94.79%\n",
            "\t Val. Loss: 0.306 |  Val. Acc: 89.30%\n",
            "\t>> Validation loss improved (0.306). Saving model...\n",
            "Epoch: 65 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.159 | Train Acc: 94.82%\n",
            "\t Val. Loss: 0.304 |  Val. Acc: 88.90%\n",
            "\t>> Validation loss improved (0.304). Saving model...\n",
            "Epoch: 66 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.152 | Train Acc: 95.44%\n",
            "\t Val. Loss: 0.302 |  Val. Acc: 89.30%\n",
            "\t>> Validation loss improved (0.302). Saving model...\n",
            "Epoch: 67 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.158 | Train Acc: 94.87%\n",
            "\t Val. Loss: 0.305 |  Val. Acc: 90.08%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 68 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.145 | Train Acc: 95.80%\n",
            "\t Val. Loss: 0.303 |  Val. Acc: 89.69%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 69 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.141 | Train Acc: 95.61%\n",
            "\t Val. Loss: 0.301 |  Val. Acc: 89.88%\n",
            "\t>> Validation loss improved (0.301). Saving model...\n",
            "Epoch: 70 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.136 | Train Acc: 95.60%\n",
            "\t Val. Loss: 0.300 |  Val. Acc: 90.08%\n",
            "\t>> Validation loss improved (0.300). Saving model...\n",
            "Epoch: 71 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.143 | Train Acc: 95.60%\n",
            "\t Val. Loss: 0.303 |  Val. Acc: 89.22%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 72 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.129 | Train Acc: 96.19%\n",
            "\t Val. Loss: 0.300 |  Val. Acc: 90.27%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 73 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.128 | Train Acc: 96.07%\n",
            "\t Val. Loss: 0.300 |  Val. Acc: 89.69%\n",
            "\t>> Validation loss improved (0.300). Saving model...\n",
            "Epoch: 74 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.124 | Train Acc: 96.44%\n",
            "\t Val. Loss: 0.301 |  Val. Acc: 89.76%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 75 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.127 | Train Acc: 96.30%\n",
            "\t Val. Loss: 0.298 |  Val. Acc: 89.56%\n",
            "\t>> Validation loss improved (0.298). Saving model...\n",
            "Epoch: 76 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.124 | Train Acc: 96.05%\n",
            "\t Val. Loss: 0.300 |  Val. Acc: 90.34%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 77 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.121 | Train Acc: 96.60%\n",
            "\t Val. Loss: 0.302 |  Val. Acc: 89.49%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 78 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.119 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.297 |  Val. Acc: 90.54%\n",
            "\t>> Validation loss improved (0.297). Saving model...\n",
            "Epoch: 79 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.116 | Train Acc: 96.50%\n",
            "\t Val. Loss: 0.298 |  Val. Acc: 90.73%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 80 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.114 | Train Acc: 96.76%\n",
            "\t Val. Loss: 0.299 |  Val. Acc: 90.54%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 81 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.109 | Train Acc: 96.99%\n",
            "\t Val. Loss: 0.299 |  Val. Acc: 89.95%\n",
            "\t>> Validation loss did not improve. Counter: 3/10\n",
            "Epoch: 82 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.107 | Train Acc: 97.01%\n",
            "\t Val. Loss: 0.294 |  Val. Acc: 90.54%\n",
            "\t>> Validation loss improved (0.294). Saving model...\n",
            "Epoch: 83 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.098 | Train Acc: 97.50%\n",
            "\t Val. Loss: 0.296 |  Val. Acc: 89.95%\n",
            "\t>> Validation loss did not improve. Counter: 1/10\n",
            "Epoch: 84 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.103 | Train Acc: 97.07%\n",
            "\t Val. Loss: 0.296 |  Val. Acc: 90.54%\n",
            "\t>> Validation loss did not improve. Counter: 2/10\n",
            "Epoch: 85 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.098 | Train Acc: 97.18%\n",
            "\t Val. Loss: 0.297 |  Val. Acc: 89.83%\n",
            "\t>> Validation loss did not improve. Counter: 3/10\n",
            "Epoch: 86 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.099 | Train Acc: 97.18%\n",
            "\t Val. Loss: 0.296 |  Val. Acc: 89.76%\n",
            "\t>> Validation loss did not improve. Counter: 4/10\n",
            "Epoch: 87 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.096 | Train Acc: 97.53%\n",
            "\t Val. Loss: 0.300 |  Val. Acc: 89.42%\n",
            "\t>> Validation loss did not improve. Counter: 5/10\n",
            "Epoch: 88 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.093 | Train Acc: 97.49%\n",
            "\t Val. Loss: 0.298 |  Val. Acc: 90.73%\n",
            "\t>> Validation loss did not improve. Counter: 6/10\n",
            "Epoch: 89 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.091 | Train Acc: 97.54%\n",
            "\t Val. Loss: 0.296 |  Val. Acc: 89.49%\n",
            "\t>> Validation loss did not improve. Counter: 7/10\n",
            "Epoch: 90 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.081 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.300 |  Val. Acc: 90.73%\n",
            "\t>> Validation loss did not improve. Counter: 8/10\n",
            "Epoch: 91 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.093 | Train Acc: 97.08%\n",
            "\t Val. Loss: 0.295 |  Val. Acc: 89.95%\n",
            "\t>> Validation loss did not improve. Counter: 9/10\n",
            "Epoch: 92 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.091 | Train Acc: 97.26%\n",
            "\t Val. Loss: 0.297 |  Val. Acc: 90.80%\n",
            "\t>> Validation loss did not improve. Counter: 10/10\n",
            "--- Early stopping triggered after 92 epochs ---\n",
            "\n",
            "============================================================\n",
            "--- Training Finished ---\n",
            "Best Model saved to: best_model_cnn.pt\n",
            "  -> Best Validation Loss: 0.294\n",
            "  -> Best Validation Acc at Best Loss: 90.54%\n",
            "============================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"--- Checking Model Predictions (1 Batch from Validation Set) ---\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "idx_to_class = {\n",
        "    0: '협박 대화', 1: '갈취 대화', 2: '직장 내 괴롭힘 대화',\n",
        "    3: '기타 괴롭힘 대화', 4: '일반 대화'\n",
        "}\n",
        "\n",
        "# 1. 저장된 Best 모델 로드\n",
        "try:\n",
        "    model.load_state_dict(torch.load(model_save_path))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: 저장된 모델({model_save_path})을 찾을 수 없습니다.\")\n",
        "    exit()\n",
        "\n",
        "# 2. 검증 데이터 1배치 가져오기\n",
        "with torch.no_grad():\n",
        "    # iter()로 DataLoader를 반복 가능한 객체로 만들고 next()로 1배치 추출\n",
        "    try:\n",
        "        batch = next(iter(valid_loader))\n",
        "    except StopIteration:\n",
        "        print(\"ERROR: valid_loader가 비어있습니다.\")\n",
        "        exit()\n",
        "\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    labels = batch['labels'].to(device)\n",
        "\n",
        "    # 3. 모델 예측 수행\n",
        "    predictions = model(input_ids)\n",
        "    y_pred = predictions.argmax(dim=1) # 예측 클래스 ID (0~4)\n",
        "\n",
        "    # 4. 결과 비교 출력\n",
        "    print(f\"Total {len(labels)} samples in this batch.\\n\")\n",
        "\n",
        "    for i in range(len(labels)):\n",
        "        # 1) input_ids (텐서) -> list -> vocab으로 디코딩\n",
        "        # <pad> 토큰(ID: 0)은 디코딩 시 제외\n",
        "        token_ids = input_ids[i].cpu().tolist()\n",
        "\n",
        "        # 0번(PAD_ID) 토큰을 제외하고 실제 텍스트로 디코딩\n",
        "        # vocab.decode()는 dataset.py의 SentencePieceVocab 객체에 정의되어 있음\n",
        "        # (BOS/EOS/CLS 등 특수 토큰은 vocab.decode()가 알아서 제외함)\n",
        "        text = vocab.decode([tid for tid in token_ids if tid != PAD_IDX])\n",
        "\n",
        "        pred_class_id = y_pred[i].item()\n",
        "        true_class_id = labels[i].item()\n",
        "\n",
        "        # 2) 예측 클래스와 실제 클래스 이름 가져오기\n",
        "        pred_class_name = idx_to_class[pred_class_id]\n",
        "        true_class_name = idx_to_class[true_class_id]\n",
        "\n",
        "        # 3) 결과 출력\n",
        "        is_correct = \"✅ (Correct)\" if pred_class_id == true_class_id else \"❌ (WRONG)\"\n",
        "\n",
        "        print(f\"--- Sample {i+1} / {is_correct} ---\")\n",
        "        print(f\"  [Original Text]: {text}\")\n",
        "        print(f\"  [Model Predict]: {pred_class_name} (ID: {pred_class_id})\")\n",
        "        print(f\"  [Actual Label]:  {true_class_name} (ID: {true_class_id})\")\n",
        "        print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Hc7t5UzANU4g",
        "outputId": "c0312a72-40e6-4763-8fa3-be5a83e26973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "--- Checking Model Predictions (1 Batch from Validation Set) ---\n",
            "============================================================\n",
            "\n",
            "Total 64 samples in this batch.\n",
            "\n",
            "--- Sample 1 / ✅ (Correct) ---\n",
            "  [Original Text]: 야 왕따! .으.응.오.왜. 너 어제 공개적으로 차였다며? .어.떠.게 알.아.? 대놓고 고백한는데 그걸 모르는게 병신아님? 그렇.긴.한.데.못본 사람도있으니까 소문내지말아주라 제발. 왜?그럼 성의표시좀해봐! 알았어 내가 매점 다녀올께. 그래 5초준다 .아.아.알았어.\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 2 / ✅ (Correct) ---\n",
            "  [Original Text]: 이 축구공 니거야? 네 제거예요 이거 형이 좀만 가지고 놀다 줄게 안돼요 저번에도 가지고 논다고 해놓고 잃어 버렸잖아요 너 형이 누군지 몰라? 학교 재미있게 다니게 해줄까? 아 형 진짜 안돼요 이거 삼촌한테 선물받은거라서 진짜 형이 화가 좀 나려고 하네 너 1학년 몇반이랬지? 아 죄송해요 형 근데 진짜 진짜 잃어버리면 안돼요 알았으니까 형 공가지고 놀게 안보이는데로 좀 가 네.\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 3 / ✅ (Correct) ---\n",
            "  [Original Text]: 이마가 점점 넓어지는 것 같네 안 그래도 고민이다 야 넌 머리까지 없으면 너무 우울하다 안 그래도 스트레스다 돈도 없고 못생긴게 머리도 없으면 어쩌냐 그만해라 돈이라도 있으면 머리라도 심지 그만하라고 왜 나한테 그러냐 탈모는 유전인데 하\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 4 / ✅ (Correct) ---\n",
            "  [Original Text]: 필통 귀엽다. 머야? 이거 남자친구가 사준거야. 역시 안에 펜들도 비싸보인다. 나 이 펜 좀 빌려줘 글씨 잘 써지겠다. 이거 남자친구가 사준건데? 친구 한 번 빌려줘 필기 좀 하자. 나 이거 한 번도 안써봤어. 아까워서 못 쓰는 거 같은데 내가 써줄게 그럼 너도 더 잘 쓸거야 그래도 안돼. 이거 기스나면 안돼. 아니 빌려달라고. 잘 쓰고 수업 끝나고 줄게 알겠지.? 안되는데. 꼭 돌려줘야돼.\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 5 / ✅ (Correct) ---\n",
            "  [Original Text]: 친구야? 혹시 얼마 있니? 없는데요. 거짓말 하지마. 뒤져서 나오면 죽는다 정말 없어요. 언니들이 집갈려고 하는데 돈이 없어서 그래 정말 없어요 많이 필요없어 조금만 주면 된다니깐? 죄송해요. 진짜 없어요 잘 생각해봐. 돈 있잖아? 좋은말 할때 내놔 진짜진짜 없어요.\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 6 / ✅ (Correct) ---\n",
            "  [Original Text]: 오늘 저녁은 간단하게 라면에 김밥 어때? 좋아. 분식집 가서 먹을까, 사 와서 먹을까? 사 와서 편하게 집에서 먹자. 콜. 오는 길에 사 와. 알겠어. 뭐 필요한 거 없어? 음료수랑 단무지 잊지 마.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 7 / ✅ (Correct) ---\n",
            "  [Original Text]: 우리 밸런스 게임 할래? 좋아. 뭔데? 평생 똥만 먹기 vs 똥맛 카레만 먹기. 으악, 둘 다 싫어. 꼭 골라야 해? 응. 하나만 골라봐. 음. 그래도 똥맛 카레가 낫지 않을까? 똥은 아니니까.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 8 / ✅ (Correct) ---\n",
            "  [Original Text]: 나 오늘 생일인데. 생일 축하해 민아야. 생일 축하한다는게 끝이야? 응.? 그럼.뭘. 애들은 지금 다 만원씩 줬거든? 응.?미안해. 내가 지금 돈이. 웃기지마. 지갑 내놔. 싫어.왜 내가 친하지도 않은. 안 친해? 같은 반 친구가? 이거지 지갑? 잘쓴다고마워 돌려줘! 그거 심부름해야하는 돈이란말야.!\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 9 / ❌ (WRONG) ---\n",
            "  [Original Text]: 짜장면 같이 먹으러 갈래? 나도가도돼? 그럼 우리 친구잖아 고마워 근데 짜장면은 니가 사 어? 내가 같이 먹어줄테니까 니가 사라고 싫어? 싫냐고? 짜장면 그릇에 대가리 쳐 박히고싶어? 아.아니. 그럼 니가 사는거다? 알겠오\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 10 / ✅ (Correct) ---\n",
            "  [Original Text]: 승희야 나 돈 없는데 조금 빌려주면 안돼? 나 지금 돈 없어. 미안. 미안? 미안할짓 하지말고 좀 빌려주라 갚는다고 돈 없다고. 없는데 어떻게 빌려줘 넌 돈도 없냐? 도대체 있는게 뭐야 찐따같네 진짜 그만 좀 해. 너 동생한테 빌려야겠다. 걔 1학년이지? 걔한테 든뜯어야지 아 진짜 그만해. 여기. 뭐야 돈 있네? 왜 없는척해? 제발 그만 좀 해. 한번만 더 이러면 나도 못참아 어 아무튼 고마워 잘쓴다 꼭 갚아.\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 11 / ✅ (Correct) ---\n",
            "  [Original Text]: 지혜야 그 틴트 뭐야? 이쁘다. 어.이거? 아빠가 선물로 사주셨어. 그래? 발색 진짜 이쁘네. 나 한번만 발라봐도 돼? 응? 미안. 나 화장품 같이 쓰는 거 별로 안좋아해서. 뭐? 너 지금 내가 더럽다는 거야? 어이없네 아니. 그게 아니라. 참나 달라는 것도 아니고 발라본다는 건데. 내놔 어.여기. 헐 색 진짜 이쁘네. 지혜야 나 이거 두달만 빌려간다. 뭐? 이건 진짜 안돼. 너 저번에도 내 틴트 빌려가놓고 아직까지 안돌려줬잖아. 아 화나게 하지 말라고. 돌려준다니까? 또 쳐맞고 싶냐? 미안.그럼 꼭 돌려줘야해.\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 12 / ✅ (Correct) ---\n",
            "  [Original Text]: 김인턴 이리와서 어깨 좀 주물러줄래? 네? . 어차피 할 일도 많이 없잖아 ? 와서 어깨나 좀 주물러봐. 부장님 그렇지만 지금은 업무시간이고. 아니 부장이 시키는데 왜 이렇게 말이 많아? 아닙니다.그렇지만 제가 부장님의 어깨를 터치하는 것은 옳은 것이 아니라고 생각합니다. 요즘 사람들은 이렇게 눈치가 없나? 어차피 곧 정규직 전환되면 맨날 나 봐야하는데 괜찮겠어? 네?. 아 정규직 안될 수도 있나? 이거 뭐 내 입김이 닿을려나 모르겠지만 허허 아닙니다.하겠습니다.\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 13 / ✅ (Correct) ---\n",
            "  [Original Text]: 나 요즘 너무 행복해서 매일 감사 기도를 하고 자. 왜? 무슨 좋은 일 있는데? 얼굴에 평온함이 가득하네. 응. 우리 가족 모두 건강하고 화목해서. 그게 제일 큰 행복인 것 같아. 맞아. 돈이나 명예보다 더 소중한 거지. 나도 오늘부터 감사 기도 해야겠다. 응. 사소한 것에도 감사하는 마음을 가지면 더 행복해질 수 있을 거야. 좋은 말 고마워. 너 덕분에 마음이 따뜻해졌어.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 14 / ❌ (WRONG) ---\n",
            "  [Original Text]: 너 당장 이 결혼 취소해! 어머님.저 못 헤어져요.제발 저 이제 받아주시면 안 될까요.? 내 눈에 흙이 들어가기 전까진 아니 흙이 들어와도 너 같은 애는 절대 못 받아줘! 어머님.제발요. 저 광수씨 없으면 못 살아요. 우리 광수는 너 없어도 잘 살아. 너 같은 애한테 홀려서 잠깐 미친거야. 광수씨랑 저. 아이 생겼어요. 뭐? 이젠 하다하다 그 딴 이유로 어떻게든 우리집에 기어 들어오겠다는거야? 저희.이 아이 이쁘게 잘 키우고 싶어요.어머님 부탁드릴게요. 당장 따라와. 병원부터 가자 . 네? 무슨 병원이요.? 이제보니 광수가 그 애 때문에 어쩔 수없이 선택한 거 같은데 그 애만 없어지면 되는 거 잖아? 당장 따라와 ! 그 애만 없어지면 돼!\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 15 / ✅ (Correct) ---\n",
            "  [Original Text]: 야 쟤 냄새 나지않아? 응 맞아 쟤 안씻고 다니는거같애 야 너 좀 씻고 다녀 더러워 진짜 응 미안해 비켜 냄새나니까 왜 저런애랑 같은반인거야 내말이 쟤랑 놀지말자 너네도 놀지마 미안해 애들아\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 16 / ✅ (Correct) ---\n",
            "  [Original Text]: 민수씨 이것좀 우체국가서 부치고와 우체국이요? 응 우체국 계장님 급한건가요? 급하니까 갔다오라고했지 제가 차가 없는데 동기한테 물어보고 같이 다녀와도 될까요 민수씨. 차가 없는건 민수씨 사정이고 나는 급하니까 걸어서 가든 버스타고 가든 알아서 다녀와 네? 여기서 걸어가면 우체국까지 1시간이고 버스도 드문드문 다니는데 여기 시골이라 그런 곳인거 모르고 시험본거야? .하지만. 지금 갔다오면 점심까지 돌아오겠다 얼른 다녀와\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 17 / ✅ (Correct) ---\n",
            "  [Original Text]: 우리헤어지자 다른 사람 생겼어? 그런거 아니야 이제 지긋지긋해 이건 사랑이 아니야 니가 원하는 사랑은 뭔데? 그만하자 제발 서로 상처만 줄 뿐이야 나는 못헤어져. 우리가 헤어지는 순간은 없어 제발 우리는 헤어지는게 서로를 위하는 길이야 아니 내가 너랑 헤어지는 순간은 우리 둘다 죽는거야 정신차려 나도 죽고 너도 죽고 그러면 헤어져서 여기를 나갈일은 없네. 절대 못헤어져\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 18 / ✅ (Correct) ---\n",
            "  [Original Text]: 김대씨 맞습니까? 네 맞는데요 10월 9일 불법야동사이트에 접속해서 그날 그곳에서 라는 영상보셨죠? 헉! 네 그런데요. 제가 그 사이트 운영잔데 당신이 보실때 개인정보동의해서 개인정보를 내가 가지고 있거든 .원하는게 뭔데요 요즘 사이트 접속자가 없어서 돈이 안벌려 500만원만 보내주는 계좌로 보내 경찰에 말하면 알지? 그.그건 너무 심하잖아요! 그럼 700 보내든가 . 알겠어요 계좌번호 주세요\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 19 / ✅ (Correct) ---\n",
            "  [Original Text]: 원투 원투 야 똑바로 서 으 으윽 그만해 아이씨 서 있어봐 좀 아프다고! 어디서 소리를 질러? 미 미안 아. 나 귀 아픈 거 알면서. 너 일부러 그랬어? 아 아니야 미안해 야 서봐 다시 인간 샌드백 간다 원투 원투! 으윽.\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 20 / ✅ (Correct) ---\n",
            "  [Original Text]: 자네 면접 볼 때 나랑 만났지 않았는가? 네 맞습니다. 그때는 사람 참 성실해 보였는데 말이야 지금도 열심히 하고 있습니다 퇴근시간 되면 딱 퇴근하고 우린 뭐 갈 집이 없는 줄 알아? 주신 업무 다 끝내고 퇴근하는 겁니다 말대꾸까지 하는군 죄송합니다. 나 때는 말이야 상사가 퇴근 안 하면 아무도 안 했어 네 더 주의하겠습니다.\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 21 / ✅ (Correct) ---\n",
            "  [Original Text]: 지금 뭐라고 했냐? 다 밝힐겁니다. 누구 맘대로? 당신 잘못 세상에 알릴겁니다 너까짓게? 그러면 니 딸이랑 마누라 목숨은 안녕할 것 같냐? 그건. 그러니까 그냥 가만히 있어 그래도 죄값은 치뤄야. 말귀를 못알아듣네. 니 딸이랑 마누라 그리고 너까지 죽이는건 일도 아니야 죄송합니다. 한번만 더 그런 소리하면 쥐도새도 모르게 죽일줄알아\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 22 / ✅ (Correct) ---\n",
            "  [Original Text]: 그.러.지.마 돌려줘 뭘 돌.려.줘 내.말.따.라.하.지.마 그럼 말을 똑바로 하던가. 넌 왜 말을 더듬고 그래 그러니깐 놀림을 당하지. 앞으로 말하는 연습 좀 해야겠다 나도 일.부.러 그.러는.거 아.니야 그래 그래 그럼 이건 우리가 잘 쓸께. 고마워 넌 이제 돌아가봐.\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 23 / ✅ (Correct) ---\n",
            "  [Original Text]: 첫사랑 이야기 좀 더 자세히 해줘. 어떻게 만났고 어떻게 헤어졌어? 내 첫사랑은 고등학교 때 같은 반 친구였어. 맨날 티격태격 싸우다가 정들었지.  ⁇ 하고 설레는 연애였어. 그래서 왜 헤어졌어? 그렇게 좋아했는데. 대학교 가면서 자연스럽게 멀어졌어. 나는 서울로 가고 걔는 지방으로 가고. 장거리 연애는 자신이 없었어. 아쉽다. 지금 연락은 해? 아니. 그냥 좋은 추억으로 간직하고 있어. 가끔 생각나긴 하지만.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 24 / ✅ (Correct) ---\n",
            "  [Original Text]: 최근에 감동받았던 이야기 있어? 응. 어제 지하철에서 할머니께 자리 양보해드렸는데, 너무 고맙다고 손을 꼭 잡아주셨어. 마음이 따뜻해졌겠다. 응. 별거 아닌데도 너무 뿌듯하고 행복했어. 너 정말 착하다. 복 받을 거야. 고마워. 너도 오늘 착한 일 하나 해봐.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 25 / ✅ (Correct) ---\n",
            "  [Original Text]: 도저히 상황이 안돼서 말씀하신 기간까지 마련하지 못한 점 죄송하게 생각합니다. 그래서? 내가 무조건 이번달까지라고 했잖아. 니 입으로 내뱉은 말 잊었어? 니 목숨바쳐서 일하겠다고 했잖아? 죄송합니다. 면목이 없습니다. 죄송합니다가 다야? 니 말은 지켜야지. 입함부로 놀리면 어떻게 되는지 보여줄게. 네? 그게 무슨. 씨발 말귀를 못알아 쳐먹어? 좋은 말할 때 따라오라고. 정말 죄송합니다. 자꾸 비굴하게 굴면 내가 봐드릴줄 알았어? 형씨 어차피 죽을 건데 말 잘듣고 빨리 갑시다. 살려만 주시면 다음주까지는 무슨일이 있더라도 꼭 가져오겠습니다. 다음주가 아니라 당장 내일까지 준비안돼면 니 손가락먼저 잘릴줄알아.\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 26 / ✅ (Correct) ---\n",
            "  [Original Text]: 술 가져와. 어제도 마셨잖아요. 그만 마셔요. 술 가져오라면 가져와야지 죽고싶어? 마취총 쏠까? 아니에요. 하지마세요. 마취총 쏴서 기절시킨 다음에 너 죽이는 거 일도 아니야. 왜이래요. 하지 마세요. 계속 반항하네? 진짜 죽고싶어? 이 집에서 너 하나 죽는다고 누가 알기나 할 것 같아? 술 가져다 주면 되잖아요. 내가 가져다 달라고 했을 때 가져왔어야지. 왜이렇게 말대꾸야? 같이 죽을까? 우리 애도 있는데 어떻게 그런 말을 쉽게 해요. 너랑 나랑 애새끼 다같이 죽으면 그만이지 뭐어때?\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 27 / ✅ (Correct) ---\n",
            "  [Original Text]: 온라인 게임이 좋아, 콘솔 게임이 좋아? 나는 온라인 게임. 여러 사람이랑 같이 하는 게 재밌어. 나는 콘솔 게임. 혼자서 스토리에 집중하는 게 좋아. 온라인 게임은 고인물들이 너무 많아서, 초보자가 하기 힘들어. 콘솔 게임은 엔딩 보고 나면, 할 게 없어서 아쉬워. 그냥 둘 다 하면 되지. 뭐가 문제야.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 28 / ✅ (Correct) ---\n",
            "  [Original Text]: 안녕하십니까 사장님 뭔 안녕해 미친놈아 저리 꺼져 죄송합니다 사장님 그러게 죄송할 짓을 왜 하고 자빠지나 죄송합니다. 자네 창의성이 없나 죄송하다는 말밖에 못하는 장애를 가지고 있어? 그럼 어떻게 말해야 하나요? 얼래? 지금 대드는 거야? 됐다 차라리 죄송하다고 말이나 해 멍청아\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 29 / ❌ (WRONG) ---\n",
            "  [Original Text]: 저기 기업 보안부서죠? 네 그런데요 제가 당신회사 회원들 개인정보를 전부 해킹했는데요 네? 다시한번 말씀해주시겠어요? 해킹했다고요 사적인 정보까지 전부 증거가 있나요? 지금 메일로 보냈고 지금 당장 비트코인 10개 보내지않으면 전부 뿌려버리겠습니다 잠시 확인하고 연락드리겠습니다 정부에서 벌금받고 소송당하는것보단 쌀거야 알겠습니다\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 30 / ✅ (Correct) ---\n",
            "  [Original Text]: 요즘 배달비가 너무 비싸서, 포장 주문만 하고 있어. 나도. 배달비 4,000원은 너무 심한 것 같아. 최소 주문 금액도 있고. 배보다 배꼽이 더 커. 그래서 나는 웬만하면 집에서 해 먹으려고. 대단하다. 나는 요리에 소질이 없어서. 너도 한번 해봐. 생각보다 재밌어. 유튜브에 레시피도 많고.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 31 / ✅ (Correct) ---\n",
            "  [Original Text]: 우리 헤어졌는데 왜 이렇게 찾아와요. 난 못 헤어진다고 했잖아. 도대체 왜 그러는거야? 당신이 그 동안 나한테 한 폭행 의처증 그런게 한두개인가요. 나 좀 내버려둬요. 내가 그렇게 둘꺼 같아. 내가 당신 죽이고 그 놈도 죽일꺼야. 당신 정신차려요. 제발 이러지 말아요. 그 놈 죽인다니깐 이제서야 겁나? 그 사람은 아무 잘못 없어요. 그러니 나한테만 화내요. 그럼 당신이 말을 잘 듣던가. 내가 어떻게 하면 되나요? 진작에 그렇게 나올것이지.\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 32 / ✅ (Correct) ---\n",
            "  [Original Text]: 야! 너 지금 우리 딸 밀었지? 제가 노는데 얘가 끼어든 거거든요. 이게 어디서 어른이 말하는데. 진짜 민거 아니거든요. 내가 지금 내 눈으로 봤는데 어디서 거짓말하고 있는거야? 저 진짜 안밀었어요. 저는 여기서 놀고 있는데 얘가 와서 혼자 넘어진거에요. 쪼끄만게 못돼먹어가지고 여기 놀이터 니가 전세냈니? 같이 노는데 뭐가 와서 끼어들었다고 그러는거야? 저는 그냥 친구랑 놀고 있었다고요. 쟤가 혼자 넘어진거라고요. 그래도 요게. 너 빨리 우리 딸한테 사과 못해? 니가 넘어뜨렸잖아. 저 진짜 억울해요.\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 33 / ✅ (Correct) ---\n",
            "  [Original Text]: 이거 니 주민등록증 아니야? 잃어버린줄 알았는데.고마워! 고맙긴 뭘 근데 말야 이런 거 찾아주면 원래 사례금 같은 거 주지않나? 응.? 사례금? 내가 찾았으니 다행이지 모르는 사람이 니꺼 찾았으면 니 정보 다 들통나는 거잖아 그건 그렇지. 알겠어 ! 얼마나 생각하고 있어? 한 5만원 정도는 줘야하는 거아냐? 그렇게나 많이.? 싫음 말고 혹시 몰라서 내가 니꺼 주민등록증 사진 찍어놨거든 . 그거 불법아냐? 남의 개인정보잖아. 흘려서 잃어버리고 다닌 니가 잘못이지 왜 내가 잘못이야? 할튼 줄거야 말거야\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 34 / ✅ (Correct) ---\n",
            "  [Original Text]: 이번 달 월급 받자마자 바로 다 써버렸어. 이제 거지야. 왜? 뭐 샀는데? 또 쓸데없는 거 산 거 아니야? 아니. 이번에 부모님 결혼기념일이라서 좋은 선물 사드렸어. 우와 효녀다. 뭐 사드렸는데? 아빠는 지갑 사드리고 엄마는 목걸이 사드렸어. 너무 좋아하셨어. 잘했네. 나는 아직 그런 거 한번 못 해드렸는데. 반성하게 되네.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 35 / ✅ (Correct) ---\n",
            "  [Original Text]: 이번에 뇌물 받으신 거 다 알고 있습니다. 그래서 어쩌려고? 여기 녹취록이랑 출금 내역입니다. 원하는 게 뭐야? 저희 이번에 아파트 건설 들어가는 거 아시죠? 시청 옆 부지 말하는 건가? 이번에 규제 하나 때문에 몇억이 더 들게 생겼거든요. 그냥 넘어가 달란 이야기인가? 그렇지 않으면 지금 바로 이것들 기자한테 넘기고 죽일 수 밖에 없어요 알겠네. 받아들이겠어\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 36 / ✅ (Correct) ---\n",
            "  [Original Text]: 누가 그 소문 퍼뜨린거야? 무슨소리야 말 안하면 죽여버린다 .무슨.소문. 모른척할래? 우리집 가정사. 너잖아? 나 아니야. 그럼 누군데. 제대로 얘기 안하면 너인걸로 알고 너 머리채로 뽑아버릴거야. 나 아니야 난 진짜몰라 진짜몰라? 일단 맞고 시작하자 자.잠시만 일단 진정하고 얘기하자\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 37 / ✅ (Correct) ---\n",
            "  [Original Text]: 이 음식 왜 이렇게 맛이 없어요? 짜서 못 먹겠네 네 죄송합니다 고객님 다시 만들어 드릴께요 아니 됐어요 짜다고 하시니 다시 만들어드릴께요 이 실력이면 또 만들어도 짜지 거의 다 드셨는데 일찍 말씀해주시지. 맛없는거 참고 먹었어요 아.네 이거 저는 계산 못하겠어요 손님.\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 38 / ✅ (Correct) ---\n",
            "  [Original Text]: 과장님 여기 결제 서류에 사인 부탁드릴게요 어 그래 그래 자 여기 아 혹시 김대리 뭐 집안에 무슨 일 있다는데 뭔일인가? 아. 개인사정이라 말씀드리기가 어렵습니다 왜 우리끼리 그런 얘기 할 수 있잖아 비밀로 할게 나만 알면 되잖아 나 못 믿어? 아무리 과장님이어도 이건 진짜 개인 가정사라 얘기하기가 어렵습니다 하 새끼 찌질하네 그거 하나 얘기 못해줘? 내가 그렇게 입이 가벼워 보여? 그런게 아니고 오해하지마세요 과장님. 그치? 내가 오해했네 이제 말해줘봐 이리 가까이 와서 귓속말로 해 아무도 못 들어 아. 아니 그런 게 아니고 얘기 못 드려요 진짜 죄송해요 나중에 해결되고 얘기 가능할 때 해드릴게요 아효 진짜 재미도 없게 그런거 하나 못 얘기해줘? 어쩌피 너 자기소개서에 써있는거 보면 가정사 다 알아 그냥 얘기해\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 39 / ✅ (Correct) ---\n",
            "  [Original Text]: 아니 지은씨 어디가? 네? 저 퇴근. 퇴근? 퇴에그은? 내가 지은씨라면 탈퇴가 아니라 내일 업무 준비하는 척이라도 하겠어 아 네 준비하고 가겠습니다 뭐야 하란다고 진짜하네? 네? 무슨 말씀. 그렇게 본인 주관이 없어서 어떻게 일해? 아 답답해 저 그럼 이것만 보고 가겠습니다 아 그냥 빨리 좀 나가 지은씨 보고 있으면 내 속이 다 답답해 죄송합니다.\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 40 / ✅ (Correct) ---\n",
            "  [Original Text]: 여보세요? 여보세요? 땡땡씨 되시나요? 네. 제가 떙땡 인데요. 누구시죠? 네 안녕하세요. 저 땡땡씨 아드님 친구인데요. 땡땡이가 지금 교통사고나서 다쳤거든요. 네? 제 아들이 다쳤다고요? 네 그래서 그런데 지금 치료비가 없어서 연락드렸어요. 이 계좌번호로 1000만원만 보내주세요. 얼마나 다쳤길래 치료비가 1000만원이나 되요? 지금 어디 병원인가요? 친구가 지금 의식이 없어요. 그런데 병원에서 치료비를 미리 결제해야 수술이 가능하다해서 계좌로 돈 보내주시면 제가 바로 결제할게요. 지금 그렇게 큰 돈이 없어서요. 아들이 다쳤는데 빌려서라도 빨리 보내세요.\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 41 / ✅ (Correct) ---\n",
            "  [Original Text]: 나 요즘 너무 바빠서 집안일은 엄두도 못 내. 완전 난장판이야. 나도. 주말에도 출근하니까 청소할 시간이 없어. 이러다가 집에서 버섯 자라는 거 아니야? 괜찮아. 어차피 우리 집 오는 사람도 없는데 뭐. 그래도 이건 좀 심한 것 같아. 이번 주말에는 꼭 대청소 하자. 알겠어. 대신 끝나고 맛있는 거 먹으러 가자. 내가 쏠게.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 42 / ✅ (Correct) ---\n",
            "  [Original Text]: 야 길동 오늘도 과자 사왔냐? 응 여기. 야 이거 숙제 너가 우리껏도 다 해와라 알겠지? 이 많은걸 다 나혼자.? 그럼 니가 하지 누구하냐 응. 잔말말고 해오기나해 맞을래? 아냐 알겠어 진작에 그럴 것이지 응.\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 43 / ✅ (Correct) ---\n",
            "  [Original Text]: 한번만 살려주십시오. 이게 몇번째야? 이번에는 나도 힘들어. 신체포기각서 내놔. 다시는 그런실수 하지 않겠습니다. 실수? 니 놈 실수로 손해가 얼마인지 알아? 죄송합니다. 제가 더 잘하겠습니다. 필요없고 가씨 아니여도 거래처 뚫어달라는 사람 많아 제가 더 싸게 해드리겠습니다. 이번만 제발. 아 안된다니까? 제발 사장님 제발.이번에 와이프가 셋째를 가졌습니다 뭣도 없는 집구석에 또 싸지르기는.니놈 신장은 내 손에 달린거야.\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 44 / ✅ (Correct) ---\n",
            "  [Original Text]: 야 너 돈 좀 있냐? 아니. 없는데 웃기지 마 니 지갑에 돈 있는 거 다 봤어 있으면 어쩔건데. 어쩌긴 뭘 어째 이새끼야 헌납해야지 내가 왜 그래야 하는데. 이 새끼 봐라? 덜 맞았네 이제 그만해. 더 쳐맞기 싫으면 가진거 다 내놔. 알았어 미안해\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 45 / ✅ (Correct) ---\n",
            "  [Original Text]: 나 요즘 너무 바빠서 집안일은 꿈도 못 꿔. 완전 쓰레기장이야. 나도. 주말에도 일하니까 쉴 틈이 없어. 이러다가 건강 다 상하는 거 아니야? 괜찮아. 젊어서 고생은 사서도 한다잖아. 그래도 이건 좀 아닌 것 같아. 우리 그냥 돈 좀 더 벌어서 편하게 살자. 알겠어. 그럼 우리 내일부터 야근 수당 꼭 챙기자.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 46 / ✅ (Correct) ---\n",
            "  [Original Text]: 먼저 들어가보겠습니다! 오늘 다들 수고하셨습니다 허. 요즘엔 사원도 정시 퇴근하는구먼 허허. 세상 좋아졌어 그치? 아 죄송합니다. 제가 집안에 급한 사정이 생겨서. 아 그래요 집안에 사정없는 사람이 있나 허허. 그래요 괜찮아요 정말 죄송합니다. 다음부터는 먼저 들어가지 않겠습니다. 오늘은 너무 급해서. 제가 뭐라고 했나요? 허허. 누가 보면 욕이라도 한 줄 알겠어 ? 그치 김대리 ? 정말 죄송합니다. 좀 더 있다가 가겠습니다 제가 실수했습니다. 그래요 사람이 도리라는 것이 있지 벌써 부터 그러면 안돼요 알겠죠? 네. 명심하겠습니다. 오늘 집에 사정이 있어서 잠시 그랬습니다 죄송합니다. 자자 그러면 다들 바짝! 일하고 끝냅시다! 화이팅!\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 47 / ✅ (Correct) ---\n",
            "  [Original Text]: 요즘 너무 건조해서 그런지 온몸이 가 ⁇  난 논바닥 같아. 쩍쩍 갈라지고 아파. 나도. 특히 자고 일어나면 목이 너무 칼칼하고 아파. 어떻게 해야 할까? 이 건조한 지옥에서 벗어나고 싶어. 자기 전에 방에 젖은 수건 널어놓고 자봐. 효과 좋아. 그래? 오늘 밤에 당장 해봐야겠다. 고마워. 응. 그리고 귤껍질 모아서 방에 놔두는 것도 천연 가습기 효과가 있대. 알겠어. 너는 정말 나의 생활 백과사전이구나. 모르는 게 뭐야 대체? 너 없었으면 나 어떻게 살았을까.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 48 / ✅ (Correct) ---\n",
            "  [Original Text]: 야 신발샀냐? 이쁘네? 응. 엄마가 사줬어. 그건 안 궁금하고 빨리 안 벗냐? 안돼! 생일선물이란말이야! 너희 어머니가 내 생일 선물로 준셈치면되지 안돼! 저번에 빌려간 아이패드도 안줬잖아. 아이패드는 아직도 빌리는 상태인거고 . 이 신발 너보다 내가 더 잘어울릴거같아 제발 그만 가져가.\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 49 / ✅ (Correct) ---\n",
            "  [Original Text]: 나 너 맘에들어. 나랑 사귀자 나는 너 싫어. 꺼져 내가 정말 잘할게. 제발 싫다고 말했잖아 내가 이 칼로 죽고싶어? 너 맘에 든다고 꺄악! 살려주세요. 오늘 나랑 안있어주면 너 죽일거야 제발 이러지마세요. 나 잃을 게 없는 사람이야. 좋은 말로할때 내가 하라는데로 해 네 알았어요.\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n",
            "--- Sample 50 / ✅ (Correct) ---\n",
            "  [Original Text]: 너 중국에서 왔다며 ? 응 진짜 중국은 마약하면 죽냐? 응? 그게 무슨말이야 아니 뉴스보면 그러잖아 마약하면 바로 사형이라고 아.나도 사실 잘 모르겠네 . 진짜면 대박이다 중국인 미개하다 진짜 .아 그래서 짱깨 소리 듣는건가 개 웃겨 .놀리지마\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 51 / ✅ (Correct) ---\n",
            "  [Original Text]: 어머니 안녕하십니까 예 교장선생님 안녕하세요 아드님 때문에 걱정이 많으시겠어요? 정말 죄송합니다. 면목이 없습니다 교장선생님 안그래도 이번에 학폭위를 열까 얘기가 많이 나오고 있어요 어머니 아.안돼요! 그것만은 제발 안됩니다! 그쵸? 아드님 앞길 막히면 안되잖아요 어머님? 제.제가 뭘 하면 되나요 뭐든지 다 하겠습니다! 제발 학폭위만은 막아주세요. 하. 저도 그렇게 해드리고 싶은데 학폭위를 열려면 돈이 좀 들어가거든요. 근데 제가 그걸 막을만한 돈이 좀 없어서 알겠습니다 교장선생님 내일까지 바로 드리면 될까요?\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 52 / ✅ (Correct) ---\n",
            "  [Original Text]: 저기요. 지금 이게 드라이라고 해주신 거에요? 네? 제 머리가 집에서 나올 때보다 더 거지같.어? 최민주? 죄송합니다.어? 최연이? 아 너 여기서 일하는 거였어? 하. 그럼 그렇지. 니가 옛날부터 미용한다고 설칠 때부터 알아봤다. 미안.그래도 난 열심히 한다고 한거였는데. 니 눈엔 이게 제대로 한걸로 보여? 내가 내 돈내고 이 거지꼴로 나가야겠어? 빨리 다시 해줄래? 네. 알겠습니다. 최대한 빨리. 너한텐 안 받을꺼니까 다른 직원 불러줘. 널 믿을 수가 있어야지 음.내가 다시 해보면 안될까? 다들 손님보고계시는데. 아니? 그냥 내가 기다리면 기다렸지. 너한텐 다시 받고싶진 않은데?\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 53 / ✅ (Correct) ---\n",
            "  [Original Text]: 그 소문 진짜야? 너가 다른 애들 뒷담화하고 다녔다며? 응? 나 그런 적 없는데? 아니긴 뭘 아니야. 이미 소문 쫙 났는데. 응? 나 진짜 그런 적 없어. 됐어. 너 성격 원래 그런 줄 알았어. 무슨 소리야. 나는 하늘에 맹세코 그런 적 없어. 지랄하지마. 진짜 역겨워. 너가 그래서 친구 없는 거야. 진짜 억울하다. 내가 뭘 잘못했다고 그래? 억울하면 처신 똑바로 하고 다녔어야지. 진짜 너무하다 너.\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 54 / ✅ (Correct) ---\n",
            "  [Original Text]: 엄마 없는 애가 도시락은 누가 맨날 싸주시는거야? 할머니가.아침에 매일 해주셔. 우와 할머니가 너 때문에 맨날 고생하시는 거네? 아침.하시면서.내꺼 챙겨주시는 거야. 우리 할머니 나 이뻐해주셔. 그게 너 이뻐해주는 거겠냐? 그냥 오갈데 없는 애니까 봐주시는거 아냐? 쯧쯧. 나 그리고 엄마.없는 거아냐. 그럼 어딨는데? 어디 계신데? 모시고 와! 곧 체육대회잖아 우리 엄마 멀리 있는거야. 없는 거 아니라고.! 엄마는 있는데 못데리고 오는거야? 너랑 같이 살기 싫으시데? 아 버리고 간건가? 그만해 너 ! 정말 .나빠!\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 55 / ✅ (Correct) ---\n",
            "  [Original Text]: 김우주 이번 국어 수행평가 0점이다. 너 수행평가 미제출로 최하점이야. 내기만 하면 만점 준다니까 게을러서 못 냈지? 네? 선생님 저 분명 반장한테 제출했어요. 제가 수행 제출 안 할 애가 아니잖아요. 뭐라고? 반장 이게 무슨 말이야? 너가 우주만 미제출이라며 하는거 깜박해서 못 해왔다고 못 낸다고 얘기했다며 네 분명히 안냈는데요. 쟤가 거짓말 치나봐요. 괜히 수행 혼자서 수행 점수 깎이니가 저러는 건가 봐요. 뭔소리야 저번주에 너가 나한테 수행평가 종이 달라고 너가 모아서 제출해야 한다고 그래서 내가 너한테 줬더니 수행 빨리 준비했다고 그랬잖아. 야 소설을 써라 소설을. 내가 왜 저번주에 걷었겠어 이번주에 제출인데 애들거 잃어버리면 내가 책임지라고? 너 진짜 왜그래 너가 내준다며. 나 이번 수행 점수 떨어지면 등급도 떨어져. 너도 알잖아. 설마 너 나보다 시험 1점 못 봤다고 그러더니 너가 등\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 56 / ✅ (Correct) ---\n",
            "  [Original Text]: 너의 버 ⁇ 리스트는 뭐야? 나는 오로라 보러 가는 거. 죽기 전에 꼭 한번 보고 싶어. 너는? 나는 스카이다이빙 해보는 거. 짜릿하고 재밌을 것 같아. 둘 다 멋있다. 꼭 이룰 수 있을 거야.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 57 / ✅ (Correct) ---\n",
            "  [Original Text]: 야 일로와봐 응.? 얼마있냐 어.?나? 너말고 누가있어 나 돈 없는데. 야 얘 가방 뒤져봐 내 가방이야 만지지마! 쳐맞고 열래? . 열어서 나온만큼 다 가져간다\n",
            "  [Model Predict]: 갈취 대화 (ID: 1)\n",
            "  [Actual Label]:  갈취 대화 (ID: 1)\n",
            "------------------------------\n",
            "--- Sample 58 / ✅ (Correct) ---\n",
            "  [Original Text]: 오늘 저녁은 간단하게 김치볶음밥 해 먹을까? 좋아. 계란 프라이는 반숙으로 해줘. 당연하지. 치즈도 듬뿍 올려줄게. 콜. 생각만 해도 맛있다. 내가 맛있게 끓인 라면도 준비할게. 최고의 조합이다. 빨리 집에 가서 해 먹자. 응. 배고파서 현기증 난단 말이야.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 59 / ✅ (Correct) ---\n",
            "  [Original Text]: 정인턴 네? 복장이 그게 뭐지? 죄송합니다 뭐가 죄송한데 죄송합니다 다음부턴 안그러겠습니다 널 보면 우리 회사가 망하겠어 죄송합니다 저리 사라져 꼴보기 싫어 죄송합니다\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 60 / ✅ (Correct) ---\n",
            "  [Original Text]: 양대리 네? 양대리는 일처리가 왜 그모양이야 뭐가요 보고서를 내가 맡겼는데 너무 못쓰잖아 내가 발로 써도 이것보단 잘쓰겠어 전 최선을 다했습니다 최선을 다했는데 이따위라고? 죄송합니다 죄송하면 다야? 다시 해오겠습니다\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 61 / ✅ (Correct) ---\n",
            "  [Original Text]: 이번 주말에 뭐 할지 안정했으면 나랑 같이 클라이밍 하러 갈래? 좋아. 안 그래도 요즘 살쪄서 운동 좀 해야겠다고 생각했는데. 재밌겠다. 콜. 가서 정상까지 올라가서 뿌듯함도 느끼고 스트레스도 날려버리자. 좋은 생각이야. 생각만 해도 너무 짜릿하다. 가서 예쁜 사진도 많이 찍어서 인스타에 올려야지. 운동하는 여자 이렇게. 응. 내가 너의 멋진 모습을 카메라에 담아줄게. 기대해.\n",
            "  [Model Predict]: 일반 대화 (ID: 4)\n",
            "  [Actual Label]:  일반 대화 (ID: 4)\n",
            "------------------------------\n",
            "--- Sample 62 / ✅ (Correct) ---\n",
            "  [Original Text]: 아니 안대리 일을 왜 그 따위로 밖에 못해 안대로 또 사고쳤나? 일처리 똑바로 안할거야! 죄송합니다. 부장님 능력이 없으면 일을 하질 말던가 저런 놈한테 월급이나 주고 세상 참 좋네 에이 안대리 하는게 하루 이틀인가요? 진정하세요 저걸 진짜 자를 수도 없고\n",
            "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
            "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
            "------------------------------\n",
            "--- Sample 63 / ✅ (Correct) ---\n",
            "  [Original Text]: 머라는거야 너 참 맘에 안든다 내가 멀 진짜 멀이라니 눈 깔어 왜 그래 니 눈 맘에 안들어 아휴 아휴라니 그말은 머야 미안 미안하긴 머가 미안한데 미안\n",
            "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
            "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
            "------------------------------\n",
            "--- Sample 64 / ✅ (Correct) ---\n",
            "  [Original Text]: 음. 여기가 어디지? 이제 일어났나? 여기가 어딘지 궁금하지 않아? .! 길 가는 중에 차에 강제로 태운 것들이 니 새끼들이냐? 하. 주제도 모르고 입 놀리네 입 놀리는 거 보면 아직도 정신 못 차렸냐? 아니? 정신 아주 잘만 차렸는데? 날 살려둘 생각이나 있긴 하냐? 살려둘 생각이야 없지만 패기 하나는 인정해줄게 우리도 두려워서 질질 싸는 것보다야 이게 낫지 나 하나 죽는 걸로 끝날 것 같지? 니들도 언젠가는 나랑 똑같은 신세 될 텐데 글쎄? 과연 그럴까? 네 장기만 팔았을 것 같냐? 너를 포함해 장기 팔아서 얻은 돈 가로채서 얻은 돈이 얼마일 것 같아? 내가 그냥 죽을 것이라고 생각하지마 여기 오면서 내가 그만한 안전 장치도 안 했을 것 같아? . 설마. 야! 이 새끼 죽여버릴거야! 시체도 못 찾을 정도로 죽여버린다! 감히 카메라를 설치하고 녹음\n",
            "  [Model Predict]: 협박 대화 (ID: 0)\n",
            "  [Actual Label]:  협박 대화 (ID: 0)\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. 테스트 데이터 예측 및 제출 파일 생성\n",
        "print(f\"\\n--- Loading best CNN model for test prediction ---\")\n",
        "try:\n",
        "    model.load_state_dict(torch.load(\"/content/best_model_cnn_10.pt\"))\n",
        "\n",
        "    # test_loader로 예측 수행\n",
        "    test_predictions = predict_test(model, test_loader, device)\n",
        "\n",
        "    print(\"Prediction complete. Creating submission file...\")\n",
        "\n",
        "    import pandas as pd\n",
        "    test_df = pd.read_csv(TEST_PATH)\n",
        "\n",
        "    if len(test_df) == len(test_predictions):\n",
        "        submission_df = pd.DataFrame({\n",
        "            'idx': test_df['idx'],\n",
        "            'class': test_predictions # <-- 숫자 ID 리스트를 그대로 사용\n",
        "        })\n",
        "        submission_df.to_csv('submission.csv', index=False)\n",
        "        print(\"submission.csv file created successfully (with numeric IDs).\")\n",
        "    else:\n",
        "        print(f\"ERROR: Mismatch in length. Test DF: {len(test_df)}, Predictions: {len(test_predictions)}\")\n",
        "        print(\"Please check preprocessing logic if it removes test samples.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: 저장된 모델({model_save_path})을 찾을 수 없습니다.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during test prediction: {e}\")"
      ],
      "metadata": {
        "id": "oA59KerENU2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "862658ed-19a0-42d9-d418-825b353515e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Loading best CNN model for test prediction ---\n",
            "Prediction complete. Creating submission file...\n",
            "submission.csv file created successfully (with numeric IDs).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub = pd.read_csv(\"submission.csv\")\n",
        "sub.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiDcXT9HuFfC",
        "outputId": "31cbb711-d875-4a78-a40e-d6fce042a13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 500 entries, 0 to 499\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   idx     500 non-null    object\n",
            " 1   class   500 non-null    int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 7.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y8rTTlZ6JfKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습 기록\n",
        "1차 시도:  \n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.286\n",
        "  -> Best Validation F1 (Macro) at Best Loss: 0.889\n",
        "============================================================\n",
        "```\n",
        "<br>\n",
        "\n",
        "2차 시도:\n",
        "- L2 정칙화 추가  \n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.333\n",
        "  -> Best Validation F1 (Macro) at Best Loss: 0.888\n",
        "============================================================\n",
        "```\n",
        "loss 크게 증가함. -> 다시 빼자  \n",
        "<br>\n",
        "\n",
        "3차 시도:  \n",
        "- 정칙화 다시 제거\n",
        "- N_FILTERS = 64 (128 -> 64)\n",
        "- EMBED_DIM = 128 (256 -> 128)  \n",
        "모델 크기 줄임\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.313\n",
        "  -> Best Validation F1 (Macro) at Best Loss: 0.886\n",
        "============================================================\n",
        "```\n",
        "<br>\n",
        "\n",
        "4차 시도:  \n",
        "- vocab_size = 1300 (1500 -> 1300)\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.294\n",
        "  -> Best Validation F1 (Macro) at Best Loss: 0.887\n",
        "============================================================\n",
        "```\n",
        "<br>\n",
        "\n",
        "5차 시도:\n",
        "- N_FILTERS = 128 (원상복구)\n",
        "- EMBED_DIM = 256 (원상복구)\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.300\n",
        "  -> Best Validation F1 (Macro) at Best Loss: 0.890\n",
        "============================================================\n",
        "```\n",
        "다 비슷비슷한데,,, 지금까진 모두 얼리스탑했으니 학습률 조정하고 에포크 늘려보자.  \n",
        "<br>\n",
        "\n",
        "6차 시도:  \n",
        "- 평가 방법 변경 (f1 -> Acc)\n",
        "- lr = 0.0001 (0.001 -> 0.0001)\n",
        "- epochs = 500 (30 -> 500)\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.239\n",
        "  -> Best Validation Acc at Best Loss: 91.21%\n",
        "============================================================\n",
        "```\n",
        "45 epoch에서 early stop  \n",
        "<br>\n",
        "\n",
        "7차 시도:  \n",
        "- FILTER_SIZES = [2, 3, 4, 5]   \n",
        "    ([3, 4, 5] -> [2, 3, 4, 5])\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.233\n",
        "  -> Best Validation Acc at Best Loss: 91.80%\n",
        "============================================================\n",
        "```\n",
        "57 epoch에서 early stop  \n",
        "<br>\n",
        "\n",
        "8차 시도:  \n",
        "- dropout = 0.3 (0.5 -> 0.3)\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.237\n",
        "  -> Best Validation Acc at Best Loss: 91.02%\n",
        "============================================================\n",
        "```\n",
        "늘려서 다시 해보자  \n",
        "<br>\n",
        "\n",
        "9차 시도:  \n",
        "- dropout = 0.7 (0.3 -> 0.7)\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.241\n",
        "  -> Best Validation Acc at Best Loss: 91.14%\n",
        "============================================================\n",
        "```\n",
        "큰 차이 없어 보임.  \n",
        "<br>\n",
        "\n",
        "10차 시도:  \n",
        "- lr 줄였으니 L2 정칙화 다시 시도  \n",
        "- 라고 하려고 했으나 지금까지 정칙화 계속 적용하고 있었음;;  \n",
        "- 이번엔 없애서 해보자  \n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.222\n",
        "  -> Best Validation Acc at Best Loss: 92.90%\n",
        "============================================================\n",
        "```\n",
        "ridge 없애니 확실히 올랐음.  \n",
        "<br>\n",
        "\n",
        "11차 시도:  \n",
        "- 다시 모델 크기 줄여보기\n",
        "- N_FILTERS = 64 (128 -> 64)\n",
        "- EMBED_DIM = 128 (256 -> 128)  \n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.276\n",
        "  -> Best Validation Acc at Best Loss: 90.29%\n",
        "============================================================\n",
        "```\n",
        "  \n",
        "<br>\n",
        "\n",
        "12차 시도:  \n",
        "- N_FILTERS = 256 (64 -> 256)\n",
        "- EMBED_DIM = 512 (128 -> 512)  \n",
        "-> 파라미터 250만개\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.230\n",
        "  -> Best Validation Acc at Best Loss: 92.58%\n",
        "============================================================\n",
        "```\n",
        "좋긴 한데,, 학습률 더 낮춰보자  \n",
        "<br>\n",
        "\n",
        "13차 시도:  \n",
        "- lr = 1e-5 (0.0001 -> 1e-5)\n",
        "```\n",
        "============================================================\n",
        "--- Training Finished ---\n",
        "Best Model saved to: best_model_cnn.pt\n",
        "  -> Best Validation Loss: 0.290\n",
        "  -> Best Validation Acc at Best Loss: 90.15%\n",
        "============================================================\n",
        "```\n",
        "의미 없는 듯 하다.  \n",
        "<br>\n",
        "\n",
        "\n",
        "1D CNN 선택 이유:  \n",
        "- 협박, 갈취 등 자극적인 대화는 \"죽어\", \"내놔\" 같은 짧은 키워드로 구분될 가능성이 높다고 생각했다.  \n",
        "- 따라서 n-gram 방식을 사용하며 국소적인 패턴을 감지하는 데 좋은 성능을 보이는 1d CNN을 선택했다.  \n",
        "- 또한, 구조가 다른 모델에 비해 단순해서 학습에 걸리는 시간이 상대적으로 짧다.\n"
      ],
      "metadata": {
        "id": "G2vZFgB1Tpjm"
      }
    }
  ]
}