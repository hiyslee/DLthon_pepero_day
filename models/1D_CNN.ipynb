{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1762751790091,
     "user": {
      "displayName": "최원진",
      "userId": "08438666853507493188"
     },
     "user_tz": -540
    },
    "id": "ymkKuxN0LUvC",
    "outputId": "372f5ddf-ff6c-4cc3-a935-2e077f4149c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Colab Notebooks/아이펠/DLthon_pepero_day\n"
     ]
    }
   ],
   "source": [
    "%cd \"/content/drive/MyDrive/Colab Notebooks/아이펠/DLthon_pepero_day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2152,
     "status": "ok",
     "timestamp": 1762751793436,
     "user": {
      "displayName": "최원진",
      "userId": "08438666853507493188"
     },
     "user_tz": -540
    },
    "id": "0jTAIhMYLMxg",
    "outputId": "61cf8f80-f1e3-4816-d8b7-d1c950b16c03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 작업 디렉토리: /content/drive/MyDrive/Colab Notebooks/아이펠/DLthon_pepero_day\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# 현재 파일이 상위의 루트 디렉토리로 이동시킨 것으로 인식하게 하도록...\n",
    "# 이렇게 하면 경로 수정 필요 없음\n",
    "if os.path.basename(os.getcwd()) == 'models':\n",
    "    os.chdir('..')\n",
    "print(\"현재 작업 디렉토리:\", Path.cwd())\n",
    "\n",
    "# 프로젝트 내 폴더에서 함수 로드\n",
    "from dataset import DKTCDataset, collate_fn, create_dataloaders\n",
    "\n",
    "# 디바이스 설정\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxezvJsYMFlk"
   },
   "source": [
    "# 1. 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1762756467698,
     "user": {
      "displayName": "최원진",
      "userId": "08438666853507493188"
     },
     "user_tz": -540
    },
    "id": "kR_ZDzNaB20H"
   },
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    1D CNN 기반 텍스트 분류 모델\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 vocab_size,      # 어휘 사전의 크기 (vocab 객체로부터 받음)\n",
    "                 embed_dim,       # 임베딩 벡터의 차원\n",
    "                 num_classes,     # 분류할 클래스의 개수 (5)\n",
    "                 num_filters,     # 각 필터 크기별 컨볼루션 필터의 수\n",
    "                 filter_sizes,    # 사용할 컨볼루션 필터의 크기\n",
    "                 dropout_prob    # 드롭아웃 확률\n",
    "                ):\n",
    "\n",
    "        super(CNNClassifier, self).__init__()\n",
    "\n",
    "        # 1. 임베딩 레이어\n",
    "        # padding_idx=0: <PAD> 토큰은 0 벡터로 임베딩하고 학습하지 않음\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "\n",
    "        # 2. 1D Convolution 레이어들 (다른 커널 크기를 사용)\n",
    "        # filter_sizes 개수만큼의 Conv1d 레이어를 ModuleList로 생성\n",
    "        # Conv1d는 (batch_size, in_channels, seq_len)을 입력으로 받음\n",
    "        # 우리 임베딩은 (batch_size, seq_len, embed_dim)이므로, permute(0, 2, 1) 필요\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=embed_dim,\n",
    "                      out_channels=num_filters,\n",
    "                      kernel_size=k) # n-gram 크기\n",
    "            for k in filter_sizes\n",
    "        ])\n",
    "\n",
    "        # 3. 드롭아웃\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "        # 4. FC 레이어 (분류기)\n",
    "        # 각 필터에서 하나씩의 피처(max-pooling)가 나오므로,\n",
    "        # 총 num_filters * len(filter_sizes) 개의 피처가 입력됨\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(num_filters * len(filter_sizes), num_filters * len(filter_sizes)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Linear(num_filters * len(filter_sizes), num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        \"\"\"\n",
    "        모델의 순전파 로직\n",
    "\n",
    "        Args:\n",
    "            input_ids (torch.Tensor): (batch_size, seq_len)\n",
    "                                     dataset.py에 의해 seq_len은 max_length-1이 됨\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: (batch_size, num_classes)\n",
    "                          각 클래스에 대한 logits\n",
    "        \"\"\"\n",
    "\n",
    "        # 1. 임베딩\n",
    "        # input_ids: (batch_size, seq_len)\n",
    "        # embedded: (batch_size, seq_len, embed_dim)\n",
    "        embedded = self.embedding(input_ids)\n",
    "\n",
    "        # 2. Conv1d 입력을 위해 차원 변경\n",
    "        # embedded: (batch_size, embed_dim, seq_len)\n",
    "        embedded = embedded.permute(0, 2, 1)\n",
    "\n",
    "        # 3. 컨볼루션 + ReLU\n",
    "        # conved: (batch_size, num_filters, new_seq_len)\n",
    "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
    "\n",
    "        # 4. Max pooling\n",
    "        # F.max_pool1d(conv, conv.shape[2])는 (batch_size, num_filters, 1)을 반환\n",
    "        # .squeeze(2)를 통해 (batch_size, num_filters)로 만듦\n",
    "        # pooled: [ (batch_size, num_filters), (batch_size, num_filters), ... ]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "\n",
    "        # 5. 피처 결합 (Concatenate)\n",
    "        # catted: (batch_size, num_filters * len(filter_sizes))\n",
    "        catted = torch.cat(pooled, dim=1)\n",
    "\n",
    "        # 6. 드롭아웃\n",
    "        dropped = self.dropout(catted)\n",
    "\n",
    "        # 7. 완전 연결 레이어 (분류)\n",
    "        # logits: (batch_size, num_classes)\n",
    "        logits = self.fc(dropped)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufi2zwbjD572"
   },
   "source": [
    "# 2. Helper 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1762751794764,
     "user": {
      "displayName": "최원진",
      "userId": "08438666853507493188"
     },
     "user_tz": -540
    },
    "id": "RPonn9uFOmrB"
   },
   "outputs": [],
   "source": [
    "# 1. 헬퍼 함수 정의\n",
    "def count_parameters(model):\n",
    "    \"\"\"학습 가능한 파라미터 수 계산\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    \"\"\"에폭 소요 시간 계산\"\"\"\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def calculate_accuracy(preds, y_true):\n",
    "    \"\"\"\n",
    "    Accuracy 계산 함수\n",
    "    logits(preds)를 받아서 argmax로 예측 클래스를 추출\n",
    "    \"\"\"\n",
    "    y_pred = preds.argmax(dim=1) # (batch_size, num_classes) -> (batch_size)\n",
    "    correct = (y_pred == y_true).float() # True/False를 1.0/0.0으로\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc.item() # Python float 값으로 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8C5-Cm2D573"
   },
   "source": [
    "# 3. train 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1762751795206,
     "user": {
      "displayName": "최원진",
      "userId": "08438666853507493188"
     },
     "user_tz": -540
    },
    "id": "IRJHeKfWPGDx"
   },
   "outputs": [],
   "source": [
    "# 3. 평가 함수 정의\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            predictions = model(input_ids)\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            # Accuracy 계산\n",
    "            acc = calculate_accuracy(predictions, labels)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1762751795393,
     "user": {
      "displayName": "최원진",
      "userId": "08438666853507493188"
     },
     "user_tz": -540
    },
    "id": "XGu6CyOjOqQ7"
   },
   "outputs": [],
   "source": [
    "# 2. 훈련 함수 정의\n",
    "def train(model, iterator, optimizer, criterion, device):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch in iterator:\n",
    "        # 1. 배치 데이터를 device로 이동\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # 2. 그래디언트 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 3. 순전파\n",
    "        # input_ids: (batch_size, seq_len)\n",
    "        # predictions (logits): (batch_size, num_classes)\n",
    "        predictions = model(input_ids)\n",
    "\n",
    "        # 4. 손실 계산\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        # 5. Accuracy 계산\n",
    "        acc = calculate_accuracy(predictions, labels)\n",
    "\n",
    "        # 6. 역전파\n",
    "        loss.backward()\n",
    "\n",
    "        # 7. 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        # 8. 가중치 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 9. 누적\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc\n",
    "\n",
    "    # 평균 손실과 평균 acc 반환\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3Z6WtX3D577"
   },
   "source": [
    "# 4. 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1762760025605,
     "user": {
      "displayName": "최원진",
      "userId": "08438666853507493188"
     },
     "user_tz": -540
    },
    "id": "wKmJXLQSD577"
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = './Data/aiffel-dl-thon-dktc-online-15/aug_hub_cleaned.csv'\n",
    "TEST_PATH = './Data/aiffel-dl-thon-dktc-online-15/test.csv'\n",
    "SUBMIT_PATH = \"./Data/aiffel-dl-thon-dktc-online-15/submission.csv\"\n",
    "BEST_MODEL_PATH = './models/best_model_cnn.pt'\n",
    "VOCAB_SIZE = 1350\n",
    "MAX_LENGTH = 450\n",
    "BATCH_SIZE = 64\n",
    "VALID_RATIO = 0.1\n",
    "\n",
    "EMBED_DIM = 64\n",
    "NUM_CLASSES = 5\n",
    "N_FILTERS = 256\n",
    "FILTER_SIZES = [2, 3, 4, 5]\n",
    "DROPOUT_PROB = 0.2\n",
    "\n",
    "N_EPOCHS = 500\n",
    "PATIENCE = 10\n",
    "\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSWfNGY7D578"
   },
   "source": [
    "# 5. 데이터 로더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23552,
     "status": "ok",
     "timestamp": 1762753194751,
     "user": {
      "displayName": "최원진",
      "userId": "08438666853507493188"
     },
     "user_tz": -540
    },
    "id": "nQDQOusDVGKy",
    "outputId": "22c7025f-4c71-486d-9fb9-9f15fff2a2d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data...\n",
      "\n",
      "Loading data...\n",
      "==================================================\n",
      "데이터 로드 및 전처리 중...\n",
      "==================================================\n",
      "Train 데이터: 9887 개의 conversation\n",
      "Test 데이터: 500 개의 conversation\n",
      "\n",
      "샘플 데이터:\n",
      "Conversation: 지금 너 스스로를 죽여달라고 애원하는 것인가? 아닙니다. 죄송합니다. 죽을 거면 혼자 죽지 우리까지 사건에 휘말리게 해? 진짜 죽여버리고 싶게. 정말 잘못했습니다. 너가 선택해. 너가 죽을래 네 가족을 죽여줄까. 죄송합니다. 정말 잘못했습니다. 너에게는 선택권이 없어. 선택 못한다면 너와 네 가족까지 모조리 죽여버릴거야. 선택 못하겠습니다. 한번만 도와주세요. 그냥 다 죽여버려야겠군. 이의 없지? 제발 도와주세요.\n",
      "Label: 0\n",
      "\n",
      "Conversation: 길동경찰서입니다. 9시 40분 마트에 폭발물을 설치할거다. 네? 똑바로 들어 한번만 더 얘기한다. 장난전화 걸지 마시죠. 9시 40분 마트에 폭발물이 터지면 다 죽는거야. 장난전화는 업무방해죄에 해당됩니다. 판단은 너에게 달려있다. 길동경찰서에도 폭발물 터지면 꽤나 재미있겠지. 선생님 진정하세요. 난 이야기했어. 경고했다는 말이야.\n",
      "Label: 0\n",
      "\n",
      "Conversation: 너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어. 그만해. 니들 놀리는거 재미없어. 지영아 너가 160이지? 그럼 재는 160도 안돼는거네? 너 군대도 안가고 좋겠다. 니들이 나 작은데 보태준거 있냐? 난쟁이들도 장가가고하던데. 너도 희망을 가져봐 더이상 하지마라. 그 크는 수술도 있대잖아? 니네 엄마는 그거 안해주디? 나람 해줬어. 저 로 어찌살아. 제발 그만 괴롭히라고!\n",
      "Label: 3\n",
      "\n",
      "==================================================\n",
      "SentencePiece 모델 학습 중...\n",
      "==================================================\n",
      "\n",
      "모델 저장됨: ./configs/sentences.model\n",
      "Vocab 크기: 1350\n",
      "\n",
      "Train DataLoader 준비 완료: 총 8899개 conversations\n",
      "Validation DataLoader 준비 완료: 총 988개 conversations\n",
      "Test DataLoader 준비 완료: 총 500개 conversations.\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 로더 준비\n",
    "print(\"\\nLoading data...\")\n",
    "\n",
    "\n",
    "# 2. 데이터 로더 생성\n",
    "print(\"\\nLoading data...\")\n",
    "try:\n",
    "    # create_dataloaders는 훈련/테스트 로더와 vocab을 반환\n",
    "    train_loader, val_loader, test_loader, vocab = create_dataloaders(\n",
    "        TRAIN_PATH, TEST_PATH,\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        max_length=MAX_LENGTH,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    PAD_IDX = vocab.PAD_ID # collate_fn에 사용\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"=\"*50)\n",
    "    print(\"ERROR: 데이터 파일(train.csv/test.csv)을 찾을 수 없습니다.\")\n",
    "    print(\"TRAIN_PATH와 TEST_PATH를 실제 파일 경로로 수정해주세요.\")\n",
    "    print(\"=\"*50)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYnfXaxdtoVq"
   },
   "source": [
    "# 6. 모델 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1762760030786,
     "user": {
      "displayName": "최원진",
      "userId": "08438666853507493188"
     },
     "user_tz": -540
    },
    "id": "39AkPv2XD579",
    "outputId": "a56e0ff4-bca8-4709-cc12-85f418605530"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing 1D CNN model...\n",
      "The model has 1,371,525 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "# 5. 모델 하이퍼파라미터 및 초기화\n",
    "print(\"\\nInitializing 1D CNN model...\")\n",
    "\n",
    "model = CNNClassifier(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embed_dim=EMBED_DIM,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    num_filters=N_FILTERS,\n",
    "    filter_sizes=FILTER_SIZES,\n",
    "    dropout_prob=DROPOUT_PROB\n",
    ").to(device)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ed2KpeND57-"
   },
   "source": [
    "# 7. loss function, optimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1762760031087,
     "user": {
      "displayName": "최원진",
      "userId": "08438666853507493188"
     },
     "user_tz": -540
    },
    "id": "Ylh9DvwZcA6w"
   },
   "outputs": [],
   "source": [
    "# 6. 옵티마이저 및 손실 함수 정의\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# 7. 학습 설정\n",
    "best_valid_loss = float('inf')\n",
    "best_valid_acc = 0.0\n",
    "patience_counter = 0\n",
    "model_save_path = BEST_MODEL_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sb5TpDhFD57-"
   },
   "source": [
    "# 8. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 152828,
     "status": "ok",
     "timestamp": 1762760184465,
     "user": {
      "displayName": "최원진",
      "userId": "08438666853507493188"
     },
     "user_tz": -540
    },
    "id": "AbVE10VqNU0Q",
    "outputId": "a21535c5-f2ff-4b40-8bc4-c2ef217e9966"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "--- 1D CNN Model Training starts ---\n",
      "============================================================\n",
      "\n",
      "Epoch: 01 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 1.482 | Train Acc: 34.48%\n",
      "\t Val. Loss: 1.177 |  Val. Acc: 55.26%\n",
      "\t>> Validation loss improved (1.177). Saving model...\n",
      "Epoch: 02 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.986 | Train Acc: 61.45%\n",
      "\t Val. Loss: 0.712 |  Val. Acc: 76.92%\n",
      "\t>> Validation loss improved (0.712). Saving model...\n",
      "Epoch: 03 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.715 | Train Acc: 73.56%\n",
      "\t Val. Loss: 0.565 |  Val. Acc: 80.95%\n",
      "\t>> Validation loss improved (0.565). Saving model...\n",
      "Epoch: 04 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.597 | Train Acc: 77.69%\n",
      "\t Val. Loss: 0.509 |  Val. Acc: 82.16%\n",
      "\t>> Validation loss improved (0.509). Saving model...\n",
      "Epoch: 05 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.522 | Train Acc: 81.27%\n",
      "\t Val. Loss: 0.443 |  Val. Acc: 84.48%\n",
      "\t>> Validation loss improved (0.443). Saving model...\n",
      "Epoch: 06 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.464 | Train Acc: 83.05%\n",
      "\t Val. Loss: 0.428 |  Val. Acc: 85.01%\n",
      "\t>> Validation loss improved (0.428). Saving model...\n",
      "Epoch: 07 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.417 | Train Acc: 85.19%\n",
      "\t Val. Loss: 0.442 |  Val. Acc: 84.13%\n",
      "\t>> Validation loss did not improve. Counter: 1/10\n",
      "Epoch: 08 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.383 | Train Acc: 85.89%\n",
      "\t Val. Loss: 0.398 |  Val. Acc: 86.00%\n",
      "\t>> Validation loss improved (0.398). Saving model...\n",
      "Epoch: 09 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.349 | Train Acc: 87.42%\n",
      "\t Val. Loss: 0.376 |  Val. Acc: 87.23%\n",
      "\t>> Validation loss improved (0.376). Saving model...\n",
      "Epoch: 10 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.314 | Train Acc: 88.97%\n",
      "\t Val. Loss: 0.374 |  Val. Acc: 86.64%\n",
      "\t>> Validation loss improved (0.374). Saving model...\n",
      "Epoch: 11 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.285 | Train Acc: 90.02%\n",
      "\t Val. Loss: 0.384 |  Val. Acc: 86.02%\n",
      "\t>> Validation loss did not improve. Counter: 1/10\n",
      "Epoch: 12 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.269 | Train Acc: 90.33%\n",
      "\t Val. Loss: 0.333 |  Val. Acc: 88.25%\n",
      "\t>> Validation loss improved (0.333). Saving model...\n",
      "Epoch: 13 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.246 | Train Acc: 90.91%\n",
      "\t Val. Loss: 0.342 |  Val. Acc: 88.35%\n",
      "\t>> Validation loss did not improve. Counter: 1/10\n",
      "Epoch: 14 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.228 | Train Acc: 91.75%\n",
      "\t Val. Loss: 0.345 |  Val. Acc: 88.45%\n",
      "\t>> Validation loss did not improve. Counter: 2/10\n",
      "Epoch: 15 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.219 | Train Acc: 92.15%\n",
      "\t Val. Loss: 0.329 |  Val. Acc: 89.10%\n",
      "\t>> Validation loss improved (0.329). Saving model...\n",
      "Epoch: 16 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.192 | Train Acc: 93.13%\n",
      "\t Val. Loss: 0.321 |  Val. Acc: 89.37%\n",
      "\t>> Validation loss improved (0.321). Saving model...\n",
      "Epoch: 17 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.170 | Train Acc: 94.02%\n",
      "\t Val. Loss: 0.361 |  Val. Acc: 88.35%\n",
      "\t>> Validation loss did not improve. Counter: 1/10\n",
      "Epoch: 18 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.171 | Train Acc: 93.75%\n",
      "\t Val. Loss: 0.341 |  Val. Acc: 89.16%\n",
      "\t>> Validation loss did not improve. Counter: 2/10\n",
      "Epoch: 19 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.156 | Train Acc: 94.72%\n",
      "\t Val. Loss: 0.359 |  Val. Acc: 88.44%\n",
      "\t>> Validation loss did not improve. Counter: 3/10\n",
      "Epoch: 20 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.153 | Train Acc: 94.47%\n",
      "\t Val. Loss: 0.334 |  Val. Acc: 89.59%\n",
      "\t>> Validation loss did not improve. Counter: 4/10\n",
      "Epoch: 21 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.132 | Train Acc: 95.17%\n",
      "\t Val. Loss: 0.327 |  Val. Acc: 90.38%\n",
      "\t>> Validation loss did not improve. Counter: 5/10\n",
      "Epoch: 22 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.127 | Train Acc: 95.45%\n",
      "\t Val. Loss: 0.319 |  Val. Acc: 89.67%\n",
      "\t>> Validation loss improved (0.319). Saving model...\n",
      "Epoch: 23 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.118 | Train Acc: 95.92%\n",
      "\t Val. Loss: 0.354 |  Val. Acc: 89.17%\n",
      "\t>> Validation loss did not improve. Counter: 1/10\n",
      "Epoch: 24 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.130 | Train Acc: 95.23%\n",
      "\t Val. Loss: 0.297 |  Val. Acc: 90.70%\n",
      "\t>> Validation loss improved (0.297). Saving model...\n",
      "Epoch: 25 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.101 | Train Acc: 96.39%\n",
      "\t Val. Loss: 0.308 |  Val. Acc: 90.80%\n",
      "\t>> Validation loss did not improve. Counter: 1/10\n",
      "Epoch: 26 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.101 | Train Acc: 96.40%\n",
      "\t Val. Loss: 0.337 |  Val. Acc: 89.39%\n",
      "\t>> Validation loss did not improve. Counter: 2/10\n",
      "Epoch: 27 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.097 | Train Acc: 96.27%\n",
      "\t Val. Loss: 0.319 |  Val. Acc: 91.09%\n",
      "\t>> Validation loss did not improve. Counter: 3/10\n",
      "Epoch: 28 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.098 | Train Acc: 96.26%\n",
      "\t Val. Loss: 0.324 |  Val. Acc: 90.58%\n",
      "\t>> Validation loss did not improve. Counter: 4/10\n",
      "Epoch: 29 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.083 | Train Acc: 96.91%\n",
      "\t Val. Loss: 0.351 |  Val. Acc: 89.07%\n",
      "\t>> Validation loss did not improve. Counter: 5/10\n",
      "Epoch: 30 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.088 | Train Acc: 96.85%\n",
      "\t Val. Loss: 0.342 |  Val. Acc: 90.28%\n",
      "\t>> Validation loss did not improve. Counter: 6/10\n",
      "Epoch: 31 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.074 | Train Acc: 97.35%\n",
      "\t Val. Loss: 0.346 |  Val. Acc: 90.48%\n",
      "\t>> Validation loss did not improve. Counter: 7/10\n",
      "Epoch: 32 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.070 | Train Acc: 97.63%\n",
      "\t Val. Loss: 0.339 |  Val. Acc: 91.11%\n",
      "\t>> Validation loss did not improve. Counter: 8/10\n",
      "Epoch: 33 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.069 | Train Acc: 97.44%\n",
      "\t Val. Loss: 0.358 |  Val. Acc: 90.08%\n",
      "\t>> Validation loss did not improve. Counter: 9/10\n",
      "Epoch: 34 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.067 | Train Acc: 97.49%\n",
      "\t Val. Loss: 0.443 |  Val. Acc: 87.96%\n",
      "\t>> Validation loss did not improve. Counter: 10/10\n",
      "--- Early stopping triggered after 34 epochs ---\n",
      "\n",
      "============================================================\n",
      "--- Training Finished ---\n",
      "Total Training Time: 2m 32s\n",
      "Best Model saved to: ./models/best_model_cnn.pt\n",
      "  -> Best Validation Loss: 0.297\n",
      "  -> Best Validation Acc at Best Loss: 90.70%\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"--- 1D CNN Model Training starts ---\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# 8. 학습 루프\n",
    "total_start_time = time.time()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        best_valid_acc = valid_acc\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        patience_counter = 0\n",
    "        print(f'\\t>> Validation loss improved ({best_valid_loss:.3f}). Saving model...')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f'\\t>> Validation loss did not improve. Counter: {patience_counter}/{PATIENCE}')\n",
    "\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(f'--- Early stopping triggered after {epoch+1} epochs ---')\n",
    "            break\n",
    "\n",
    "total_end_time = time.time()\n",
    "total_mins, total_secs = epoch_time(total_start_time, total_end_time)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"--- Training Finished ---\")\n",
    "print(f\"Total Training Time: {total_mins}m {total_secs}s\")\n",
    "print(f\"Best Model saved to: {model_save_path}\")\n",
    "print(f\"  -> Best Validation Loss: {best_valid_loss:.3f}\")\n",
    "print(f\"  -> Best Validation Acc at Best Loss: {best_valid_acc*100:.2f}%\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 82,
     "status": "ok",
     "timestamp": 1762759917902,
     "user": {
      "displayName": "최원진",
      "userId": "08438666853507493188"
     },
     "user_tz": -540
    },
    "id": "Hc7t5UzANU4g",
    "outputId": "d6bb2086-bdeb-4e0c-e41f-eb7f2ce6f453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "--- Checking Model Predictions (1 Batch from Validation Set) ---\n",
      "============================================================\n",
      "\n",
      "Total 32 samples in this batch.\n",
      "\n",
      "--- Sample 1 / ✅ (Correct) ---\n",
      "  [Original Text]: 야 빨리 일해 노닥 거리지 말고 물류 물량 더 들어온다 야 색꺄 똑바로 안해? 죄송합니다. 약해 빠지면 애초에 일하지마 임마 저 약해 빠진놈 죄송합니다. 다시 해보겠습니다. 야 됐어 얘 더이상 못쓰겠다. 와 차라리 나오지를 말지 저 민폐 여기 사람들 다 일하는데 죄송해요 시끄럽고 넌 청소나 해 미안합니다. 입 다물어 에휴 어처피 일급은 다 똑같이 나올텐데 저런놈은 줄여야 하는데 그럼 제 그냥 보네죠 추노를 허용시고 돈 못 받게 하는겁니다. 얘 천재인가?\n",
      "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
      "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
      "------------------------------\n",
      "--- Sample 2 / ✅ (Correct) ---\n",
      "  [Original Text]: 너 내 아이패드 왜 안 줘? 조금만 더 쓰고 준다고 했잖아 나도 필요하다고! 어서 내놔 나도 마저 하던 거 끝내야 해 좋게 말 할 때 내놔. 너 이거 도둑질이야 뭐? 내가 도둑이라도 된다는 거니? 말도 없이 가져가면 도둑이지 뭐니? 말이 너무 심하다. 마무리 하고 내일 줄게 그 말만 지금 열 번째야. 내놓으라고 당장 아 싫다고 몇 번 말해\n",
      "  [Model Predict]: 갈취 대화 (ID: 1)\n",
      "  [Actual Label]:  갈취 대화 (ID: 1)\n",
      "------------------------------\n",
      "--- Sample 3 / ✅ (Correct) ---\n",
      "  [Original Text]: 야 돈 있어? 나 어디에 급하게 쓸 돈이 필요한데 부족하네. 좀 줄 수 있어? 아니 나 돈 없어. 미안해. 아니 친군데 못줘? 너 직장에 가서 예전에 너가 한 짓 다 까발릴까? 그래도 괜찮아? 야 왜그래. 이게 그거랑 무슨 상관이야. 그렇게 되면 나 일도 제대로 못해. 너 일 못하는게 날아 무슨상관이야. 그때 그 일 내가 까발리면 너 짤릴텐데 그래도 안줄거야? 미안해 줄 돈이 없어. 제발 그러지마. 아니? 내가 이렇게 말해도 못준다고? 나 이보다 더한 짓도 할 수 있어. 제발 그러지마. 미안해. 너 직장에만 말할 것같아? 니 부모한테도 다 말할거야. 그래도 괜찮겠어? 아니야 절대 안돼 제발 그러지마.\n",
      "  [Model Predict]: 갈취 대화 (ID: 1)\n",
      "  [Actual Label]:  갈취 대화 (ID: 1)\n",
      "------------------------------\n",
      "--- Sample 4 / ✅ (Correct) ---\n",
      "  [Original Text]: 안녕 응? 왜 그렇게 뚱뚱해? 그냥.모르겠어?그게 너랑 무슨 상관이야? 아, 싸구려 말은 안 하네. 당신은 싸움을 시작했습니다 뚱뚱해서 돼지같고 냄새도 돼지같아. 그런 힘이 어디있나요? 제발 꺼져. 나한테 왜 이러는 걸까요?\n",
      "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
      "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
      "------------------------------\n",
      "--- Sample 5 / ✅ (Correct) ---\n",
      "  [Original Text]: 어제유퀴즈 봣어? 아 거하게 잣네 안봄 오늘 보려고. 안창림 귀엽던데 지금 올림픽 선수들 나오는거 아닌가 마 ⁇  그 라디오스타에 펜싱이랑 양궁 안창림 나오던데 노래부르더라 합창수준으로 그 아는형님 거기에서도 펜싱선수들 나와 ⁇ 던것 같은데 그건봣어 아진짜 하동에서 저녁에 틀엇는데 아는형님 안본지 넘 오래 나오는거야 그래서 막걸리먹으면서 봄 재밌었다던데 나는 근데 그냥 아는형님 솔직히 재미음슴 나도 안본지 오래 티비업자나요 티빙에 나오자나 티빙안봐서 어떤지몰라  ⁇ tbc는 다나옴 월간집 재밌다던데 볼 시간이 없네 낮잠잘시간에 보면되쥬 요즘 왜케 정신없냐 오빠도 집에 있는데 이직할 회사도 재택이셔? 아 맞아 아까 아니 헐 이번주까지 쉬는주 혼자 괜춘겟어? 재택은 아직 모름 조우종 라디오에서 감자튀김잇자나 프렌치후라이 감튀품절 그게 거의 품절어어 알어? 맥날이 거의 그렇다던데\n",
      "  [Model Predict]: 일반 대화 (ID: 4)\n",
      "  [Actual Label]:  일반 대화 (ID: 4)\n",
      "------------------------------\n",
      "--- Sample 6 / ✅ (Correct) ---\n",
      "  [Original Text]: 오빠 나 돈 좀 빌려줘 친구가 돈 빌려달래 무슨 친구 얼마? 아니 그냥 좀 빌려줘 얼마 200만원 왜 돈을 나한테 빌려 싫다는 거야? 아니 왜냐고 그냥 빌려주기 싫다고 말 해 어 싫어 그래 그럼 그렇게 해 오빠 비밀은 나도 책임질 수 없고 아 너 왜그래 그럼 주던지 말던지\n",
      "  [Model Predict]: 갈취 대화 (ID: 1)\n",
      "  [Actual Label]:  갈취 대화 (ID: 1)\n",
      "------------------------------\n",
      "--- Sample 7 / ✅ (Correct) ---\n",
      "  [Original Text]: 아 요즘 미생물 음식물쓰레기 처리기가 핫하대 맞나 다 광고아니가 광고도 당연히 있는데 그만큼 괜찮은가봐 평이 좋더나 응응 일단 음쓰버리러 거의 안가다 ⁇  되고 분해도 되게잘되고 친환경적이고 베란다에 두고 써야하나 그런사람도 있는데 거의 냄새가 안난다는데 음식물 쓰레기가 있는데 어떻게 냄새가 안나노 일단 그 통을 닫고있고 그 미생물들이 음식물을 다 자기네가 분해하는거지 흙처럼 되던데 벌레도 안생기나 응 벌레생기면 사람들이 돈주고 살리가. 막상 사서 써보면 별로일 것 같은데 만족도 되게 높던데\n",
      "  [Model Predict]: 일반 대화 (ID: 4)\n",
      "  [Actual Label]:  일반 대화 (ID: 4)\n",
      "------------------------------\n",
      "--- Sample 8 / ✅ (Correct) ---\n",
      "  [Original Text]: 나랑 고등학교 때 같은 곳에서 알바하던 친구 이번에 중학교 선생님 됐다 오, 정말, 이쁘냐? 남자친구 있는데 없어도 소개 안 시켜 줄 거야 너는 오빠가 평생 혼자서 독방 생활하다가 갔으면 좋겠다는 거야? 주변에 괜찮은 사람 있으면 소개 시켜주고 해야지 그건 아닌데 내 친구 소개 받기에는 나이 차이가 조금 양심 없지. 왜 양심이 없지? 엄빠도 6살 차인데? 우린 9살 차이야 내 친구들도 비슷한 또래 남친 만나서 치킨 뜯으러 가야지 9살 연상 만나서 한방 능이 백숙 먹으러 갈 수는 없잔하. 한방 능이 백숙 무시하는데 치킨 비싸야 3만 원이지? 능이 백숙 비싸면 15만 원이다 그러니까 오빠는 15만 원 값어치를 알아볼 수 있는 여자친구를 만나야지. 어린 나이에 선생님이 된 친구 말고 어린 나이라니 이제 니가 어린 나인 아니지 요즘 고등학교 친구랑 몇 살 차인지 아니? 어린 나이지. 나는 고1 때 선생님 중에 7살 \n",
      "  [Model Predict]: 일반 대화 (ID: 4)\n",
      "  [Actual Label]:  일반 대화 (ID: 4)\n",
      "------------------------------\n",
      "--- Sample 9 / ✅ (Correct) ---\n",
      "  [Original Text]: 독약 먹을래? 아니 그 총 내놔 안 그럼 딸에게 독약 줄 거야 어떻게 ? 하지 않을 거면서 정말인데? 쿠에 독약을 탈 수도 있는데 안 되 그러니 어서 내려놔 알았어 지금 내려놔 폭파시기 전에 어\n",
      "  [Model Predict]: 협박 대화 (ID: 0)\n",
      "  [Actual Label]:  협박 대화 (ID: 0)\n",
      "------------------------------\n",
      "--- Sample 10 / ✅ (Correct) ---\n",
      "  [Original Text]: 집에서 강아지 우는 사람? 난 안워 알레르기 때문에 저도 안워요. 돈 들어가서 애기들이 강아지 우고 싶다해서 처음우는거면 진짜 힘들텐데 말 잘듣고 잘 안 아픈애로 분양 받아요. 근데 돈 많이 들겠지? 엄청 들걸? 분양 받고 이발하고 밥 값에 뭐에 하면. 강아지 아프면 보험도 안돼서 병원비 많이 나온데요. 이걸 어떻게 해야 하나? 형수는 뭐라고 해? 워도 된데? 진짜 요새는 강아지 팔자가 상 팔자 인듯 와이프는 뭐 애들이 우자고 하니까. 잘 고민해보고 결정해 애기들은 진짜 좋아 하겠네요.\n",
      "  [Model Predict]: 일반 대화 (ID: 4)\n",
      "  [Actual Label]:  일반 대화 (ID: 4)\n",
      "------------------------------\n",
      "--- Sample 11 / ✅ (Correct) ---\n",
      "  [Original Text]: 거기 잠깐만! 예.? 저.저요.? 그래. 내가 돈이 지금 급해서 말이야. 저.저 지금 돈이 없는데요. 하.왜 그래.방금 은행에서 나와놓고. 저.진짜 돈이 없어요. 야.뒤질래.? 네.네.? 빨리 돈 내놓으라고 방금 인출한 20만원 아.안돼요.이 돈만은\n",
      "  [Model Predict]: 갈취 대화 (ID: 1)\n",
      "  [Actual Label]:  갈취 대화 (ID: 1)\n",
      "------------------------------\n",
      "--- Sample 12 / ✅ (Correct) ---\n",
      "  [Original Text]: 최팀장 일로와봐 네 너 이거 내가 이런식으로 일 대충대충하지 말랬지 너 이거 나한테 들킨것만 해도 몇번이냐 아. 아닙니다 너 내가 우습지? 너 진짜 팀장만 한 십년 해볼래? 죄송합니다 왜이렇게 빡대가리인거야 제대로 하겠습니다 너 나랑 인사팀이랑 친한거알지? 내가 입털면 넌 승진이고 뭐고 짤리지만 않으면 다행인줄알아 죽을 죄를 지었습니다.\n",
      "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
      "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
      "------------------------------\n",
      "--- Sample 13 / ✅ (Correct) ---\n",
      "  [Original Text]: 네 반지 예뻐 용돈으로 샀어요. 한번만 해볼게 응 응 와, 예쁘네요.하루만 빌려주세요. 이것은 비싸다. 우리 사이? 아직. 이봐, 괜찮아 당신은 화가 났나요?\n",
      "  [Model Predict]: 갈취 대화 (ID: 1)\n",
      "  [Actual Label]:  갈취 대화 (ID: 1)\n",
      "------------------------------\n",
      "--- Sample 14 / ✅ (Correct) ---\n",
      "  [Original Text]: 내 남동생이 예쁘다고 했어? 내 동생을 어떻게 아세요? 당신이 예쁘다는 소문이 있어요 내 동생 근처에도 가지 마 그럼 내가 말한 대로 하세요. 그거 어렵다 동생을 생각하면 제발 내 동생 건드리지 마세요 오늘까지 내가 말하는 대로 하여라. 생각해 볼게\n",
      "  [Model Predict]: 협박 대화 (ID: 0)\n",
      "  [Actual Label]:  협박 대화 (ID: 0)\n",
      "------------------------------\n",
      "--- Sample 15 / ✅ (Correct) ---\n",
      "  [Original Text]: 휴대폰을 사야 하는데, 휴대폰 요금이 미납되어 있어서 살 수 없습니다. 아, 힘들겠다 지금 당장 미납금을 갚아야 하는데, 백만 원만 빌려주실 수 있나요? 나에게 그 큰 돈은 어디에 있습니까? 직장에서 해고되어서 돈이 없어요. 미안 돈이 없어 내 월급은 알잖아 하지만 당신은 직업이 있고 부모님과 함께 살고 있습니다.지금 나에게는 인생이 어렵다. 지금은 어떻게 그 많은 돈을 벌 수 있나요? 당신의 가족은 부자입니다.부모님에게 부탁을 해보세요.\n",
      "  [Model Predict]: 갈취 대화 (ID: 1)\n",
      "  [Actual Label]:  갈취 대화 (ID: 1)\n",
      "------------------------------\n",
      "--- Sample 16 / ✅ (Correct) ---\n",
      "  [Original Text]: 야 찐따 응. 가서 빵좀사와 지금? 그래. 우유도같이 돈은? 니돈으로사 임마 지금 돈이 없는데 어쭈 죽을래 미안해.\n",
      "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
      "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
      "------------------------------\n",
      "--- Sample 17 / ✅ (Correct) ---\n",
      "  [Original Text]: 이번주에 뭐하나 김사원 아 딱히 별일은 없어서 집에서 쉬려고합니다 아 잘됐네 네? 이번주말에 우리 삼촌이 가평에 갈비집을 여는데 손이 부족하다하네 네? 그게 왜 저랑 . 자네 젊었을때 갈비집에서 알바했다고 면접볼때 그런게 생각나서 오랜만에 적성도 살리고 갈비도 먹고 바람도 쐬고 좋지 않은가 아 그건 좀 힘들것같습니다 별일 없다고 하지 않았어? 네. 그래도 좀 참 요새 젊은 사람들은 정이 없어 정이 그렇지? 죄송합니다. 앞으로 정없이 칼같이 나도 자네에게 대할세\n",
      "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
      "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
      "------------------------------\n",
      "--- Sample 18 / ❌ (WRONG) ---\n",
      "  [Original Text]: 중구가 시드나? 경찰들 논간에 놀아나는 거여 어이 정청 이 짱개새꺄 우리가 개 호구로 보이냐? 이런 모지리들 뭐 이새꺄! 드루와 드루와 이런 미친! 야 다 드루와 드루와 죽어 이 짱개 새꺄! 너네는 오늘 내한테 다 죽는다! 억! 중구 형님.\n",
      "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
      "  [Actual Label]:  협박 대화 (ID: 0)\n",
      "------------------------------\n",
      "--- Sample 19 / ✅ (Correct) ---\n",
      "  [Original Text]: ᄀ김희진 선수 너무 좋아 여자 배구 말하는거지? 대박이야 맞아 반한거 같아 이번에도 사비로 팬미팅 진행 했다던대 늦덕이라 눈물난다 그러게 갔으면 좋았을텐데 다음에도 또 하겠지? 매년 하는거 같더라 올해는 김희진 선수한테 올인한다 팬미팅도 가 가고 싶다 진짜 방법 찾아봐야지 실물영접하면 좋겠네 응 경기도 직관해보고싶어 경기는 나도 보고싶은데 언제 한번 같이 가볼래? 좋지! 재밌겠다 가기전에 배구 공부 좀 하고가자 맞아 룰은 알아야 재밌지 우리 이러다 배구 팬 되는거 아닌지 몰라\n",
      "  [Model Predict]: 일반 대화 (ID: 4)\n",
      "  [Actual Label]:  일반 대화 (ID: 4)\n",
      "------------------------------\n",
      "--- Sample 20 / ✅ (Correct) ---\n",
      "  [Original Text]: 안녕하세요 병원장님 어 그래 약국은 잘 돼지? 네 덕분에요 응 그래그래 근데 다음주부터 여기 약국에 다른 사람이 들어오기러 했는데 어떡하지? 네? 아니 나친한 친구 딸도 약사인데 목 좋은데서 하고 싶다고 사정사정하기길래 아니그래도 그렇죠. 당장 다음주부터 나가라고 하시면 어떡합니까 그치? 그래서 너무 인정머리 없는 것 같아서 내가 내려왔잖아 네? 그 친구가 약국 인수하게 해주면 돈 좀 챙겨준다는데 나는 김약사 그동안의 정을 생각해서 먼저 알려주라고 내려왔지친구가 준다는거 딱 반만 받겠네\n",
      "  [Model Predict]: 갈취 대화 (ID: 1)\n",
      "  [Actual Label]:  갈취 대화 (ID: 1)\n",
      "------------------------------\n",
      "--- Sample 21 / ✅ (Correct) ---\n",
      "  [Original Text]: 아, 지금은 차값이 없어요. 그래서 뭐 5만원만 주실 수 있나요? 돈이 없어 나도 학생이야 학생이든 뭐든 부모님한테 전화해서 빨리 5만원 챙겨오세요. 알았어 여기 감사합니다 다음에 다시 줘 싫어\n",
      "  [Model Predict]: 갈취 대화 (ID: 1)\n",
      "  [Actual Label]:  갈취 대화 (ID: 1)\n",
      "------------------------------\n",
      "--- Sample 22 / ✅ (Correct) ---\n",
      "  [Original Text]: 이봐!네 테러 공격을 주도한 사람이 누구야? 모르겠습니다. 지금 말하지 않으면 평생 불구가 될 텐데 그래도 아무 말도 안 할 건가요.? 나는 정말로 모른다. 알았어 그럼 그렇게 나오겠지? 그럼 딸은 어쩌고? 딸이 평생 장애인이 되어도 아무말도 안하잖아.? 아, 아뇨, 그냥 내 딸이에요. 야!딸 손톱 뽑아라 그냥 자! 아.?말해줄래? 내가 말해주지.\n",
      "  [Model Predict]: 협박 대화 (ID: 0)\n",
      "  [Actual Label]:  협박 대화 (ID: 0)\n",
      "------------------------------\n",
      "--- Sample 23 / ✅ (Correct) ---\n",
      "  [Original Text]: 사람들은 정말 배신적이야.그렇지? 죄송합니다. 그렇게 살고 싶었을 때는 절박해서 뭐든지 할 수 있는 것처럼 행동했어요.하하. 그땐 정말 감사했어요.정말 당신 덕분에 살았습니다. 응.나 덕분에 이렇게 살고 있구나.나 모르는 척.너무 웃기고 슬프다. 나는 무서웠다.나는 무서웠다. 내가 세상에서 가장 싫어하는 사람은 약속을 지지 않고 실망시는 사람이다. 두 가지가 있다고 하셨다. 다시 한 번 최선을 다할 게요, 알았죠?나한테 기회를 주면 안 돼요? 알았어.기회를 줄게.약속 잊지 않았지?10번의 기회를 줬어.손가락 걸게.이번이 두 번째니까 이제 그만둬.잠깐이면 돼.고통도 짧을 것이다. .이거 줘!안돼안돼!제발 이러지 마세요.더 이상 잃고 싶지 않아요!\n",
      "  [Model Predict]: 협박 대화 (ID: 0)\n",
      "  [Actual Label]:  협박 대화 (ID: 0)\n",
      "------------------------------\n",
      "--- Sample 24 / ✅ (Correct) ---\n",
      "  [Original Text]: 승민아 나 담배사야되는데 만원만 줘 오늘 나 돈 없어. 에이 만원도 없는 사람이 어딨냐 좀 줘봐 아 진짜 없어. 아 금방 줄게. 안돼 오늘은 진짜 돈 없어 달라는거 아니고 내일 갚는다고! 알았어 이번만이야. 진작에 그럴 것이지 내일 꼭 줘.\n",
      "  [Model Predict]: 갈취 대화 (ID: 1)\n",
      "  [Actual Label]:  갈취 대화 (ID: 1)\n",
      "------------------------------\n",
      "--- Sample 25 / ✅ (Correct) ---\n",
      "  [Original Text]: 나 요새 자기전에 스도쿠해 자기전에 스도쿠? 지루해서 잠이오는거야? 머리를 심하게 쓰면 잠이 오거든 반대 아니야? 너무 머리 써서 졸린 그 순간에 잘 수 있는거야 수면용 게임인거야? 응 자기 전에는 테트리스 아니면 스도쿠야 차라리 책을 읽지 책은 재미가 없으니까 테트리스랑 스도쿠는 책보단 재밌긴하지 너도 나중에 자기 전에 한번 해봐 그래볼게. 믿기진않지만 재미도 있고 잠도 오고 일석이조야\n",
      "  [Model Predict]: 일반 대화 (ID: 4)\n",
      "  [Actual Label]:  일반 대화 (ID: 4)\n",
      "------------------------------\n",
      "--- Sample 26 / ❌ (WRONG) ---\n",
      "  [Original Text]: 미안한데 내가 너 물건을 부셨어 왜 어떻게 하다 부셨는데 가지고 놀다가 부셨어 내일 까지 사와 나 돈이 없는데 미안 내일 까지 안사오면 내가 니 가장 아끼는 물건 부실게 안돼 이건 내가 가장 아끼는거야 안그러면 사오시든지 어쨌든 내일 까지 똑같은거로 사와 안그러면 부실게\n",
      "  [Model Predict]: 갈취 대화 (ID: 1)\n",
      "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
      "------------------------------\n",
      "--- Sample 27 / ✅ (Correct) ---\n",
      "  [Original Text]: 나를 왜 자꾸 때려 때리고 싶으니깐. 내가 뭐 잘못했어? 아니 잘못없지 근데 왜? 너만보면 기분이 나쁘니깐 왜 나쁜데 쳐다보는게 기분나쁘다 그럼 어떡해야해? 그냥 닥치고 맞으면 돼\n",
      "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
      "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
      "------------------------------\n",
      "--- Sample 28 / ✅ (Correct) ---\n",
      "  [Original Text]: 아, 지금 일어났어? 어, 그거.나를 놓아주세요.제발.제발. 울지 마세요, 울지 마세요. 아가씨, 내가 당신에게 무슨 짓을 해서 울고 있어요. 도대체 무엇을 원하는 걸까요?예.? 울지 마세요!여자들이 우는 걸 제일 싫어해요! .울지 않을게요.제발.제발 저를 구해주세요.예.? 올치.이제 네 엄마가 내 돈을 가져가서 도망갔어.근데 못찾겠어? 음, 엄마.?나도 엄마를 본 지 몇 년이 됐어요.사실이에요. 알았지?네 딸이 죽었다고 말하면 모른 척은 안 할 거야.네?이게 내가 네 엄마한테서 돈을 받을 수 있는 유일한 방법이니까. 제발 무슨 일이 있어도 엄마를 찾아갈게요.살려주세요.!\n",
      "  [Model Predict]: 협박 대화 (ID: 0)\n",
      "  [Actual Label]:  협박 대화 (ID: 0)\n",
      "------------------------------\n",
      "--- Sample 29 / ✅ (Correct) ---\n",
      "  [Original Text]: 왜 내 전화를 안 받나요? 이제 그만 연락하시길 바랍니다.미안해요. 이제 우리는 무엇을 할 건가요?이게 우리 사이의 전부인가요? 이미 끝났어 그만하자 아직 끝나지 않았습니다. 그만해! 너 때문에 나도 이제 겁이 난다 제발 연락하지마 응?후회하지 않을 자신 있어? 나는 그것을 후회하지 않는다. 계속 이대로 가면 어떻게 될지 모르겠네요. 무슨 뜻이에요? 나 지금 네 집에 있어 뭐?뭐하는 거야?어떻게 우리집에 들어왔어! 스토커 새끼야 나랑 헤어지면 아마 지금쯤 네 개는 죽었을 거야. 널 아주 잔인하게 죽여버릴 거야. 아니요!\n",
      "  [Model Predict]: 협박 대화 (ID: 0)\n",
      "  [Actual Label]:  협박 대화 (ID: 0)\n",
      "------------------------------\n",
      "--- Sample 30 / ✅ (Correct) ---\n",
      "  [Original Text]: 저기요 혹시 김민경님 아세요? 혹시 누구신데 그러시죠? 김민경씨 남편 되는 사람인데요 당신 내 아내랑 바람났지? 뭔소리세요. 그런 사람 누군지 모르는데 이미 얘가 다 털어놨어요. 그니까 좋은 말 할 때 빨리 사과하시죠. 당신도 결혼한 사람이라며 어떻게 그럴 수 있어. 죄송합니다. 저희 아내한테는 말하지 말아주세요. 관계 깔끔하게 끝낼게요. 너네 아내한테 말 안 하는 조건과 더불어 내 아내랑 바람 피워서 내 정신 상태가 상당히 불안해졌거든? 정신적 보상금 합해서 100만원 내놔. 네네 빠른 시일안으로 보내드릴테니 제발 아내한테 말하지 말아주세요. 어쨋든 빠른 시일안에 100만원 보내. 안 그러면 바로 니 아내한테 말할거니까. 네 알겠습니다. 감사합니다 전화 끊겠습니다. 오빠 나 잘했지. 내가 딱 결혼한 유부남 꼬셨다니까 내가 이렇게만 하면 쉽게 돈 벌 수 있다 그랬잖아. 두 집 살림하느라 고생했다. 100만원\n",
      "  [Model Predict]: 갈취 대화 (ID: 1)\n",
      "  [Actual Label]:  갈취 대화 (ID: 1)\n",
      "------------------------------\n",
      "--- Sample 31 / ✅ (Correct) ---\n",
      "  [Original Text]: 어제 직장에서 길동 직원과 함께 식사를 배달했다고 들었는데? 아, 네, 회사에 할 일이 좀 있는데 너무 늦게 자서 배가 고파서 저녁을 주문했어요. 그런데 길동직원이 불쌍하네요. 그게 무슨 뜻인지 추측할 수 있나요? 아니요, 맞습니다.일도 못 하고 사이도 안 좋은 사람이랑 같이 일해야 해서 속으로 너무 환멸이 났나 봐요. 어제 몰래 밥 먹기 싫었나 봐요. 먼저 식사를 제안한 사람은 길동 직원이었습니다. 그리고 말이 너무 많습니다. 나는 뭐지?옳은 말만 했어. 일을 못하니까 사람들이 나랑 아무것도 하기 싫어하고, 밥도 같이 먹으려 하지 않잖아. 아, 너무 눈치채지 못한 걸까? 그렇게 생각했다면 미안하지만 그렇게 생각하는 사람은 당신뿐이다. 와, 당신은 너무 망상적이네요.아무 문제가 없습니다.그래서 당신이 문제입니다.당신은 대중의 눈 밖에 있는데도 그것을 모르고, 당신이 훌륭하다고 생각하고, 징징거리고 운이\n",
      "  [Model Predict]: 직장 내 괴롭힘 대화 (ID: 2)\n",
      "  [Actual Label]:  직장 내 괴롭힘 대화 (ID: 2)\n",
      "------------------------------\n",
      "--- Sample 32 / ✅ (Correct) ---\n",
      "  [Original Text]: 야 이거봐 완전 길동이  ⁇ 음 진짜네 야 그러지마. 왜 똑같구만 원숭이 하지말라고! 야 장난이야 장난 장난도 정도가 있지! 그래 알았다 미안하다 왜케 찌질하냐 뭐? 아니다 꺼져라\n",
      "  [Model Predict]: 기타 괴롭힘 대화 (ID: 3)\n",
      "  [Actual Label]:  기타 괴롭힘 대화 (ID: 3)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"--- Checking Model Predictions (1 Batch from Validation Set) ---\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "idx_to_class = {\n",
    "    0: '협박 대화', 1: '갈취 대화', 2: '직장 내 괴롭힘 대화',\n",
    "    3: '기타 괴롭힘 대화', 4: '일반 대화'\n",
    "}\n",
    "\n",
    "# 1. 저장된 Best 모델 로드\n",
    "try:\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: 저장된 모델({model_save_path})을 찾을 수 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "# 2. 검증 데이터 1배치 가져오기\n",
    "with torch.no_grad():\n",
    "    # iter()로 DataLoader를 반복 가능한 객체로 만들고 next()로 1배치 추출\n",
    "    try:\n",
    "        batch = next(iter(val_loader))\n",
    "    except StopIteration:\n",
    "        print(\"ERROR: valid_loader가 비어있습니다.\")\n",
    "        exit()\n",
    "\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "\n",
    "    # 3. 모델 예측 수행\n",
    "    predictions = model(input_ids)\n",
    "    y_pred = predictions.argmax(dim=1) # 예측 클래스 ID (0~4)\n",
    "\n",
    "    # 4. 결과 비교 출력\n",
    "    print(f\"Total {len(labels)} samples in this batch.\\n\")\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        # 1) input_ids (텐서) -> list -> vocab으로 디코딩\n",
    "        # <pad> 토큰(ID: 0)은 디코딩 시 제외\n",
    "        token_ids = input_ids[i].cpu().tolist()\n",
    "\n",
    "        # 0번(PAD_ID) 토큰을 제외하고 실제 텍스트로 디코딩\n",
    "        # vocab.decode()는 dataset.py의 SentencePieceVocab 객체에 정의되어 있음\n",
    "        # (BOS/EOS/CLS 등 특수 토큰은 vocab.decode()가 알아서 제외함)\n",
    "        text = vocab.decode([tid for tid in token_ids if tid != PAD_IDX])\n",
    "\n",
    "        pred_class_id = y_pred[i].item()\n",
    "        true_class_id = labels[i].item()\n",
    "\n",
    "        # 2) 예측 클래스와 실제 클래스 이름 가져오기\n",
    "        pred_class_name = idx_to_class[pred_class_id]\n",
    "        true_class_name = idx_to_class[true_class_id]\n",
    "\n",
    "        # 3) 결과 출력\n",
    "        is_correct = \"✅ (Correct)\" if pred_class_id == true_class_id else \"❌ (WRONG)\"\n",
    "\n",
    "        print(f\"--- Sample {i+1} / {is_correct} ---\")\n",
    "        print(f\"  [Original Text]: {text}\")\n",
    "        print(f\"  [Model Predict]: {pred_class_name} (ID: {pred_class_id})\")\n",
    "        print(f\"  [Actual Label]:  {true_class_name} (ID: {true_class_id})\")\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m76XgImJD58C"
   },
   "source": [
    "# 9. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1762759923878,
     "user": {
      "displayName": "최원진",
      "userId": "08438666853507493188"
     },
     "user_tz": -540
    },
    "id": "5Y632d0iQDvF"
   },
   "outputs": [],
   "source": [
    "# 4. 테스트 로더용 예측 함수\n",
    "def predict_test(model, iterator, device):\n",
    "    \"\"\"\n",
    "    레이블이 없는 test_loader에 대해 예측을 수행하고\n",
    "    (문장 ID 대신) 인덱스 순서대로 예측 클래스를 반환합니다.\n",
    "    (submission.csv 생성을 위함)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            # test_loader는 'labels'가 없음\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "\n",
    "            # 모델 예측 (logits)\n",
    "            predictions = model(input_ids)\n",
    "\n",
    "            # 가장 확률이 높은 클래스 ID (0~4)\n",
    "            y_pred = predictions.argmax(dim=1)\n",
    "\n",
    "            predictions_list.extend(y_pred.cpu().numpy())\n",
    "\n",
    "    return predictions_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOlIXv-tD58E"
   },
   "source": [
    "# 10. 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 882,
     "status": "ok",
     "timestamp": 1762759977337,
     "user": {
      "displayName": "최원진",
      "userId": "08438666853507493188"
     },
     "user_tz": -540
    },
    "id": "oA59KerENU2Z",
    "outputId": "a40f4c95-96a5-47a9-b884-442f64af36b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading best CNN model for test prediction ---\n",
      "Prediction complete. Creating submission file...\n",
      "submission.csv file created successfully (with numeric IDs).\n"
     ]
    }
   ],
   "source": [
    "# 9. 테스트 데이터 예측 및 제출 파일 생성\n",
    "print(f\"\\n--- Loading best CNN model for test prediction ---\")\n",
    "try:\n",
    "    model.load_state_dict(torch.load(\"./models/best_model_cnn.pt\"))\n",
    "\n",
    "    # test_loader로 예측 수행\n",
    "    test_predictions = predict_test(model, test_loader, device)\n",
    "\n",
    "    print(\"Prediction complete. Creating submission file...\")\n",
    "\n",
    "    import pandas as pd\n",
    "    test_df = pd.read_csv(TEST_PATH)\n",
    "\n",
    "    if len(test_df) == len(test_predictions):\n",
    "        submission_df = pd.DataFrame({\n",
    "            'idx': test_df['idx'],\n",
    "            'class': test_predictions # <-- 숫자 ID 리스트를 그대로 사용\n",
    "        })\n",
    "        submission_df.to_csv('submission.csv', index=False)\n",
    "        print(\"submission.csv file created successfully (with numeric IDs).\")\n",
    "    else:\n",
    "        print(f\"ERROR: Mismatch in length. Test DF: {len(test_df)}, Predictions: {len(test_predictions)}\")\n",
    "        print(\"Please check preprocessing logic if it removes test samples.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: 저장된 모델({model_save_path})을 찾을 수 없습니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during test prediction: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OiDcXT9HuFfC",
    "outputId": "31cbb711-d875-4a78-a40e-d6fce042a13d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   idx     500 non-null    object\n",
      " 1   class   500 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv(SUBMIT_PATH)\n",
    "sub.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2vZFgB1Tpjm"
   },
   "source": [
    "# 학습 기록\n",
    "1차 시도:  \n",
    "```\n",
    "============================================================\n",
    "--- Training Finished ---\n",
    "Best Model saved to: best_model_cnn.pt\n",
    "  -> Best Validation Loss: 0.286\n",
    "  -> Best Validation F1 (Macro) at Best Loss: 0.889\n",
    "============================================================\n",
    "```\n",
    "<br>\n",
    "\n",
    "2차 시도:\n",
    "- L2 정칙화 추가  \n",
    "```\n",
    "============================================================\n",
    "--- Training Finished ---\n",
    "Best Model saved to: best_model_cnn.pt\n",
    "  -> Best Validation Loss: 0.333\n",
    "  -> Best Validation F1 (Macro) at Best Loss: 0.888\n",
    "============================================================\n",
    "```\n",
    "loss 크게 증가함. -> 다시 빼자  \n",
    "<br>\n",
    "\n",
    "3차 시도:  \n",
    "- 정칙화 다시 제거\n",
    "- N_FILTERS = 64 (128 -> 64)\n",
    "- EMBED_DIM = 128 (256 -> 128)  \n",
    "모델 크기 줄임\n",
    "```\n",
    "============================================================\n",
    "--- Training Finished ---\n",
    "Best Model saved to: best_model_cnn.pt\n",
    "  -> Best Validation Loss: 0.313\n",
    "  -> Best Validation F1 (Macro) at Best Loss: 0.886\n",
    "============================================================\n",
    "```\n",
    "<br>\n",
    "\n",
    "4차 시도:  \n",
    "- vocab_size = 1300 (1500 -> 1300)\n",
    "```\n",
    "============================================================\n",
    "--- Training Finished ---\n",
    "Best Model saved to: best_model_cnn.pt\n",
    "  -> Best Validation Loss: 0.294\n",
    "  -> Best Validation F1 (Macro) at Best Loss: 0.887\n",
    "============================================================\n",
    "```\n",
    "<br>\n",
    "\n",
    "5차 시도:\n",
    "- N_FILTERS = 128 (원상복구)\n",
    "- EMBED_DIM = 256 (원상복구)\n",
    "```\n",
    "============================================================\n",
    "--- Training Finished ---\n",
    "Best Model saved to: best_model_cnn.pt\n",
    "  -> Best Validation Loss: 0.300\n",
    "  -> Best Validation F1 (Macro) at Best Loss: 0.890\n",
    "============================================================\n",
    "```\n",
    "다 비슷비슷한데,,, 지금까진 모두 얼리스탑했으니 학습률 조정하고 에포크 늘려보자.  \n",
    "<br>\n",
    "\n",
    "6차 시도:  \n",
    "- 평가 방법 변경 (f1 -> Acc)\n",
    "- lr = 0.0001 (0.001 -> 0.0001)\n",
    "- epochs = 500 (30 -> 500)\n",
    "```\n",
    "============================================================\n",
    "--- Training Finished ---\n",
    "Best Model saved to: best_model_cnn.pt\n",
    "  -> Best Validation Loss: 0.239\n",
    "  -> Best Validation Acc at Best Loss: 91.21%\n",
    "============================================================\n",
    "```\n",
    "45 epoch에서 early stop  \n",
    "<br>\n",
    "\n",
    "7차 시도:  \n",
    "- FILTER_SIZES = [2, 3, 4, 5]   \n",
    "    ([3, 4, 5] -> [2, 3, 4, 5])\n",
    "```\n",
    "============================================================\n",
    "--- Training Finished ---\n",
    "Best Model saved to: best_model_cnn.pt\n",
    "  -> Best Validation Loss: 0.233\n",
    "  -> Best Validation Acc at Best Loss: 91.80%\n",
    "============================================================\n",
    "```\n",
    "57 epoch에서 early stop  \n",
    "<br>\n",
    "\n",
    "8차 시도:  \n",
    "- dropout = 0.3 (0.5 -> 0.3)\n",
    "```\n",
    "============================================================\n",
    "--- Training Finished ---\n",
    "Best Model saved to: best_model_cnn.pt\n",
    "  -> Best Validation Loss: 0.237\n",
    "  -> Best Validation Acc at Best Loss: 91.02%\n",
    "============================================================\n",
    "```\n",
    "늘려서 다시 해보자  \n",
    "<br>\n",
    "\n",
    "9차 시도:  \n",
    "- dropout = 0.7 (0.3 -> 0.7)\n",
    "```\n",
    "============================================================\n",
    "--- Training Finished ---\n",
    "Best Model saved to: best_model_cnn.pt\n",
    "  -> Best Validation Loss: 0.241\n",
    "  -> Best Validation Acc at Best Loss: 91.14%\n",
    "============================================================\n",
    "```\n",
    "큰 차이 없어 보임.  \n",
    "<br>\n",
    "\n",
    "10차 시도:  \n",
    "- lr 줄였으니 L2 정칙화 다시 시도  \n",
    "- 라고 하려고 했으나 지금까지 정칙화 계속 적용하고 있었음;;  \n",
    "- 이번엔 없애서 해보자  \n",
    "```\n",
    "============================================================\n",
    "--- Training Finished ---\n",
    "Best Model saved to: best_model_cnn.pt\n",
    "  -> Best Validation Loss: 0.222\n",
    "  -> Best Validation Acc at Best Loss: 92.90%\n",
    "============================================================\n",
    "```\n",
    "ridge 없애니 확실히 올랐음.  \n",
    "<br>\n",
    "\n",
    "11차 시도:  \n",
    "- 다시 모델 크기 줄여보기\n",
    "- N_FILTERS = 64 (128 -> 64)\n",
    "- EMBED_DIM = 128 (256 -> 128)  \n",
    "```\n",
    "============================================================\n",
    "--- Training Finished ---\n",
    "Best Model saved to: best_model_cnn.pt\n",
    "  -> Best Validation Loss: 0.276\n",
    "  -> Best Validation Acc at Best Loss: 90.29%\n",
    "============================================================\n",
    "```\n",
    "  \n",
    "<br>\n",
    "\n",
    "12차 시도:  \n",
    "- N_FILTERS = 256 (64 -> 256)\n",
    "- EMBED_DIM = 512 (128 -> 512)  \n",
    "-> 파라미터 250만개\n",
    "```\n",
    "============================================================\n",
    "--- Training Finished ---\n",
    "Best Model saved to: best_model_cnn.pt\n",
    "  -> Best Validation Loss: 0.230\n",
    "  -> Best Validation Acc at Best Loss: 92.58%\n",
    "============================================================\n",
    "```\n",
    "좋긴 한데,, 학습률 더 낮춰보자  \n",
    "<br>\n",
    "\n",
    "13차 시도:  \n",
    "- lr = 1e-5 (0.0001 -> 1e-5)\n",
    "```\n",
    "============================================================\n",
    "--- Training Finished ---\n",
    "Best Model saved to: best_model_cnn.pt\n",
    "  -> Best Validation Loss: 0.290\n",
    "  -> Best Validation Acc at Best Loss: 90.15%\n",
    "============================================================\n",
    "```\n",
    "의미 없는 듯 하다.  \n",
    "<br>\n",
    "\n",
    "\n",
    "1D CNN 선택 이유:  \n",
    "- 협박, 갈취 등 자극적인 대화는 \"죽어\", \"내놔\" 같은 짧은 키워드로 구분될 가능성이 높다고 생각했다.  \n",
    "- 따라서 n-gram 방식을 사용하며 국소적인 패턴을 감지하는 데 좋은 성능을 보이는 1d CNN을 선택했다.  \n",
    "- 또한, 구조가 다른 모델에 비해 단순해서 학습에 걸리는 시간이 상대적으로 짧다.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
